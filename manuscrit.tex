\documentclass[symmetric,justified,marginals=raggedouter]{tufte-book}

%\hypersetup{colorlinks}% uncomment this line if you prefer colored hyperlinks (e.g., for onscreen viewing)

%%
% If they're installed, use Bergamo and Chantilly from www.fontsite.com.
% They're clones of Bembo and Gill Sans, respectively.
%\IfFileExists{bergamo.sty}{\usepackage[osf]{bergamo}}{}% Bembo
%\IfFileExists{chantill.sty}{\usepackage{chantill}}{}% Gill Sans

%\usepackage{microtype}

%%
% For nicely typeset tabular material
\usepackage{booktabs}

%%
% For graphics / images
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}

% The fancyvrb package lets us customize the formatting of verbatim
% environments.  We use a slightly smaller font.
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}

%%
% Prints argument within hanging parentheses (i.e., parentheses that take
% up no horizontal space).  Useful in tabular environments.
\newcommand{\hangp}[1]{\makebox[0pt][r]{(}#1\makebox[0pt][l]{)}}

%%
% Prints an asterisk that takes up no horizontal space.
% Useful in tabular environments.
\newcommand{\hangstar}{\makebox[0pt][l]{*}}

%%
% Prints a trailing space in a smart way.
\usepackage{xspace}

%%
% Some shortcuts for Tufte's book titles.  The lowercase commands will
% produce the initials of the book title in italics.  The all-caps commands
% will print out the full title of the book in italics.
\newcommand{\vdqi}{\textit{VDQI}\xspace}
\newcommand{\ei}{\textit{EI}\xspace}
\newcommand{\ve}{\textit{VE}\xspace}
\newcommand{\be}{\textit{BE}\xspace}
\newcommand{\VDQI}{\textit{The Visual Display of Quantitative Information}\xspace}
\newcommand{\EI}{\textit{Envisioning Information}\xspace}
\newcommand{\VE}{\textit{Visual Explanations}\xspace}
\newcommand{\BE}{\textit{Beautiful Evidence}\xspace}

\newcommand{\TL}{Tufte-\LaTeX\xspace}

% Prints the month name (e.g., January) and the year (e.g., 2008)
\newcommand{\monthyear}{%
  \ifcase\month\or January\or February\or March\or April\or May\or June\or
  July\or August\or September\or October\or November\or
  December\fi\space\number\year
}


% Prints an epigraph and speaker in sans serif, all-caps type.
\newcommand{\openepigraph}[2]{%
  %\sffamily\fontsize{14}{16}\selectfont
  \begin{fullwidth}
  \sffamily\large
  \begin{doublespace}
  \noindent\allcaps{#1}\\% epigraph
  \noindent\allcaps{#2}% author
  \end{doublespace}
  \end{fullwidth}
}

% Inserts a blank page
\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage}

\usepackage{units}

% Typesets the font size, leading, and measure in the form of 10/12x26 pc.
\newcommand{\measure}[3]{#1/#2$\times$\unit[#3]{pc}}

% Macros for typesetting the documentation
\newcommand{\hlred}[1]{\textcolor{Maroon}{#1}}% prints in red
\newcommand{\hangleft}[1]{\makebox[0pt][r]{#1}}
\newcommand{\hairsp}{\hspace{1pt}}% hair space
\newcommand{\hquad}{\hskip0.5em\relax}% half quad space
\newcommand{\TODO}{\textcolor{red}{\bf TODO!}\xspace}
\newcommand{\ie}{\textit{i.\hairsp{}e.}\xspace}
\newcommand{\eg}{\textit{e.\hairsp{}g.}\xspace}
\newcommand{\na}{\quad--}% used in tables for N/A cells
\providecommand{\XeLaTeX}{X\lower.5ex\hbox{\kern-0.15em\reflectbox{E}}\kern-0.1em\LaTeX}
\newcommand{\tXeLaTeX}{\XeLaTeX\index{XeLaTeX@\protect\XeLaTeX}}
% \index{\texttt{\textbackslash xyz}@\hangleft{\texttt{\textbackslash}}\texttt{xyz}}
\newcommand{\tuftebs}{\symbol{'134}}% a backslash in tt type in OT1/T1
\newcommand{\doccmdnoindex}[2][]{\texttt{\tuftebs#2}}% command name -- adds backslash automatically (and doesn't add cmd to the index)
\newcommand{\doccmddef}[2][]{%
  \hlred{\texttt{\tuftebs#2}}\label{cmd:#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\doccmd}[2][]{%
  \texttt{\tuftebs#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newenvironment{docspec}{\begin{quotation}\ttfamily\parskip0pt\parindent0pt\ignorespaces}{\end{quotation}}% command specification environment
\newcommand{\docenv}[1]{\texttt{#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docenvdef}[1]{\hlred{\texttt{#1}}\label{env:#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}\index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name
\newcommand{\docclsoptdef}[1]{\hlred{\texttt{#1}}\label{clsopt:#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name defined
\newcommand{\docmsg}[2]{\bigskip\begin{fullwidth}\noindent\ttfamily#1\end{fullwidth}\medskip\par\noindent#2}
\newcommand{\docfilehook}[2]{\texttt{#1}\index{file hooks!#2}\index{#1@\texttt{#1}}}
\newcommand{\doccounter}[1]{\texttt{#1}\index{#1 counter@\texttt{#1} counter}}

% Generates the index
\usepackage{makeidx}
\makeindex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Customization %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{indentfirst}

\usepackage[french]{babel}


\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

\setcounter{tocdepth}{1}
\setcounter{secnumdepth}{1}

\renewcommand\contentsname{\normalfont \huge Table des matières}

\titlecontents{chapter}%
    [0em]% distance from left margin
    {\vspace{1\baselineskip}\begin{fullwidth} }% above (global formatting of entry)
    {Chapitre \contentslabel{0em} \hspace{1em} \huge $\vert$ \Large }% before w/ label (label = ``Chapter 1'')
    {}% before w/o label
    {\hfill\qquad\thecontentspage}% filler and page (leaders and page num)
    [\end{fullwidth}]% after
\titlecontents{section}% FIXME
    [0em] % distance from left margin
    {\vspace{0\baselineskip}\begin{fullwidth} \rmfamily\itshape} % above (global formatting of entry)
    {\hspace*{6,2em}\contentslabel{2em}} % before w/label (label = ``2.6'')
    {\hspace*{7em}} % before w/o label
    {\normalfont\hfill\qquad\thecontentspage} % filler + page (leaders and page num)
    [\end{fullwidth}] % after       
    

\usepackage{enumitem}
\setlist{leftmargin=20mm}

\usepackage{tikz}
\usetikzlibrary{calc}

\tikzset{
    every picture/.prefix style={
        execute at begin picture=\shorthandoff{;}
    }
}

\newcommand\tikzmark[1]{%
  \tikz[overlay,remember picture] \coordinate (#1);}
  
 \renewcommand\labelitemi{--}

\usepackage{multirow}

\makeatletter
    \newcommand{\vast}{\bBigg@{3}}
    \newcommand{\Vast}{\bBigg@{3.5}}
    \newcommand{\vastt}{\bBigg@{4}}
    \newcommand{\Vastt}{\bBigg@{11}}
    %%
    %% Size from smallest to largest:
    %%\[ ( \big( \Big( \bigg( \Bigg( \vast( \Vast( \vastt( \Vastt(\]
\makeatother

\usepackage{dpfloat}

\usepackage[]{algorithm2e}

\usepackage{afterpage}

%\widowpenalty 10000
%\clubpenalty 10000

\usepackage{microtype}

\usepackage{ellipsis}
\setlength{\ellipsisgap}{0.05em}

\begin{document}

% Front matter
\frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Titre %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\cleardoublepage
{  
  \begin{fullwidth}%
  \thispagestyle{empty} 
  \setlength{\parskip}{\baselineskip}
  \begingroup
  \vspace*{3em}
  \par\noindent\Large{Quentin Lobbé}
  \vspace*{-1em}
  \par\noindent\Huge\textbf{Archives, Fragments Web et Diasporas}  
  \par\noindent\nohyphenation\Large{Pour une exploration désagrégée de corpus d'archives Web liées aux représentations en ligne des diasporas}
  \endgroup
  \vfill  
  
  \par\noindent Thèse de doctorat de l'Université Paris-Saclay, préparée à Télécom ParisTech, école doctorale des Sciences et Technologies de l'Information et de la Communication (STIC) pour la spécialité Données, Connaissances, Apprentissage et Interaction.

  \par\noindent Présentée par \textbf{Quentin Lobbé}\\
  LTCI, Télécom ParisTech, Université Paris Saclay \& Inria. Paris, France.\\
  quentin.lobbe@telecom-paristech.fr

  \par\noindent Sous la direction de :\\
  \textbf{Pierre Senellart}, professeur à l'École Normale Supérieure\\
  \textbf{Dana Diminescu}, enseignante chercheuse à Télécom ParisTech

  \par\noindent Soutenue publiquement à Paris le 9 novembre 2018, devant un jury composé de :\\
  \textbf{Bruno Bachimont} (Rapporteur), professeur à Sorbonne Université\\
  \textbf{Marc Spaniol} (Rapporteur), professeur à l'Université de Caen Basse-Normandie\\
  \textbf{Anat Ben-David}, professeure à l'Open University of Israel\\
  \textbf{Valérie Schafer}, professeure à l'Université du Luxembourg\\
  \textbf{Bruno Defude}, professeur à Télécom SudParis  
  
  \end{fullwidth}%
}

\blankpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Résumé %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  
\newpage
\begin{fullwidth}
\thispagestyle{empty}
\setlength{\parskip}{\baselineskip}

\noindent\textbf{Titre :} \smallcaps{Archives, Fragments Web et Diasporas.} Pour une exploration désagrégée de corpus d'archives Web liées aux représentations en ligne des diasporas 

\noindent\textbf{Mots clés :}

\noindent\textbf{Résumé :}

\vfill

\noindent\textbf{Title :} \smallcaps{Archives, Web Fragments and Diasporas.}

\noindent\textbf{Keywords :}

\noindent\textbf{Abstract :}


\end{fullwidth}
  
\thispagestyle{empty}%
\clearpage%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Citation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

~\vfill
\noindent
\par\noindent \og Il me demanda de chercher la première page.\\
\noindent Je posais ma main gauche sur la couverture et ouvris le volume de mon pouce serré contre l'index. Je m'efforçais en vain : il restait toujours des feuilles entre la couverture et mon pouce. Elles semblaient sourdre du livre.\\
--- Maintenant cherchez la dernière.\\
\noindent Mes tentatives échouèrent de même; à peine pus-je balbutier d'une voix qui n'était plus ma voix :\\
--- Cela n'est pas possible.\\
\noindent Toujours à voix basse le vendeur me dit : \\
--- Cela n'est pas possible et pourtant cela \textit{est}. Le nombre de pages de ce livre est exactement infini. Aucune n'est la première, aucune n'est la dernière. \fg
\\~\\
\noindent \smallcaps{Jorge Luis Borges}, \textit{Le livre de sable} 
\vfill
\indent

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Remerciements %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\begingroup
\vspace*{8em}
\huge $\vert$ \huge Remerciements
\vspace*{4em}
\par\normalsize Là, il faudra remercie du monde.
\endgroup
\vfill

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Tables %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

%\listoffigures

%\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{\Large Introduction}
\chaptermark{INTRODUCTION}

\noindent Le Web est un environnement instable, éphémère. Né il y a moins de 30 ans, il se présente tout autant comme un flux continu d'information qu'un territoire en perpétuel expansion. Alors que de nouveaux sites Web émergent jour après jour, il arrive régulièrement que des communautés disparaissent entièrement de la surface la toile, ne laissant derrière elles que des traces incomplètes voire inexistantes.

Face à la volatilité du Web vivant, plusieurs initiatives d'archivage cherchent malgré tout à préserver la mémoire du Web passé. En effet, depuis le milieu des années 90, des pionniers archivent régulièrement une part significative des ressources publiées en ligne (des pages, des liens hypertextes, du contenu multimédia~\ldots{}), permettant ainsi la sauvegarde de cet héritage numérique pour les générations futures. Mais aujourd'hui, force est de constater qu'un mystère demeure : Pourquoi, alors qu'elles n'ont jamais été aussi vastes et aussi nombreuses, les archives Web ne font-elles pas déjà l'objet de multiples recherches historiques ? Pourquoi l'usage des archives ne s'est-il-pas démocratisé~?

Cet état de fait est à ce point paradoxal que le Web est devenu une composante essentielle de nos vies quotidiennes. Le recours à ses archives devrait être, sinon un reflex, au moins une possibilité raisonnable pour qui souhaite interroger les traces du Web passé : Quel a été le devenir de tel ou tel collectif en ligne au cours des dix dernières années ? Pourquoi certains groupes d'internautes ont-ils-été impactés par un événement socio-politique donné ? De quelle manière cette technologie s'est-elle imposée sur la toile malgré la concurrence en place ?~etc. 

Les sujets de recherche ne manquent pas et l'intérêt scientifique pour les archives Web reste vivace. En effet, ces corpus sont de véritables mines d'or ne demandant qu'à être explorées par des historiens, par des sociologues ou par de simples curieux. Mais le chemin pour y arriver est semé d'embuches et il existe, encore aujourd'hui, des freins majeurs à la possibilité de jeter un regard en arrière sur le Web et sur son histoire.\\

\noindent Le problème, selon nous, se niche au sein même de la structure des corpus archivés et se répercute en cascade dans les différents systèmes d'exploration existant. À l'origine, les archives Web furent construites pour inscrire la mémoire de la toile sur un support durable. Pourtant, ces archives ne doivent pas être considérées comme une représentation fidèle du Web vivant. Elles sont, malgré elles, les traces directes des outils de collecte programmés par les archivistes. 

En effet, l'unité principale d'exploration des collectages reste la page Web. Tous les systèmes d'archivage sont, ainsi, construits au-dessus des pages qu'ils capturent et qu'ils associent à une date de téléchargement. De fait, cette date devient le seul marqueur temporel permettant d'interroger les corpus préservés. Arrachées à leur temporalité d'origine, les archives Web nous reviennent alors comme des objets discrétisés et figés, sans lien direct avec la réalité du Web vivant dont elles sont, pourtant, censées être le reflet.

Ceci étant exposé, nous voulons, dans cette thèse, redonner aux chercheurs les moyens théoriques et techniques d'une plus grande maniabilité du Web passé, et ce, en définissant une nouvelle unité d'exploration des archives Web : le fragment Web, un sous-ensemble cohérent et auto-suffisant d'une page Web. 

Le fragment Web a la particularité d'être associé à une date d'édition (c.-à-d., la date a laquelle il a été mis en ligne) plutôt qu'aux seules dates de téléchargement. Ce faisant, les archives Web quittent, enfin, le temps des robots collecteurs pour retrouver le temps du Web tel qu'il a été. Et dans un même mouvement, c'est l'humain que nous cherchons à replacer au cœur de l'analyse des archives en témoignant directement, grâce au fragment Web, du geste des personnes qui auront, par le passé, publié, partagé ou commenté un contenu en ligne.   

Aussi, le fragment Web introduit une nouvelle grammaire analytique qui permet aux chercheurs d'explorer les archives Web de manière désagrégée et libérée de la pesanteur des formats existants. Les corpus collectés passent alors sur la table de montage, où ils sont découpés, déplacés et mis en relation avec d'autres éléments épars du Web passé. Cette souplesse méthodologique ouvre la voie à des explorations à grande échelle, susceptibles de retracer l'histoire en ligne et hors ligne d'un moment singulier. Et s'il semble ambitieux de vouloir traiter ici de l'ensemble des mutations du Web ou des transformations qu'il a induites dans nos sociétés, nous pensons néanmoins pouvoir nous focaliser sur un problème plus générique : comment rendre compte, au présent, d'un événement et de sa genèse en le restituant dans la double temporalité du Web et du réel ?

Mais les enjeux soulevés par l'exploration des archives du Web dépassent bien souvent le cadre strict d'une seule et unique discipline. Aussi, pour interroger l'histoire du Web passé, il ne faudra pas hésiter à croiser les regards, les perspectives de recherches et à s'ouvrir aux controverses. Ainsi, bien que soutenue en informatique, la présente thèse se situera, par moment, aux frontières de l'histoire et de la sociologie.\\

\noindent Pour le chercheur en informatique, la nature même des corpus d'archives Web est, en soi, un défi de taille. Leur volume et leurs étendue posent un problème fondamental d'ingénierie. Comment trouver efficacement, parmi plusieurs millions de versions de pages archivées, l'unique document correspondant à requête donnée ? 

Souvent trop larges et trop éparses, les archives Web peuvent manquer de cohérence interne voire thématique, et, malheureusement, ces soucis sont difficilement résolubles a posteriori. En effet, un chercheur doit souvent faire face à un corpus déjà constitué ou terminé (cela sera le cas de cette thèse). Il se contente alors des archives telles qu'il les découvre sans pouvoir influer directement sur la forme des collectages. 

Là encore, ce qui sous-tend toutes nos interrogations est une réflexion profonde sur la structure des archives Web. Quels problèmes posent les formats courants d'archivage ? Doit-on explorer les archives en l'état ? Ou peut-on imaginer une ou plusieurs transformations capables de faciliter leur exploration ?\\

\noindent Pour l'historien, les corpus d'archives Web demeurent des espaces encore majoritairement inexplorés (tout au moins à grande échelle). Aussi, peut-on imaginer que le Web passé soit déjà si distant de nous qu'il nous serait aujourd'hui impossible de l'appréhender dans toute sa complexité ? Existe-il des phénomènes de conservation différentielle qui entraîneraient une sous-représentation de certains types de sites Web ? N'oublions pas qu'une forme d'obsolescence technique rend désormais très compliquée la reconstruction à l'identique du Web des années 90 (par exemple) et, par là même, son analyse \textit{in situ}. 

Ce faisant, il s'agit peut-être pour nous de considérer un site ou un ensemble de pages archivées comme un chantier de fouilles à part entière. Comment étudier l'histoire d'un site Web en avançant par strates et couches successives jusqu'à remonter à ses origines et à sa mise en ligne initiale ? Se pose alors la question des indicateurs : La trace que nous avons sous les yeux est-elle historiquement significative ? Comment la dater ? Dans quel contexte a-elle été produite puis sauvegardée ? Et inversement, qu'elles ressources n'ont pas été (en conscience ou non) préservées par les archivistes ?\\  

\noindent Pour le sociologue, explorer un corpus d'archives Web est l'occasion d'étudier les multiples dynamiques à l'œuvre sur la toile. En effet, mettre un site en ligne, l'alimenter et le faire vivre est une forme de présence tout à fait singulière sur le Web. Là où d'autres naviguent de page en page et réagissent face à du contenu déjà existant, certaines personnes choisissent plutôt de mettre en ligne des ressources originales. Ces espaces créés de toutes pièces deviennent des lieux d'échanges, de connections et de partages. Ce faisant, il existe un geste singulier à interroger derrière chaque site Web. Aussi, ces derniers doivent être considérés comme des acteurs évoluant au sein de réseaux d'internautes, de pages Web, de robots d'indexation, d'institutions\ldots{} 

Par exemple, la dynamique des liens de citation produits sur le Web est une piste de réflexion pour qui souhaite questionner une forme de géopolitique de l'hypertexte. Quels enjeux hors ligne déterminent un lien de reconnaissance en ligne ? Comment un acteur conserve-t-il une position d'autorité au sein d'un collectif de sites nouvellement crée ? Quelle forme d'organisation \textit{IRL}\footnote{Expression anglaise (\textit{in real life}) désignant généralement la vie en dehors du Web.} préfigure la naissance d'une communauté d'internautes ? etc. 

Finalement, la question est, ici, de faire du Web un espace de recherche capable d'enrichir une enquête qualitative ou d'être lui même renforcé par une série d'entretiens. Comment faire se confronter et mettre en relation le récit d'une personne donnée avec ses traces Web telles qu'elles ont été archivées ? Peut-on réorienter l'exploration automatique d'un corpus d'archives Web sur la base d'indices issus d'observations de terrain ?\\

\noindent Sur ce dernier point et de manière transversale à tous les enjeux précédemment cités, demeure la question de l'interdisciplinarité qu'il nous faudra prendre à bras-le-corps. En effet, il s'agira pour cette thèse de se positionner dans un dialogue constant entre chaque discipline afin de conjuguer ensemble les problématiques des unes et des autres. Notre méthodologie d'exploration des archives Web se verra ainsi fortement influencée par ce besoin de pouvoir passer, à volonté ou suivant les contraintes du moment, d'un ensemble de traitements automatiques à grande échelle vers une série de validations focalisées et manuelles. 

Pour ce faire, nous nous inscrirons dans l'héritage des travaux pionniers de l'Atlas e-Diasporas \citep{diminescu_e-diasporas_2012} qui mobilisa, à la fin des années 2000, des ingénieurs, des sociologues et des historiens autour de l'étude des formes de représentation en ligne des diasporas. L'Atlas, dirigé et conçu par D. Diminescu, permit l'observation et la cartographie de plus de 9000 sites Web migrants\footnote{\RaggedOuter \url{http://www.e-diasporas.fr/}}. Créés et maintenus par des personnes migrantes, ces sites se connectaient les uns aux autres par des liens de citation hypertextes formant, ainsi, de véritables réseaux : les e-Diasporas, des collectifs migrants en ligne qui s'organisaient d'abord et avant tout sur le Web. 

Mais devant faire face à la disparition totale ou partielle de tout ou partie de ces sites, il a rapidement été décidé de les archiver pendant quatre années durant, de 2010 à 2014 (de manière hebdomadaire ou mensuelle), et ce, afin de permettre la tenue de recherches futures. C'est ainsi que les archives Web de l'Atlas e-Diasporas se présentent aujourd'hui à nous comme source principale de données à partir desquelles nous déploierons les réflexions portées par cette thèse. De fait, c'est à travers l'angle particulier des usages et des activités en ligne des populations migrantes que nous chercherons à explorer ces corpus. \\

\noindent Partant de là, le Chapitre \ref{chap:2} commencera par dresser un historique des origines d'Internet et du Web. Nous découvrirons alors la manière avec laquelle les Technologies de l'Information et de la Communication (TIC) sont devenues, pour les sociologues, des angles possibles d'analyse des migrations récentes. Faisant figure d'aboutissement scientifique dans ce domaine, nous présenterons alors les différentes étapes de la construction de l'Atlas e-Diaspora en terminant par l'étude de son corpus marocain qui servira de fil conducteur à cette thèse.

Si l'archivage du Web n'est pas au cœur, à proprement parler, de nos travaux (nous explorons les archives après leur constitution), il nous semble néanmoins important de comprendre les modalités de préservation du Web à travers le monde. Le Chapitre \ref{chap:3} reviendra, ainsi, sur les vingts premières années de cet effort d'archivage, essayant de faire un tour d'horizon des diverses techniques de collecte, de stockage et de consultation du Web passé. Ce faisant, nous complèterons la description du réseau marocain de l'Atlas e-Diasporas, considéré cette fois-ci comme un corpus d'archives Web à explorer.    

Arrachées au Web vivant par des robots collecteurs, les archives du Web passé basculent dans une nouvelle temporalité, induisant la présence de différents biais de compréhension que le Chapitre \ref{chap:4} cherchera à décrire : cécité de collecte, cohérence entre pages, contenu dupliqué\ldots{} Ce sera ainsi l'occasion de porter un regard critique sur les archives Web telles que nous les connaissons. Nous présenterons ensuite, d'un point de vue technique, notre moteur d'exploration des archives Web, support des analyses à venir. 

Cela aboutira, dans le Chapitre \ref{chap:5}, à la définition d'une stratégie d'analyse capable de s'affranchir de l'héritage pesant des outils de collecte, ou tout au moins, d'en atténuer les effets. Nous changerons ainsi d'unité d'exploration, en présentant notre principale contribution : le fragment Web. Nous porterons notre réflexion sur la question de la datation des corpus archivés, en associant à chaque fragment une date d'édition. Un cas simple de détection d'événements dans les archives Web nous permettra d'en faire la démonstration.

Arrivés au Chapitre \ref{chap:6}, nous plongerons enfin au cœur de nos archives en menant deux explorations successives. Nous chercherons, en premier lieu, à questionner le devenir d'un collectif de blogueurs marocains de l'étranger. Entre 2008 et 2018, ces internautes ont progressivement déserté leur blogosphère pour migrer vers des plateformes de réseaux sociaux. Nous suivrons, ensuite, l'impact d'une mobilisation\footnote{\RaggedOuter Il s'agira des grandes manifestations marocaines du 20 février 2011.}, liée aux vagues contestataires du Printemps arabe, sur les membres d'une communauté centrale de l'e-Diaspora marocaine : le forum en ligne \textit{yabiladi.com}. Enfin, tirant les leçons de ces deux explorations, nous introduirons la notion de moments pivots du Web, comme une contribution à l'analyse du Web en tant qu'objet de recherches historiques. 

Nous terminerons cette thèse par un aperçu, dans le Chapitre \ref{chap:7}, de la diversité des formes d'archives Web et de traces numériques des migrations qu'il nous aura été donné d'explorer. En étudiant les logs de navigation de l'Internet Libre de la Bibliothèque Publique d'Information du Centre Pompidou (BPI), nous chercherons à comprendre les particularités d'un Web de première nécessité, destiné à un public précaire. Puis nous examinerons les archives du programme d'hébergement des personnes exilées Comme à la Maison (CALM), afin de saisir la dynamique de l'accueil des réfugiés en France, chez des particuliers, à la fin de l'été 2015.

\newpage

\section*{Principales contributions}
\label{sec:1_contributions}

\subsection{Publications}

\begin{itemize}[leftmargin=*]  
\item Lobbé, Q. (2018), Where the dead blogs are : a disaggregated exploration of Web archives to reveal extinct online collectives, 34\ieme{} Conférence sur la Gestion de Données – Principes, Technologies et Applications (BDA), 2018
\item Lobbé, Q. (2018), Revealing historical events out of Web archives, 22\ieme{} International Conference on Theory and Practice of Digital Libraries (TPDL), Demonstration paper, 2018
\item Lobbé, Q. (2016), \textit{Cartographier les jungles}, Plein Droit n°110, 2016
\end{itemize}

\subsection{Communications}

\begin{itemize}[leftmargin=*] 
\item Lobbé, Q. (2018), Where the dead blogs are : a disaggregated exploration of Web archives to reveal extinct collectives, Web Archiving: Best Practices for Digital Cultural Heritage, Jerusalem, 2018 
\item Diminescu, D., Jacomy, M. et Lobbé, Q. (2018), About E-Diasporas, International Forum on Migration Statistics, Session Migration Traceabillity, Paris, 2018
\item Lobbé, Q. (2017), Introducing Web Fragments : An exploration of web archives beyond the webpages, Medialab’s research seminar, SciencesPo Paris, 2017
\item Lobbé, Q. (2016), Of Maps and Refugees, DiasporasLab Workshop, University of California, Los Angeles, 2016
\end{itemize}

\subsection{Cours}

\begin{itemize}[leftmargin=*] 
\item Lobbé, Q. (2016), Voyage au cœur d'un index Lucene\footnote{\RaggedOuter \url{http://qlobbe.net/ressources/search.pdf}} : comprendre les moteurs de recherche de l'intérieure, Télécom ParisTech, 2016
\end{itemize}

\subsection{Codes et logiciels}

\begin{itemize}[leftmargin=*] 
\item Archive-miner\footnote{\RaggedOuter \url{https://github.com/lobbeque/archive-miner}} : moteur d'extraction et de transformation d'archives Web DAFF en documents Solr (Java, Spark) 
\item Archive-search\footnote{\RaggedOuter \url{https://github.com/lobbeque/archive-search}} : moteur de recherche d'archives Web (Java, Bash, Solr) 
\item Rivelaine\footnote{\RaggedOuter \url{https://github.com/lobbeque/rivelaine}} : bibliothèque d'extraction de fragments Web (Scala, Javascript)
\item Peastee\footnote{\RaggedOuter \url{https://github.com/lobbeque/peastee}} : interface de visualisation d'archives Web (Javascript, HTML) 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\begin{minipage}[t,leftmargin=5em]{1.5\linewidth}%
\begin{adjustwidth}{-0.5cm}{}
\chapter{Les Représentations en ligne des diasporas} 
\label{chap:2}
\end{adjustwidth}
\end{minipage}
\hfill

\noindent Web et diasporas sont étroitement mêlés. Le premier étant rapidement devenu un support de représentation et d'organisation au service des secondes. Les diasporas se drapent ainsi de sur-couches numériques, serties de sites Web migrants, de comptes Twitter et de groupes Facebook liés entre eux, connectés les uns aux autres et formant de véritables communautés diasporiques en ligne, dynamiques et cohérentes. 

Car le Web ne fait que ça : il connecte et rapproche. C'est une toile qui, depuis ses origines, a été construite pour mettre en relation des ressources, des personnes et des espaces. Révolution technique, le Web s'inscrit dans la longue histoire de l'informatique, prolongeant et s'appuyant sur l'une des inventions militaro-scientifiques majeure des années 70 \citep{hafner_where_1998} : Internet. 

Néanmoins, Internet et le Web ne doivent pas être confondus, l'un servant d'ossature à l'autre. Aussi, la première partie de ce chapitre, sera l'occasion pour nous de revenir sur la naissance du Web, au tout début des années 90. Initialement pensé comme un territoire virtuel à explorer, comme une galaxie de sites parmi lesquels naviguer librement, le Web se mue pourtant progressivement en un flux continue d'informations, qu'il convient de suivre avec assiduité. L'internaute s'affiliant à un panel de canaux qu'il affectionne, passant d'un silo de données à un autre. 

Mais, toujours en mouvement, le Web reprend rapidement la course de son évolution et devient mobile. Il se glisse aujourd'hui dans nos poches, on l'emporte avec nous, partout, tout le temps. Ubique, il apprend de nous et s'adapte à nos envies. Il sélectionne les ressources que nous consultons, dresse des cartes personnalisées des espaces qu'il nous faut visiter et nous suggère des listes de personnes à qui nous lier. Plutôt que de nous connecter aux autres, le Web nous rapproche désormais de nous même et des nôtres, cloisonnés dans des bulles de filtrages aux parois réfléchissantes.

Être présent sur la toile, y refléter ce que l'on est ou changer d'iden\-tité, retrouver ceux qui nous sont proches ou se connecter à d'autres plus éloignés, sont des motifs récurant du Web. Les populations migrantes ont ainsi été parmi les premières à s'approprier et à s'emparer de ces mécanismes de représentation à distance. De fait, à la fin des années 90, le développement des Technologies de l'Information et de la Communication (TIC) révolutionne le rapport au temps, à l'espace et aux frontières. L'avènement conjoint du Web grand public, des messageries électroniques et des téléphones mobiles offre de nouveaux outils de communication et d'organisation aux populations migrantes et aux collectifs dispersés. 

Aussi, la seconde partie de ce chapitre, nous permettra de saisir le changement de paradigme scientifique qui s'opéra, alors, autour de la figure du migrant comme objet d'étude. Considéré, jusque là, à travers le prisme du double déraciné \citep{sayad_double_1999}, à la fois absent dans son pays d'origine et difficilement intégré à son pays d'accueil, les TIC permettent, au contraire, de voir et de comprendre le migrant comme l'élément moteur d'une économie du lien et de la présence à distance \citep{diminescu_connected_2008}. 

Ce faisant, l'intérêt sociologique ou historique pour les formes de représentations en ligne des diasporas s'est rapidement développé. Sur la toile, les populations migrantes s'organisent collectivement à travers des réseaux de blogs ou sur des forums de discussion. Les personnes s'y rassemblent et font groupe autour de valeurs culturelles communes et partagées. Le Web devient alors un terrain favorable à l'établissement de points de rencontres, considérés comme des espaces de connections ou de re-connections avec les siens, tout autant que des lieux de conservation d'une mémoire dispersée, voire comme de véritables outils au service d'actions militantes.

Ce faisant, nous terminerons ce chapitre par la présentation de l'Atlas e-Diasporas \citep{diminescu_e-diasporas_2012}, fruit du travail coordonné d'un collectif de cher\-cheurs, d'ingénieurs et de designers, visant à explorer, documenter et cartographier des réseaux de sites Web migrants. Crées ou maintenus par des personnes migrantes\footnote{\RaggedOuter De manière générale, tous les sites liés explicitement à la vie d'une diaspora donnée ont été cartographiés (sites personnels, d'associations ou d'ambassades)}, ces sites Web sont connectés les uns aux autres, formant ce que nous appelons une e-Diaspora suivant la nomenclature introduite par l'Atlas. Aussi et plus concrètement, nos réflexions à venir seront basées sur l'exploration de ces e-Diasporas et de leurs archives Web\footnote{\RaggedOuter Archives sur lesquelles nous reviendrons en détail (Section~\ref{sec:3_edias})}.

\section{Généalogie du Web}
\label{sec:2_web}

\noindent L'informatique est la science des machines programmables et du traitement automatisé de l'information. Alors que l'origine des premières machines à calculer remonte à l'antiquité (abaques grecs\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Abaque\_(calcul)}}, bouliers chinois\ldots{}), le traitement automatisé de tâches élémentaires n'apparait qu'avec l'inauguration du métier à tisser programmable, crée par J.M. Jacquard, au début du XIXe siècle. Suites finies et non ambiguës d'instructions codées sur des cartes perforées, l'invention de Jacquard préfigure la \textbf{programmation algorithmique} à venir qui, de A. Lovelace\footnote{\RaggedOuter En 1843, A. Lovelace crée ce qui est considéré comme le premier programme informatique, à savoir un algorithme de calcul des nombres de Bernouilli.} à la machine de Turing (1935), s'attèlera alors à la résolution de problèmes de plus en plus complexes. Parallèlement, les ordinateurs ne cessent de se perfectionner et de voir leurs capacités de calculs augmenter \citep{lazard_histoire_2016}.

\subsection{Faire dialoguer les machines}

\noindent En pleine Guerre Froide, J.C.R. Licklider, alors directeur de l'agence américaine Advanced Research Projects Agency (ARPA), théorise un changement majeur : le passage de l'âge du calcul par ordinateur à celui des communications par machines interposées \citep{licklider_computer_1968}. Profitant de la création de la NASA\footnote{\RaggedOuter National Aeronautics and Space Administration}, lancée pour contrer l'URSS sur le terrain de la conquête spatiale, Licklider réoriente les travaux de l'ARPA pour laquelle il négocie une plus grande indépendance budgétaire et scientifique. Ce faisant, ses équipes se focalisent sur la possibilité de faire communiquer des ordinateurs entre eux et à distance par transfère d'information. Alors qu'il existait déjà des circuits de mutualisation des forces de calcul, Licklider cherche plutôt à privilégier la conception d'un réseau informatique pensé, d'abord, comme un vecteur de circulation de l'information, tel qu'il le prophétise : \\

\begin{fullwidth}
\og\textit{Life will be happier for the on-line individual because the people with whom one interacts most strongly will be selected more by commonality of interests and goals than by accidents of proximity. Second, communication will be more effective and productive, and therefore more enjoyable. Third, much communication and interaction will be with programs and programmed models, which will be (a) highly responsive, (b) supplementary to one’s own capabilities, rather than competitive, and (c) capable of representing progressively more complex ideas without necessarily displaying all the levels of their structure at the same time-and which will therefore be both challenging and rewarding. And, fourth, there will be plenty of opportunity for everyone (who can afford a console) to find his calling, for the whole world of information, with all its fields and disciplines, will be open to him – with programs ready to guide him or to help him explore}\fg{} --- \citep[p.21]{licklider_computer_1968}\\
\end{fullwidth}

\noindent Convaincus par Licklider, de jeunes chercheurs et ingénieurs rejoignent rapidement l'ARPA et planchent sur un prototype. L'un d'entre eux, P. Baran propose de bâtir un \textbf{réseau distribué} (Figure~\ref{fig:arpanet-0}, c) à l'opposé des modèles centralisés ou décentralisés plus classiques\footnote{\RaggedOuter Modèles notamment utilisés pour les réseaux téléphoniques.} (Figure~\ref{fig:arpanet-0}, a \& b). Le modèle distribué tend, en effet, à éviter la création de \textit{hubs} ou de points d'étranglements fragilisant la structure globale du réseau et préfère, au contraire, un maillage redondant où chaque nœud (ie: une machine) est relié à son voisinage direct. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-0}
  \caption{Trois modèles de réseaux : centralisé (a), décentralisé (b), distribué (c)}
  \label{fig:arpanet-0}
\end{figure*} 

\noindent En 1969, après quelques années d'efforts, un premier réseau baptisé \textbf{Arpanet} voit le jour. Un test grandeur nature est effectué dans la foulée, des messages sont alors échangés à distance entre les machines de quatre universités de l'Ouest américain\footnote{\RaggedOuter L'\textit{University of California, Los Angeles} (UCLA), l'\textit{University of California, Santa Barbara} (UCSB), la \textit{Leland Stanford Junior University} (laboratoire SRI) et l'\textit{University of Utah}}. Mais, il faut attendre octobre 1972 pour que l'Arpanet soit publiquement présenté lors de l'International Conference on Computer Communication (ICCC), à Washington. Le réseau démontre alors sa capacité à faire communiquer pour la première fois des ordinateurs entre côtes Est et Ouest des États-Unis \citep[p.175-186]{hafner_where_1998}.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-1}
  \caption{Schéma de la première version de l'Arpanet (P. Baran, 1969, a) et structure de l'Arpanet en 1972 (b)}
  \label{fig:arpanet-1}
\end{figure*} 

\noindent Mais au delà de la pure démonstration technique, c'est une communauté entière qui se rassemble ce jour là à l'ICCC et, parmi elle, des personnes qui ne s'étaient encore jamais rencontrées hors du réseau. Et c'est là l'une des grandes réussites symboliques de l'Arpanet que d'avoir fait émerger les premières communautés en ligne sous la forme, à cette époque, de listes de discussions et de spécifications\footnote{\RaggedOuter Notamment à travers la liste de discussion et de spécifications \textit{Request for comment} (RFC), \url{https://fr.wikipedia.org/wiki/Request\_for\_comments}}. Le réseau met en relation, il rapproche les chercheurs malgré la distance. 

\newpage 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/arpanet-2}
  \vspace*{0.2cm}  
  \caption{Fonctionnement générale de la communication par paquets}
  \label{fig:arpanet-2}
\end{marginfigure} 

Néanmoins, pour communiquer avec n'importe quel interlocuteur, humain ou robot, il faut d'abord établir un protocole (un langage par example) et trouver le moyen technique de transmettre le message que l'on cherche émettre (par la parole ou par le geste). Aussi, le génie des équipes de l'ARPA est d'avoir mis au point un nouveau système de communication robuste et capable de passer à l'échelle : la \textbf{communication par paquet}. Contrairement à la communication téléphonique, ce modèle ne nécessite pas l'établissement d'un circuit électrique continu entre deux points fixes. En effet, sur l'Arpanet chaque message est divisé en un ensemble de paquets distincts, envoyés les uns à la suite des autres de manière discontinue. C'est au récepteur de reconstituer l'intégralité du message grâce aux informations contenu dans son en-tête (Figure~\ref{fig:arpanet-2}). 

S'appuyant sur le succès de sa démonstration, l'Arpanet s'étend tout au long des années 70, accueillant de nouvelles machines voire même des réseaux fermés d'ordinateurs déjà existants\footnote{\RaggedOuter Notamment le réseaux de l'International Network Working Group (INWG)}. Mais face à cette croissance continue, se pose rapidement la question des modalités de communication et d'intégration de machines diverses et variées. Comment les faire parler la même langue à l'échelle globale tout en respectant leur spécificités techniques locales ? 

Pour résoudre ce problème, l'Arpanet se dote en 1983 d'un protocole unifié de communication, le \textbf{TCP/IP}\footnote{\RaggedOuter De l'anglais, Transmission Control Protocol/Internet Protocol, \url{https://fr.wikipedia.org/wiki/Suite\_des\_protocoles\_Internet}} désormais adossé à une \textbf{architecture en couches}. Ce faisant, chaque nœud du réseau est alors identifié par une adresse IP unique permettant d'acheminer précisément les paquets de données vers un récepteur\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Adresse\_IP}} (Figure~\ref{fig:arpanet-3}).  

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-3}
  \caption{Cheminement d'un message à travers un réseau de type Arpanet, suivant le protocole TCP/IP}
  \label{fig:arpanet-3}
\end{figure*} 

\noindent Les messages, quant à eux, cheminent à travers les différentes cou\-ches du réseau qui se voient, chacune, attribuer un rôle différent dans le transport de l'information. L'idée générale étant de permettre à n'importe qui de développer de nouveaux protocoles applicatifs (com\-me un système d'emails ou de discussion en temps réel), tout en conservant une grande autonomie et sans avoir à se soucier de la livraison des messages. Ainsi, l'adoption du TCP/IP dynamise le développement international du réseau, en lui offrant une plasticité jusque là inédite. L'Arpanet vieillissant laisse alors progressivement sa place à un \textbf{Internet} devenu globale. Le vieux rêve de Licklider a pris forme, les machines et les hommes communiquent d'un continent à l'autre et les réseaux pénètrent déjà différentes couches de la société : des administrations aux industries, en passant par le monde académique. \\

\subsection{L'invention du World Wide Web} 

\noindent Au tournant des années 90, T. Berners Lee, alors chercheur au CERN\footnote{\RaggedOuter Désignation courante de l'Organisation européenne pour la recherche nucléaire, à Genève}, planche sur un nouveau système de partage et de gestion de documents informatiques. Son intuition est la suivante : appliquer le principe de l'\textbf{hypertexte} aux capacités de circulation d'information de l'Internet. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/hypertext-0}
  \vspace*{0.2cm}  
  \caption{Un hyperlien entre deux documents A et B}
  \label{fig:hypertext-0}
\end{marginfigure} 

Théorisé par T. Nelson au milieu des années 60 \citep{nelson_getting_1967}, l'hypertexte est un modèle de mise en relation de documents numé\-riques par liens de citation ou références (ie : les hyperliens). Chaque document ou ensemble de documents hypertextes contiennent des unités d'information (texte, image\ldots{}) reliées les unes aux autres par des hyperliens (Figure~\ref{fig:hypertext-0}). L'hypertexte est donc tout autant un système d'organisation de documents qu'un principe de navigation dans un espace numérique. En effet, un utilisateur peut cheminer d'une ressource à l'autre, depuis un terminal informatique, en suivant de manière non linéaire les liens de son choix. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-4}
  \caption{Communication HTTP entre un client et un serveur sur le Web}
  \label{fig:arpanet-4}
\end{figure*} 

\noindent Ainsi, le World Wide Web (Web), tel que l'invente Berners Lee \citep{cern_document_1993}, se veut être un système d'écriture, de lecture et de partage de documents numériques sur Internet tout autant qu'un espace de navigation hypertexte. En cela, le Web est une application d'Internet\footnote{\RaggedOuter Il se développe et s'étend dans la couche applicative du réseau.} permettant à un \textbf{client} de consulter une ressource située à un point distant du réseau et mise à disposition par un \textbf{serveur}. Pour faire dialoguer clients et serveurs, le Web utilise le protocole de communication \textbf{HTTP}\footnote{\RaggedOuter De l'anglais \textit{Hypertext Transfer Protocol}, notons qu'il existe une version sécurisée de ce protocole : le https.}. Aussi, un client voulant accéder à un document en ligne, envoie une requête HTTP au serveur qui en a la charge. Sa requête est alors transférée à travers le réseau Internet, et ce, jusqu'au serveur. Si ce dernier le peut ou le veut, il donne accès à la ressource Web via l'envoie d'une réponse HTTP dédiée (Figure~\ref{fig:arpanet-4}). En pratique, l'internaute n'est pas directement considéré comme étant le client, ce rôle est attribué à son \textbf{navigateur Web}\footnote{\RaggedOuter Logiciel conçu pour naviguer sur le Web et afficher son contenu} à qui revient également la tâche de charger et d'afficher à l'écran le document à consulter. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-5}
  \caption{De la page au site Web}
  \label{fig:arpanet-5}
\end{figure*} 

Sur le Web, chaque document est identifié par une adresse unique appelée \textbf{URL}\footnote{\RaggedOuter De l'anglais \textit{Uniform Resource Locator}}. Une URL est constituée du préfix \textit{http://}\footnote{\RaggedOuter Indiquant le protocole de communication. On utilise \textit{https://} pour la version sécurisée}, suivi d'un nom de domaine indiquant le serveur web auquel le navigateur doit s'adresser. Ce nom de domaine est pourvu d'une extension (\textit{.fr, .com, .net}\ldots{}) désignant un ensemble plus large de serveurs (Figure~\ref{fig:arpanet-5}, a). Partant de là, un hyperlien est toujours construit autour de l'URL du document pointé, seule l'adresse de la cible est ainsi renseignée (Figure~\ref{fig:arpanet-5}, b).  

L'unité de consultation et de navigation de base du Web est la \textbf{page Web}\footnote{\RaggedOuter Nous discuterons des langages de programmation conçus pour représenter les pages Web en Section~\ref{sec:5_scraping}}. Aussi, nous nous tiendrons, dans la suite de ce manuscrit, à l'usage courant qui tend à assimiler tout document du Web à une page, bien que certaines images ou vidéos en ligne sont adressables par leurs propres URL. Sur ce point, chaque document du Web possède un marqueur de type, le MIME type\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Type\_de\_médias}}, indiquant plus ou moins précisément sa nature : text, image, audio\ldots{} 

Plusieurs pages peuvent être rassemblées en une seule et même entité de plus haut niveau, abstraite et arbitraire : le \textbf{site Web} (Figure~\ref{fig:arpanet-5}, c). De fait, un site est un espace hypertexte cohérent du Web, construit comme un arbre de documents partant d'une page principale (la \textit{front page}) et dont les ramifications peuvent être suivies jusqu'aux pages les plus éloignées. La forme des URL de chaque page d'un site Web peut traduire cette arborescence (Figure~\ref{fig:arpanet-5}, c).  

\subsection{Toile, silos et bulles} 

\noindent Le premier navigateur Web est développé par les équipes du CERN en 1992. Ce \textit{navigateur en ligne de commande}\footnote{\RaggedOuter \url{http://line-mode.cern.ch/}}, qui ne dispose pas encore d'interface graphique à proprement parler, permet, en entrant une URL donnée, d'accéder à une page Web et d'afficher le texte qu'elle contient. Le Web est alors considéré comme une \textbf{toile}\footnote{\RaggedOuter Traduction littérale de World Wide Web} pouvant théoriquement s'étendre dans toutes les directions de développement et formant, de fait, un réseau rhizomatique\footnote{\RaggedOuter \url{https://frama.link/zXhEvzna}} de sites et de pages sans véritable hiérarchie interne. 

Pourtant, le Web est plus structuré qu'il n'y parait. Plusieurs modèles le décrive ainsi comme une galaxie possédant, en son centre, un noyau très dense de sites Web fortement connectés les uns aux autres \citep{broder_graph_2000}. Ces sites font \textbf{autorité} car, suivant une loi de puissance\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Loi\_de\_puissance}}, ils attirent dans leur seule direction une grande partie des liens de citations émis par les autres pages \citep{barabasi_scale-free_2000}. C'est en passant par ces points centraux du réseau que l'on accède généralement aux parties les plus éloignées du Web formées, par endroit, de grappes lointaines de sites ou d'îlot de pages isolées \citep{kumar_stochastic_2000}.

Pour l'internaute, à moins de connaitre d'avance une URL à visiter, l'exploration du Web se fait en cheminant de page en page, via un navigateur. Aussi et afin d'améliorer ce processus de découverte, un nouveau type de site apparait : les moteurs de recherche. Deux d'entre eux, Lycos et Yahoo! sont lancés conjointement dès 1994 et préfigurent déjà l'arrivée d'un grand nombre de concurrents. Ce sont des registres indexant les URL de plusieurs centaines ou milliers de sites Web  que l'on peut alors parcourir. En outre, les modalités de présentation des URL sont propres à chaque moteur, qu'il s'agisse d'une liste alphabétique à dérouler ou d'un arbre thématique à parcourir.

C'est avec l'arrivée de Google, en 1998, que se dessinent de nouvelles formes de navigation basées, cette fois ci, sur le contenu des ressources à découvrir. Les méta-données, le texte puis les images des pages Web sont automatiquement analysés par les systèmes de Google, et ce, à très grande échelle \citep{brin_anatomy_1998}. L'accès à un document ne se fait plus par le choix d'une URL ou d'une suite d'URL, mais en se fiant à une liste de résultats retournés par un algorithme. Face la toile, l'internaute peut alors être vu comme un navigateur ayant à sa disposition un certains nombre d'outils conçus pour accélérer ou spécialiser ses recherches (Figure~\ref{fig:arpanet-6}, a).   

Dans la foulée, l'invention des systèmes de syndication permet à l'internaute de ne plus aller chercher l'information au hasard de sa navigation, mais de la suivre directement depuis des applications dédiées. Les Google Reader\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Google\_Reader}} et autres lecteurs de flux RSS ou Atom\footnote{\RaggedOuter Formats de données utilisés pour la syndication à du contenu Web \url{https://fr.wikipedia.org/wiki/RSS} et \url{https://fr.wikipedia.org/wiki/Atom}} agrègent les contenus publiés sur des blogs, sur des forums ou sur des sites d'actualités en un ou plusieurs canaux unifiés. Le Web n'est plus alors seulement un territoire à explorer, il se présente également comme un flux continu d'informations et de ressources à suivre. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/arpanet-6}
  \caption{Différents modes de consultation d'une information dans un réseau hypertexte (type Web)}
  \label{fig:arpanet-6}
\end{figure*} 

\noindent Poussant cette logique plus avant, la vague des réseaux sociaux Myspace (2003), Facebook (2004) ou encore Twitter (2006) cherche à installer des espaces de partages et de connections à l'intérieur même du Web, voire \textit{en marge} de celui-ci \citep{ellison_social_2007}. En effet, tout est fait pour que l'internaute consulte le Web depuis l'intérieur de ces plateformes, de manière indirecte via le contenu partagé par des amis en ligne ou par des algorithmes de recommandation. Ces réseaux sociaux deviennent alors de véritables médias alternatifs dont le modèle économique est en partie basé sur la vente d'espaces publicitaires en ligne. Ce faisant, la navigation sur le Web s'oriente de plus en plus vers des circuits fermés, l'information se découvrant et s'échangeant depuis des \textbf{silos} de données (Figure~\ref{fig:arpanet-6}, b) auxquels il faut se connecter \citep{helmond_platformization_2015}. 

Au tournant des années 2010, le Web devient mobile et peut être consulté autrement que depuis l'ordinateur du salon. Grâce au smartphone, le Web nous suit partout, tout le temps. Nous le glissons dans nos poches et il s'adapte en conséquence, la forme et le contenu des sites variant en fonction de l'appareil depuis lequel on navigue ou par rapport à la qualité de notre connexion réseau\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Site\_web\_adaptatif}}. De plus, certaines applications ou certaines plateformes de réseaux sociaux sont créées à dessein et uniquement pour être utilisées depuis un téléphone portable ou via l'écran d'une télévision. Ainsi, le Web se personnalise, il apprend de nous et des traces que nous déposons sur la toile. 

La plasticité du Web va alors grandissante à mesure que les systèmes qui y prospèrent nous dépossèdent de nos choix de consultations. Les filtres cherchent à se faire oublier de nous. Ils sont automatiquement réajustés suivant l'évolution de nos profils en ligne et déterminés par des algorithmes toujours plus performant. Nous expérimentons tous désormais un Web différent. Il n'y a plus une seule toile, mais une multitude de versions adaptées à nos habitudes de navigation. Les résultats des moteurs de recherche ou l'information qui circule sur les pages Facebook sont personnalisés suivant chacune de nos particularités \citep{robertson_auditing_2018}. Nous cheminons maintenant sur le Web enfermés dans des \textbf{bulles} de filtrage (Figure~\ref{fig:arpanet-6}, c) façonnées à notre image \citep{gillani_me_2018}.

\section{Dispersés mais présents sur la toile}
\label{sec:2_migrant}

\noindent Lors de la leçon inaugurale\footnote{\RaggedOuter Voir la leçon : \url{https://frama.link/CmK5e2ex}} de sa chaire \textit{Migrations et sociétés}, donnée au Collège de France en avril 2018, F. Héran choisit de rappeler, en préambule, que les migrations ont de tout temps été encrées dans nos vies. Par delà les crises et les épisodes spectaculaires qui polarisent l'attention\footnote{\RaggedOuter Voir le travail réalisé sur la base de données CALM en rapport avec la \textit{crise des réfugiés}, en Europe à l'été 2015 (Section~\ref{sec:7_calm}).}, les migrations restent et demeurent des composantes essentielles des dynamiques qui animent nos sociétés, comme nous le rappellent les faits suivants : 

Pour l'ONU\footnote{\RaggedOuter \url{https://refugeesmigrants.un.org/fr/définitions}}, le terme \textbf{migrant} désigne \og\textit{toute personne qui a résidé dans un pays étranger pendant plus d'une année, quelles que soient les causes, volontaires ou involontaires, du mouvement, et quels que soient les moyens, réguliers ou irréguliers, utilisés pour migrer}\fg{}. En Europe et plus précisément au sein de l'Union Européenne (UE), le flux de migrants est estimé selon l'INSEE\footnote{\RaggedOuter \url{https://www.insee.fr/fr/statistiques/1521331}} à près de 2,4 millions de personnes pour l'année 2015. Cet ordre de grandeur fait de l'Europe un continent important d'immigration, supérieur même à des terres historiques de migrations comme les États-Unis. 

De son côté, la France est un pays d'immigration depuis le milieu du XIXème siècle, époque où la main d'œuvre étrangère était sollicitée pour venir travailler dans l'industrie minière et ferroviaire. Aussi, durablement marquée par le passé colonial français, l'immigration hexagonale est aujourd'hui constituée à $43\%$ de personnes originaires du Maghreb et d'Afrique Subsaharienne\footnote{\RaggedOuter Projection pour l'année 2018, basée sur les statistiques 2014 de l'INSEE  \url{https://www.insee.fr/fr/statistiques/3303358?sommaire=3353488}}. En 2018, les migrants de la première génération\footnote{\RaggedOuter c.-à-d., les personnes nées à l'étranger, même naturalisées française par la suite} représentent ainsi $11\%$ de la population française, la seconde génération\footnote{\RaggedOuter Personne descendant d'un ou deux parents migrants} comptant, quant à elle, pour $13\%$ du total. De fait, un quart de la population française est aujourd'hui liée à l'immigration.

Par ailleurs, le fait économique (se déplacer pour trouver du travail) n'est plus une composante première des migrations modernes. En effet, à partir des années 70, une décorrélation s'opère entre motifs économiques (croissance/récession du pays d'accueil) et flux d'immi\-gration. De nos jours, les motifs qui poussent une personne à se déplacer sont bien plus nombreux : études, regroupement familiale, changement climatique, bouleversements politiques, fuir sous contrain\-te un pays, un régime ou tout simplement rechercher une vie meilleur.   

Mais, souvent perçues comme trop froides, les statistiques sur les migrations échouent à traduire et à transcrire l'infinie complexité de ces dispersions individuelles et collectives. Ce faisant, F. Héran clôt sa leçon en rappelant que les entretiens sociologiques, les récits de migrants et les analyses de traces (parlées, écrites\ldots{}) sont autant de contrepoints capables de venir contextualiser, densifier, critiquer ou interroger les chiffres manipulés par les démographes, les administrations et les politiques.

Aussi, cette section sera pour nous l'occasion de présenter comment de nouveaux types de traces : les traces nativement numériques et notamment celle laissées sur le Web sont devenues, depuis la fin des années 90, objets de compréhension des migrations, passant d'une science de l'absence à l'étude de multiples formes de présences.  

\subsection{Absence et Présence}

Au cours des années 70 et 80, le sociologue A. Sayad réalise plusieurs séries d'enquêtes de terrain, s'entretenant le plus souvent avec des immigrés Algériens venus travailler en France dix ou vingts ans plus tôt \citep{sayad_double_1999}. Partant de l'étude de ces récits individuels, sa méthode consiste à avancer par croisements et rapprochements successifs~: croisements de sujets interviewés, rapprochements d'époques, confrontation entre générations\ldots{} Il amène ainsi les personnes, avec qui il s'entretient, à restituer au présent des récits d'immigrations passées, révélant par la même certains regrets face aux illusions initiales de l'émigré, voire une forme de souffrance à postériori chez l'immigrant. Il met également en avant les déterminations individuelles et collectives liées à la mémoire récente de la Guerre d'Algérie et de la colonisation française, montrant, de fait, l'existence de décalages générationnels structurant les représentations et les pratiques des personnes rencontrées.  

Une distance nait ainsi au cœur de la figure de l'émigré/immigré~: une distance physique, sentimentale, familiale et spirituelle vis-à-vis de son pays d'origine d'une part et une distance culturelle, linguistique, religieuse voire sociale et politique vis-à-vis du pays d'accueil d'autre part. Le migrant est alors vu comme un déraciné, pris dans un tiraillement continu entre présence et absence :\\

\newpage

\begin{fullwidth}
\og\textit{L'émigration, pour ne pas être pure "absence", appelle une manière d'ubiquité impossible, une manière d'être qui affecte les modalités de l'absence qu'elle entraîne (de même qu'elle affecte les modalités de la présence par laquelle se matérialise l'immigration) : continuer à "être présent en dépit de l'absence", à être "présent même absent et même là où on est absent" --- ce qui revient à "n'être que partiellement absent là où on est absent" --- c'est le sort ou le paradoxe de l'émigré --- et, corrélativement, à "ne pas être totalement présent là où on est présent, ce qui revient à être absent en dépit de la présence", à être "absent (partiellement) même présent et même là  où on est présent" --- c'est la condition ou le paradoxe de l'immigré. Le risque pour l'émigré et pour l'immigré qu'il est aussi est  que  ces  formes  incomplètes  d'absence  et  de  présence  finissent,  tôt  ou  tard,  par  s'accomplir intégralement : la présence "physique" et seulement physique de l'immigré finira par devenir une présence "morale" aussi (par le corps et par l'esprit ; par l'actuel et par le futur ; par le travail et par l'engendrement, c'est-à-dire le sang; par le fait et par le droit) ; corrélativement, l'absence matérielle et seulement matérielle de l'émigré finira par devenir une absence "morale" (et "spirituelle"), une absence consommée, une rupture accomplie avec la communauté.}\fg{} --- \citep[p.225-226]{sayad_double_1999}\\
\end{fullwidth}

\noindent Pourtant, les derniers travaux de Sayad, à la fin des années 80, révèlent déjà les prémisses d'un changement à venir. De nouvelles formes de présences à distance, qu'il détecte dans l'\textit{usage inattendu de l'enre\-gistrement sur magnétophone} \citep{sayad_du_1985}, permettent d'entretenir un lien discontinu entre deux personnes. Ainsi, décryptant l'envoie de messages sur cassettes magnétiques entre une mère et son jeune fils émigré, Sayad note cette phrase prononcée par la mère :\\

\begin{fullwidth}
\og\textit{Ah ! Celle-là [la mallette contenant le magnétophone], c'est ma consolation ! Elle me cautérise (les plaies). Depuis qu'on a inventé ces caissettes, si je pouvais je ne m'en séparerais jamais. Je leur parle comme je te parle, comme je vous parle à tous, comme s'il était là devant moi.}\fg{} --- \citep[p.12]{sayad_du_1985}\\
\end{fullwidth}

\noindent La technique commence alors à rendre possible l'ubiquité recherchée par le migrant. En effet, dans les années 90, le perfectionnement et la démocratisation des Technologies de l'Information et de la Communication (TIC) révolutionnent notre rapport à l'espace, au temps et aux frontières. Les téléphones portables, les systèmes de messagerie électroniques et le Web naissant deviennent rapidement, dans les mains des personnes migrantes, des outils de communication et d'organisation individuelle ou collective. 

D'un point de vue épistémologique, l'usage des TIC s'installe comme un nouvel angle d'analyse possible des migrations, voire comme une composante essentielle de la figure moderne du \textbf{migrant connecté} \citep{diminescu_connected_2008}. Suivant les analyses de D. Diminescu, l'image du déraciné est à repenser :\\

\begin{fullwidth}
\og\textit{un autre principe organisateur émerge : mobilité et connectivité forment désormais un ensemble de base dans la définition du migrant du XXI siècle. Ensemble ils agissent comme un vecteur qui assure et conduit les lignes de continuité dans la vie des migrants et dans les rapports que ceux-ci entretiennent avec leur environnement d’origine, d’accueil ou parcouru. Hier : immigrer et couper les racines ; aujourd’hui : circuler et garder le contact. Cette évolution semble marquer un nouvel âge dans l’histoire des migrations : l’âge du migrant connecté}\fg{} --- \citep[p.3]{diminescu_connected_2008}\\
\end{fullwidth}

\noindent Le migrant s'inscrit désormais dans une culture de liens qu'il construit lui même et qu'il entretient dans sa mobilité (géographique, sociale, sur les réseaux\ldots{}). Il se déplace, noue des alliances à l'extérieur de sa communauté mais sans pour autant se détacher de cette dernière, la somme des liens virtuels permettant d'être toujours présent à distance, ici ou là bas. Réactivables, ces liens s'inscrivent dans une dynamique faite de ruptures et de moments de continuité qu'il nous faut apprendre à analyser. 

Ainsi, ces nouvelles formes de présences à distance font rapidement l'objet de recherches dédiées \citep{diminescu_les_2002}. Les traces qu'elles génèrent, de par les systèmes techniques sur lesquels elles s'appuient ou via les modalités de stockage qu'elles induisent, engendrent une hybridation scientifique. Des projets pionniers et interdisciplinaires sont alors mis en place dans les années 2000, alliant de fait, méthodes d'analyses sociologiques et techniques d'exploration informatiques. 

\subsection{Des traces nativement numériques}

\noindent Les pratiques communicationnelles des migrants, portées et accentuées par l'usage des TIC, forment de vastes corpus de données à explorer. Captées directement depuis des flux d'informations \textit{live} ou récupérées après coup dans des systèmes de stockage, ces données peuvent aider à comprendre le fonctionnement de certains réseaux transnationaux, tels que des systèmes de transfère d'argent par téléphone portable \citep{bounie_analyse_2010}, ou encore servir à mesurer l'inté\-gration des migrants dans les pays d'accueil. Ce sont également des vecteurs de compréhension des modalités de surveillance déployés par les institutions pour contrôler les étrangers \citep{amoore_biometric_2006}. Nous pouvons enfin nous servir de ces traces pour reconstituer le parcours individuel d'une personne passant d'une frontière à l'autre, à la manière d'un journal de bord, et ce, en supplément d'une série d'entretiens \citep{diminescu_traces_2016}.

Définies, structurées et finement datées par des systèmes informatiques et automatiques, ces traces témoignent du quotidien des migrations ou de grands événements polarisants. Ce sont des empreintes \citep{rogers_end_2009} qui peuvent être déposées en conscience sur la toile (un message sur un blog), arrachées de forces et inscrites dans une base de données (au passage d'une frontière) ou encore dérobées par divers systèmes espions et capteurs à l'insu des personnes concernées (vidéo surveillance). \textbf{Nativement numériques}, certaines de ces traces sont produites exclusivement par et depuis les TIC, ne devant ainsi pas être confondues avec d'autres formes de traces numérisées à postériori (textes et images scannés, transcription au format numérique de documents historiques passés\ldots{}) et qui sont, l'apanage du champ plus large des Humanités Numériques\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Humanités_numériques}}. Le présent manuscrit est quasi-exclusivement concerné par l'exploration de ces traces dites nativement numériques. Aussi, plutôt que de réévaluer et de mettre à jour des méthodes de recherche existantes, ces traces nécessitent le développement d'outils conceptuels et méthodologiques nouveaux\footnote{\RaggedOuter Voir, par exemple, les outils d'analyse développés par les équipes du MédiaLab \url{http://tools.medialab.sciences-po.fr/} ou de DMI \url{https://wiki.digitalmethods.net/Dmi/ToolDatabase}}, à la frontière entre sociologie et ingénierie \citep{barats_manuel_2016}. 

À titre d'exemples, travailler sur ce type de traces revient à analyser des séries de mails, des conversations en ligne via des systèmes de chat \citep{dekker_smart_2018}, la couverture d'un territoire par un réseau mobile \citep{sanchez-querubin_connected_2018}, des échanges vidéos en direct\footnote{\RaggedOuter Voir le projet Ubi-screen réalisé par I. Grosse \url{http://www.isabellegrosse.net/ubiscreen/}}, des traces GPS d'embarcations \citep{heller__2014}, des messages vocaux postés sur Telegram\footnote{\RaggedOuter Utilisation de l'application Telegram (\url{https://telegram.org/}), voir \url{https://frama.link/JnjBqw8u}}, ou encore des \textit{selfies} partagés sur Instagram \citep{risam_now_2018}, etc. 

\subsection{Être ensemble sur le Web}

\noindent Au début des années 2000, le Web est déjà pourvoyeur d'une grande partie des traces numériques sur lesquelles peuvent être menées des investigations.  Sites et pages Web \citep{tyner_pan-national_2000}, blogs \citep{park_developing_2008}, forums en ligne \citep{van_den_bos_territorial_2006} et autres bases de données sont autant de documents succeptibles de faire l'objet de recherches. Ce faisant, le groupe de travail TIC-Migration, coordonné par D. Diminescu, se constitue dans le but d'analyser certains sites Web retenus pour leurs liens directs avec les migrations. En effet, ces nouveaux supports d'information commencent à devenir des formes de représentation à part entière pour les communautés dispersées. 

Pour S. Dufoix, le terme \textbf{diaspora} renvoie à l'idée de dispersion d'un peuple ou d'une communauté à travers le monde. Mais, il peut également désigner les multiples formes d'organisations et de représentations (ethniques, nationales ou religieuses) de ces même communautés \citep{dufoix_les_2003}. Ainsi, toute diaspora cherche à maintenir une mémoire collective, pour créer des repères et un imaginaire commun \citep{bernal_diaspora_2006}. Et s'il faut essayer de demeurer ensemble malgré la distance, cela passe souvent par la création d'espaces (physiques, en ligne, sur papier, par la musique\ldots{}) et de moments dédiés à l'animation de la communauté. On y évoque d'égale manière les grands bouleversements historiques et les petits événements du quotidien \citep{koukoutsaki-monnier_deterritorialising_2012} qui jalonnent la vie du groupe. 

De fait, les sites Web deviennent progressivement de nouveaux points de rencontres à distance, où chaque communauté décide de son mode de communication privilégié (par vidéo pour les tziganes, par messages vocaux pour les kabyles\ldots{}). De natures variables, ces espaces en ligne prennent la forme de carrefours où l'on se croisent, de vitrines pour l'histoire de la communauté \citep{whitaker_tamilnet._2004}, de lieux de reconstruction et de partage de repères communs \citep{sabancioglu_new_2011}, ou encore de porte-voix au service de revendications politiques \citep{kumar_rerouting_2018}.

Combinant leurs analyses, les premiers travaux des chercheurs du groupe TIC-Migration apportent rapidement de nouvelles pistes de réflexion \citep{laflaquiere_archiver_2005}. Selon C. Scopi \citep{scopsi_les_2009}, certains sites Web\footnote{\RaggedOuter \textit{mondeberbere.com}, \textit{originesvietnam.com}\ldots{}} sont crées autour de valeurs culturelles communes et maintenus exclusivement par des communautés en ligne de migrants, tels que les RME (Ressortissants Marocains de l'Étranger) ou les Viet Keu (Vietnamien de l'étranger). L'analyse de sites communautaires bulgares, menée par R. Soultanova, révèle pour sa part la transformation progressive de sites personnels de migrants\footnote{\RaggedOuter \textit{bgcanada.com}} en véritables portails ouverts sur la diaspora et fédérant un collectif régulier d'utilisateurs.  Pour S. Gangloff, le Web peut aussi servir de point d'appui\footnote{\RaggedOuter \textit{info-turk.be}, \textit{bleublancturc.com}\ldots{}}, afin de sensibiliser l'opinion publique sur le devenir des ressortissants turques de l'étranger. De son côté, T. Guignard voit, dans les messages postés sur des sites sénégalais\footnote{\RaggedOuter \textit{homeview.sn}, \textit{lesoleil.sn}\ldots{}}, un nouvel espace d'échange nord/sud, les membres de la diaspora sénégalaise souhaitant, grâce au Web, renouer avec leur culture d'origine. 

Le profil des migrants faisant vivre quotidiennement les diasporas en ligne peut aussi faire l'objet d'études. En effet, la mise en place et la maintenance de ces sites appellent (tout au moins dans les premières années du Web) un important baguage technique, comme le décrit M. Nedelcu en documentant la création du portail roumain \textit{thebans.com} par un jeune ingénieur émigré au Canada \citep{nedelcu_e-communautarisme_2003}. Enfin, la toile devient parfois un outil militant, servant à organiser une action ou à maintenir vivace le souvenir d'une lutte. Sur ce point, le site \textit{pajol}\footnote{\RaggedOuter \url{http://www.bok.net/pajol/index2.html}} fait figure de précurseur. Crée en 1996, il retrace l'histoire de l'occupation de l'église Saint-Bernard à Paris par le mouvement des sans-papiers, et ce, jusqu'à leur expulsion par les forces de l'ordre en août de la même année\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Mouvement_des_sans-papiers_à_Paris_en_1996}}.

Pris indépendamment les uns des autres, ces sites ont tous un élément ou une information importante à nous révéler. Pourtant, le Web peut aussi s'appréhender à une échelle plus large et bien plus complexe, faite de rapports de forces, de rapprochements et d'éloignements, d'amitié et d'ignorance. Car le Web est une toile et les formes de représentations en ligne des diasporas n'échappent pas à la tentation de faire réseau. Bien au contraire, les sites migrants se connectent les uns aux autres, via des liens de citation hypertextes et forment ainsi les nouveaux territoires de la dispersion. Pour les explorer, le collectif TIC-Migration s'agrandit et se lance, à la fin de années 2000, dans une campagne de cartographie de plusieurs milliers de sites migrants, aujourd'hui réunis au sein de l'Atlas e-Diaspora.  

\section{L'Atlas e-Diasporas : Cartographier les sites migrants}
\label{sec:2_atlas}

\noindent Dirigé par D. Diminescu et développé par M. Jacomy à la R\&D, l'Atlas e-Diasporas est un effort collectif de recensement, de cartographie et d'analyse de sites Web migrants \citep{diminescu_e-diasporas_2012}.

Un \textbf{site Web migrant} est un site crée ou maintenu par une ou plusieurs personnes migrantes et/ou qui est en lien direct avec ces dernières. De manière plus générale, diaspora et/ou migration doivent être des composantes essentielles de ces sites. Cela peut être un site personnel, un blog, le site d'une association, un portail ou un forum, un site institutionnel ou toute autre support de contenu Web similaire. L'usage de ces sites par des migrants n'est pas un critère de sélection. En effet, un site consulté par un migrant (un média, un réseau social\ldots{}) n'est pas nécessairement un site migrant. De fait, la prise en compte du caractère \textit{migrant} d'un site s'appuie, d'abord avant tout, sur le contenu de ce dernier et sur sa production de liens de citations. Enfin, un site migrant n'est pas obligatoirement localisé dans un pays étranger\footnote{\RaggedOuter Sur la question de localisation d'un site, voir la discussion en Section~\ref{sec:6_blogs}.}, il peut également être hébergé depuis le pays d'origine de son fondateur. 

Actant l'existence de nouvelles formes de représentations en ligne des diasporas et s'appuyant sur la démocratisation du Web au grand public\footnote{\RaggedOuter Le passage du Web 1.0 au Web 2.0, avec l'apparition des blogs et des réseaux sociaux, fait du Web un espace accessible à des personnes peu ou pas spécialistes des TIC.}, l'Atlas agrège les travaux conjoints de plus de 80 chercheurs, ingénieurs et designers dispersés dans le monde. Ce faisant et après plusieurs années de recherches, ce sont plus de 9000 sites Web qui se voient ainsi documentés et répartis dans pas moins de 30 e-Diasporas\footnote{\RaggedOuter Voir la liste complète \url{http://www.e-diasporas.fr/\#workingpapers}}.

L'\textbf{e-Diaspora} est l'analogie rapportée au Web de la notion classique de diaspora, soit des personnes issues d'un.e même culture/territoire, dispersées de par le monde, mais maintenant malgré tout des liens, faisant réseau. Une e-Diaspora est un collectif migrant qui s'organise, d'abord et avant tout, sur le Web, une communauté dont les pratiques sont déterminées et portées par les possibilités d'interactions numériques qu'offre le Web. Une e-Diaspora est un collectif dispersé, hétérogène et instable, sa forme changeant chaque fois qu'un nouvel élément est intégré. Les grandes directions de son développement ne sont pas figées, mais reconfigurées à mesure que le collectif évolue. Ces transformations sont le fait de processus individuel et non collectifs, un nouveau membre est intégré ou s'intègre à la l'e-Diaspora en ajoutant ou en supprimant un simple lien de citation hypertexte sur son site. 

En effet, d'un point de vue pratique, une e-Diaspora est un réseau dirigé de sites Web, liés les uns aux autres par des liens de citations hypertextes. Le sens de ces liens a une importance puisque qu'il permet, en partie, de déterminer le rôle joué par un individu dans la communauté : un site établi de longue date et faisant autorité dans le collectif sera pointé par nombre de membres (Figure~\ref{fig:edia-1}, a); au contraire, un site cherchant à s'intégrer à une e-Diaspora commencera par citer des membres existants (Figure~\ref{fig:edia-1}, b) dans l'idée de se faire reconnaitre, accepter\ldots{} Selon le point de l'observateur, un lien hypertexte sera soit considéré comme \textbf{sortant} (il est émit par le site témoin) ou comme \textbf{entrant} (il pointe le site témoin depuis un autre site). 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/edia-1}
  \vspace*{0.2cm}  
  \caption{Exemple de réseau dirigé, (a) fait autorité, (b) cherche à intégrer la communauté}
  \label{fig:edia-1}
\end{marginfigure}  

Cette manière d'analyser la valeur d'un lien de citation permet de définir les contours d'une géopolitique de l'hypertexte \citep{rogers_national_2013}, les e-Diasporas étant à la fois \textit{online} et \textit{offline}. Aussi, ce que nous voyons sur le Web peut, tout à fait, être le reflet d'une situation qui trouve ses origines hors ligne. L'analyse des différentes e-Diasporas trace des pont entre le Web et le réel. Chaque e-Diaspora doit être étudiée tout autant au regard de ce qu'elle est en ligne (c.-à-d., un réseau de sites Web), que vis-à-vis des connaissances accumulées sur la diaspora hors ligne et dont elle est le pendant numérique.    

\subsection{Outils et Méthodologie}

\noindent Explorer, documenter, cartographier et visualiser un tel corpus de sites migrants nécessite le développement d'outils dédiés à chacune de ces tâches. Pour ce faire, les ingénieurs et les chercheurs investis dans la création de l'Atlas définissent ensemble une chaîne inédite d'analyse socio-technique (Figure~\ref{fig:edia-2}).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/edia-2}
  \caption{Chaîne d'analyse socio-technique de l'Atlas e-Diasporas (source~: M. Jacomy)}
  \label{fig:edia-2}
\end{figure*} 

\noindent À chaque e-Diaspora est d'abord assigné un chercheur spécialiste des communautés concernées (un sociologue, un historien\ldots{}), sa tâche initiale consistant à \textbf{explorer} le Web afin de sélectionner un premier ensemble de sites migrants. L'unité de base de toute exploration est donc le site Web, et non la page ou tout autre ressource postée sur la toile. Ce faisant, le chercheur se sert de son expertise et de ses connaissances du terrain pour identifier les \textbf{sites sources} depuis lesquels il constitue petit à petit son corpus. Partant de ces sites sources, le chercheur utilise le logiciel Navicrawler\footnote{\RaggedOuter Outil de collecte de sites Web, présenté comme une extension au navigateur Firefox (\url{https://frama.link/q3HWA2JU})} pour cheminer à travers le Web, en suivant les liens de citations sortants et en sélectionnant à la volée ce qu'ils considèrent être des sites migrants.  

Une fois satisfait de son corpus, lorsque son exploration converge enfin, le chercheur exporte sa collecte dans le logiciel de visualisation de graphes Gephi\footnote{\RaggedOuter Outil open-source de spatialisation et d'analyse de graphes, développé par M. Bastian, M. Jacomy, J. Blicke et S. Heymann \url{https://gephi.org/}}. Là le réseau est spatialisé (une place est attribuée dans l'espace à chaque site) et un système de détection de communautés est appliqué\footnote{\RaggedOuter Voir la Section~\ref{sec:6_printemps} pour une discussion sur la détection de communautés dans Gephi}. Mais, ajoutons que durant l'exploration du Web avec Navicrawler, le chercheur peut, s'il le souhaite, ajouter une ou plusieurs catégories aux sites visités (type de sites, langue, thématique\ldots{}), et ce, en se basant sur le contenu affiché à l'écran. 

Aussi, le passage par Gephi est l'occasion d'affiner cette première \textbf{catégorisation} et de la questionner au regard de la spatialisation du réseau et des communautés de sites détectées. Ce faisant et au terme de cette étape, chaque corpus est ainsi constitué d'un ensemble de sites migrants et de liens de citations enrichis par le savoir du chercheur et les indices révélés par les différents logiciels utilisés.  

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/edia-3}
  \caption{Annotation de l'e-Diaspora des étudiants Marocains sur Facebook, par S. Marchandise \citep{marchandise_facebook_2014}}
  \label{fig:edia-3}
\end{figure*}   

\noindent À ce niveau, les corpus sont confiés à la société Linkfluence\footnote{\RaggedOuter \url{https://linkfluence.com/fr/}} qui réalise une \textbf{collecte} large et automatique du Web afin de consolider la forme et la structure des futures e-Diasporas. Il s'agit également de détecter et de capturer les \textbf{sites frontières}. En effet, ces sites ne sont pas directement rattachés à une e-Diaspora (c.-à-d., sélectionnés par un chercheur), mais peuvent permettre d'enrichir la compréhension du réseau par la connaissance de son voisinage direct. 

Les réseaux de sites sont, ensuite, \textbf{visualisés} sur la plateforme en ligne de l'Atlas\footnote{\RaggedOuter \url{http://www.e-diasporas.fr/}}. Par convention, les e-Diasporas sont visualisées sous la forme de graphes dans lesquels les sites Web sont représentés par des cercles pleins et les liens de citations sont figurés par des lignes (fléchées ou non). 

S'ensuit l'étape de \textbf{validation} qui marque le moment important où cher\-cheurs et ingénieurs se confrontent aux réseaux, les annotent, les corrigent et commencent à s'en servir comme outil de travail sur le terrain. Car une e-Diaspora (comme toute forme de visualisation) n'est pas une fin en soi, mais un moyen d'enrichir et de questionner, par le prisme du Web, notre connaissance des communautés concernées. C'est là tout le caractère inédit de la méthodologie développée pour l'Atlas : faire des allers-retours constants entre données du Web et savoir des chercheurs, entre traitements automatiques et validations manuelles. Il s'agit, à tout moment, de pouvoir revenir à l'étude de la dimension sociale des traces observées.   

\subsection{Résultats et Interprétations}

\noindent Chaque e-Diaspora peut être analysée suivant deux grands niveaux de lecture : \textbf{1)} le niveau topographique nous permet de considérer les connexions et les proximités entre les acteurs cartographiés. Certains réseaux se présentent ainsi comme un ensemble de grappes d'entités dispersées (e-Diaspora indienne, Figure~\ref{fig:edia-4}, b), là où d'autres (e-Diaspora palestinienne, Figure~\ref{fig:edia-4}, a) restent centrés autour de sites faisant autorité \citep{ben-david_palestinian_2012}; \textbf{2)} le niveau quantitatif/qualitatif est une restitution des informations obtenues lors de l'exploration des sites par les chercheurs et lors de confrontations avec leurs travaux sur le terrain. Ce niveau regroupent toutes les connaissances venues enrichir la constitution des réseaux.

Les différentes parties de l'Atlas sont à l'image de leurs diasporas de rattachement. Les réseaux permettent de saisir la complexité de la dispersion de chaque communauté, tout autant que leur formes particulières de représentation et d'organisation en ligne. Les e-Diasporas brossent ainsi un portrait singulier du Web et de sa prise en main par les populations migrantes : sites Web, forums en ligne (e-Diaspora marocaine\footnote{\RaggedOuter \url{https://frama.link/vWpTQ3gb}}), blogs (e-Diaspora tunisienne\footnote{\RaggedOuter \url{https://frama.link/JtnjZJf0}}) et réseaux sociaux (e-Diaspora des étudiants marocains sur Facebook\footnote{\RaggedOuter \url{https://frama.link/QyjKMuqB}}) sont tous représentés, certains même depuis le début des années 90. De plus et bien que majoritairement hébergés sur des serveurs aux États-Unis, le lieu depuis lequel on alimente un site est souvent affiché de manière visible (e-Diaspora népalaise\footnote{\RaggedOuter \url{https://frama.link/FSP7-6bx}}), réinjectant de fait une dimension géographique à la lecture de ces réseaux.

Le Web devient alors un espace transnational où peuvent croitre des imaginaires collectifs jouant, parfois, un rôle performatif pour certaines diasporas en formation \citep{brusle_les_2012}. Lire une e-Diaspora permet également de comprendre les relations qu'entretiennent les émigrés avec leur pays d'origine et en particulier la proximité entre sites d'expatriés et sites étatiques. Dans le cas de l'e-Diaspora française\footnote{\RaggedOuter \url{https://frama.link/_K718ZHp}}, ces liens sont forts et réciproques \citep{berthomiere_french_2013}, contrairement à l'e-Diaspora mexicaine\footnote{\RaggedOuter \url{https://frama.link/JyWsTG1V}} où la connexion ne se fait que dans un sens (de l'état vers la diaspora). Une lecture plus fine peut enfin être engagée en associant des sites à des communautés régionales ou religieuses comme le propose E. Leclerc pour la e-Diaspora indienne \citep{leclerc_cyberespace_2012} révélant, par la spatialisation du réseau, des tensions réelles entre chaque groupe d'activistes. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/edia-4}
  \caption{L'e-Diaspora palestinienne (a, par A. Ben-David) et l'e-Diaspora indienne (b, par E. Leclerc)}
  \label{fig:edia-4}
\end{figure*} 

\noindent Pour terminer, rappelons que toute e-Diaspora est forgée en premier lieu par un chercheur et par sa connaissance personnelle du terrain. Ce faisant, il pourrait être légitime de remettre en cause la partialité et la subjectivité des réseaux résultants. Néanmoins, en comparant deux corpus palestiniens\footnote{\RaggedOuter e-Diaspora palestinienne n°1 : \url{https://frama.link/Qr3MbQe3},e-Diaspora palestinienne n°2 : \url{https://frama.link/6jXd-ndV}}, réalisés en parallèle par deux chercheurs différents, on se rend compte que ces derniers se recoupent et se recroisent en grande partie. 

Les chercheurs sont essentiels à la constitution de l'Atlas, car toute l'analyse ne peux pas être déléguée aux machines et aux traitements automatiques. À titre d'exemple, nous savons que le Web est un mélange d'éléments textuels, audios, vidéos ou logiciels. Or, il peut arriver que certains indices clés d'une analyse ne soient disponibles qu'à travers des images ou des bannières. Aussi, sachant que le traitement automatique de ces dernières est très couteux \citep{ben-david_colors_2018} et que certaines communautés utilisent énormément d'éléments visuels sur leurs sites, l'interprétation humaine doit rester au cœur de la chaîne méthodologique.

\subsection{L'e-Diaspora marocaine}

\noindent Dans la suite de cette thèse, nous nous intéresserons plus particulièrement à l'e-Diaspora marocaine\footnote{\RaggedOuter http://www.e-diasporas.fr/wp/moroccan.html} et à son corpus de sites et de blogs, sélectionnés par D. Diminescu et M. Renault en 2008. Support de nos explorations à venir, l'e-Diaspora marocaine présente plusieurs avantages permettant de l'intégrer facilement comme base de travail. Tout d'abord, nous conservons une proximité directe avec les chercheurs ayant cartographié ce réseau, pouvoir échanger régulièrement sur la base d'hypothèses ou de résultats étant un avantage non négligeable. Par ailleurs, lors de la cartographie initiale des sites, D. Diminescu et M. Renault avaient établis des contacts avec les créateurs de certains blogs marocain. Il pourrait, par exemple, être intéressant de réactiver ces connexions pour de futurs entretiens.  

L'e-Diaspora marocaine a, ensuite, la particularité d'agréger un grand nombre de sites Web écrits en français. Bien que nous prévoyons un certains nombre de traitements automatiques (applicables à un large panel de langues), il ne faut pas négliger la part importante de travail manuel à réaliser. Être locuteur de la langue d'un site reste donc un avantage. Enfin, cette e-Diaspora peut faire l'objet d'une lecture topographique relativement claire, présentant différents espaces et différentes communautés de sites, amenant chacun et chacune vers plusieurs pistes de réflexion. 

Le corpus marocain est composé de 156 sites Web et de 397 liens de citations hypertextes. Majoritairement écrits en français et en anglais, les sites se répartissent en trois grandes catégories : \textbf{1)} sites d'associa\-tions et d'ONG (50 sites), \textbf{2)} blogs (47 sites), \textbf{3)} sites institutionnels (22 sites). Leurs thématiques sont diverses et variées, mélangeant développement, citoyenneté et politique ou encore sujets intimistes et billets d'hum\-eur (voir la Figure~\ref{fig:edia-5} pour un comptage complet).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/edia-5}
  \caption{Répartition des sites de l'e-Diaspora marocaine par catégorie, sous-catégorie et langue principale (source : Atlas e-Diaspora \url{https://frama.link/Pyt3Aq2x})}
  \label{fig:edia-5}
\end{figure*} 

\noindent La Figure~\ref{fig:edia-6} représente la carte de l'e-Diaspora marocaine sous la forme d'un graphe : les nœuds sont les sites, les arcs sont les liens hypertextes et la taille des nœuds est proportionnelle au degré de chaque site\footnote{\RaggedOuter Le degré peut ici être compris comme une mesure d'importance. Voir la Figure~\ref{fig:degree} et la Section~\ref{sec:3_constituer} pour une explication plus détaillée de la notion de degré}. D'un point de vue de la topologie du réseau et de sa seule structure, nous pouvons observer un premier groupe de sites (Figure~\ref{fig:edia-6}, a), non liés entre eux et très isolés du reste du graphe. Ce sont principalement des sites d'associations qui, au regard de leur production de liens de citations, semblent s'ignorer mutuellement. Ce faisant, la carte commence à nous interroger et à tracer des hypothèse entre le Web et le réel. Cette méconnaissance entre sites associatifs est elle uniquement visible sur le Web ou peut elle être vérifiée sur le terrain ? Pourquoi les associations refuseraient-elles de faire collectif ? 

Deux autres groupes de sites sont également très clairement visibles (Figure~\ref{fig:edia-6}, b \& c), mais présentent un profil différent. Très fortement liés entre eux, chacune de ces communautés de site semble en revanche détachée du reste du graphe, toujours un peu à l'écart. Le premier groupe (Figure~\ref{fig:edia-6}, b) est ainsi composé de sites institutionnels (consulats, ambassades\ldots{}), formant un ensemble dense et homogène. Mais, théoriquement construits par l'État marocain à destination de ses ressortissants vivant à l'étranger, il est frappant de voir que ces sites ne sont pas très bien connectés au reste du réseau et encore moins à la seconde communauté de sites. En effet, ce dernier ensemble (Figure~\ref{fig:edia-6}, c) témoigne tout particulièrement de la présence en ligne des migrants marocains, puisqu'il est principalement constitué de blogs personnels d'émigrés. 

Les sites institutionnels donnent, ainsi, l'impression d'échouer dans leur volonté (pourtant affichée) de structurer et d'organiser la vie de la diaspora, en polarisant l'attention autour d'eux (tout au moins sur le Web). Ils ne sont pas centraux, et malheureusement pour eux, ce rôle est déjà occupé deux autres sites (Figure~\ref{fig:edia-6}, points rouges), faisant le pont entre chacun des trois groupes de l'e-Diaspora marocaine. Cet état de fait est-il nouveau, peut être que ces sites viennent tout juste de s'installer ? L'État marocain est-il au courant de cette situation ? Pourquoi les blogs ne se connectent pas aux sites institutionnels, est-ce de l'ignorance, voire de l'indifférence ou est-ce fait en conscience~?    

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/edia-6}
  \caption{Cartographie de l'e-Diaspora marocaine (Par D. Diminescu \& M. Renault)}
  \label{fig:edia-6}
\end{figure*} 


\noindent De leur cotés, les sites \textit{yabiladi.com} et \textit{bladi.net} occupent une position d'autorité étant, de fait, plutôt bien cités. Ce sont des portails communautaires, bien établis dans l'écosystème et dans l'histoire longue de l'e-Diaspora marocaine\footnote{\RaggedOuter Le site \textit{yabiladi.com} et le groupe de blogs migrants feront l'objet d'explorations dédiées au Chapitre~\ref{chap:6} de cette thèse.}. Leurs forums en ligne attirent notamment plusieurs centaines de visiteurs chaque jours. Enfin, l'utilisation de la langue anglaise permet de faire un dernier lien\footnote{\RaggedOuter Voir la carte de la distribution des sites par langue \url{https://frama.link/2hFDT02Q}} entre les groupes institutionnels et l'ensemble des blogs, plusieurs sites anglophones étant ainsi situés autour de \textit{bladi.net}

\begin{center}
	\textbf{***}
\end{center}

\noindent Ces premières interrogations ne sont que des exemples pris parmi l'ensemble des problématiques soulevées par l'Atlas. Chaque nouvelle observation attentive d'une e-Diaspora amenant son lot de pistes à explorer, soit qu'elles portent sur une dimension singulière d'une population migrante, soit qu'elles interrogent plus largement le Web en tant qu'écosystème. Par exemple, les communautés de sites, révélées par l'e-Diaspora marocaine, suivent-elles un comportement particulier à ce seul réseau ? Ou peut-on dire que la forte connectivité des blogs entre eux est un fait général du Web ? 

Aussi, les e-Diasporas doivent être comprises et analysées vis-à-vis de trois aspects : \textbf{1)} le Web et ses règles propres, \textbf{2)} les connaissances rassemblées en amont et en lien avec la diaspora concernées, \textbf{3)} les retours et les confrontations à postériori avec le terrain sociologique ou historique. Mais, une grande famille de questions semble pourtant difficile à adresser, et ce, partant uniquement des e-Diasporas telles que nous les avons présentées. Comment prendre en compte le temps long, l'éphémère, les dynamiques et autres événements dans l'analyse de ces réseaux ? 

Car les e-Diasporas ne sont, au final, que des images fixes, des captures instantanées d'une petite partie du Web. Or, les pages et les sites évoluent et se transforment en continue, rendant rapidement obsolètes les cartes réalisées pour l'Atlas. Ainsi, lorsqu'après dix années d'attente, nous revenons enfin visiter chacun des sites collectés, force est de constater qu'une grande majorité d'entre eux ont disparu, ont été effacés ou ne sont plus ce qu'ils étaient.

Mais à la fin des années 2000, anticipant le caractère éphémère du Web, les chercheurs coordonnant les travaux de l'Atlas décident d'ajouter une dernière brique à leur chaîne méthodologique (Figure~\ref{fig:edia-2}) : l'\textbf{archivage}. Afin de préserver la tenue de recherches futures, portant sur l'histoire et l'évolution de chacune des e-Diasporas, une campagne d'archivage des sites cartographiés est lancée en 2010. Ce faisant, cette thèse et les chapitres à venir auront pour principal objet l'exploration au présent des archives Web de l'Atlas e-Diasporas.     

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\begin{minipage}[t,leftmargin=5em]{1.5\linewidth}%
\begin{adjustwidth}{-0.5cm}{}
\chapter{Préserver le Web et les e-Diasporas}
\label{chap:3}
\end{adjustwidth}
\end{minipage}
\hfill

\noindent Face à la disparition totale ou partielle des sites Web recensés par l'atlas e-Diasporas (Section~\ref{sec:2_atlas}), il a rapidement été décidé de mettre à l'abri cet héritage numérique. De le préserver. Aussi et dès mars 2010, se met en place, sous la responsabilité technique des équipes de l'Institut Nationale de l'Audiovisuelle (INA), une vaste campagne d'archivage des quelques 9000 sites migrants alors cartographiés. Ces archives Web, aujourd'hui constituées\footnote{\RaggedOuter L'archivage s'est officiellement terminé en septembre 2014.}, peuvent enfin faire l'objet de recherches et d'explorations. Grâce à ce travail d'archivage, nous pouvons questionner au présent les traces du Web passé. 

Mais de part la nature même du médium, le Web appelle la mise en place d'un archivage particulier, basé sur des techniques de collectage dédiées. Comment archiver ce qui est, tout autant, un flux continu d'informations qu'un territoire en perpétuelle expansion ? Quels compromis ont du faire les archivistes pour garantir une collecte représentative ? Jusqu'à quel point les archives du Web passé sont-elles fidèles au Web vivant ? 

Dans ce chapitre, nous prendrons le point de vue des archivistes. Nous évoquerons la genèse de l'archivage du Web qui, au tournant des années 2000, a connu un essor mondial, mobilisant nombre d'acteurs et d'institutions. En effet, ces diverses initiatives capturent et stockent, jour après jour, plusieurs centaines de milliers de pages Web. Par exemple, Internet Archive a réalisée, depuis son lancement en 1996, près de 650~000~000~000 captures d'objets Web (pages, images, vidéos, etc.), cela pour un total de 40~Po d'archives. Mais la réussite écrasante d'Internet Archive ne cache-elle pas un mouvement en perte de vitesse ? Qu'en est-il dans le reste du monde ? Où en sont les travaux de recherche portant directement sur les archives Web ?

Pour comprendre la manière avec laquelle ces archives sont constituées, nous introduirons ensuite les principales méthodes de sélection, collecte et stockage des corpus à préserver. Nous présenterons, enfin, les contours des archives e-Diaspo\-ras à proprement parler. Leurs particularités et leurs caractéristiques. Leur durée et leur étendue.

Bien que cette thèse se concentre sur l'exploration d'archives Web déjà existantes, il nous semble important d'évoquer la façon dont ces dernières sont constituées en amont afin de mieux saisir les biais analytiques (Chapitre~\ref{chap:4}) qui motiveront la présentation de notre principale contribution (au Chapitre~\ref{chap:5}). Ce faisant, les éléments que nous nous apprêtons à présenter s'appuient principalement sur la lecture de l'ouvrage de J.~Masanès : \textit{Web Archiving} \citep{masanes_web_2006} qui reste, encore aujourd'hui, une référence. Nous compléterons et mettrons à jour, au besoin, ces informations.\\

\section{Vingt ans d'archivage du Web}
\label{sec:3_20ans}

\noindent En octobre 2016 se tenait à la Bibliothèque Nationale de France (BNF) une grande conférence anniversaire réunissant, pour les 20 ans de l'archivage du Web\footnote{\RaggedOuter \url{http://www.bnf.fr/fr/professionnels/anx_journees_pro_2016/a.jp_161122_23_archivage_web.html}}, les acteurs français de la pratique. Alors qu'étaient évoquées les conditions du partage du dépôt légal du Web national entre la BNF et l'INA, il a été rappelé qu'à l'origine chacune des deux institutions souhaitait se voir attribuer la pleine gestion de ce dépôt. L'INA mettait en avant ses compétences techniques acquises en archivant les flux audiovisuels nouvellement introduits dans le paysage culturel. La BNF, pour sa part, s'appuyait sur son expérience pluricentenaire de préservation du patrimoine\footnote{\RaggedOuter \url{http://multimedia.bnf.fr/video/prof/161123_10_dl_web.mp4}}. 

Cette querelle initiale et son dénouement (la cotutelle du dépôt légal) sont à l'image de l'histoire même de l'archivage du Web : la conjugaison d'une tradition longue de sauvegarde des savoirs et d'un ensemble de techniques de collecte nouvellement pensées pour cet objet complexe qu'est le Web, le tout porté par une poignée de pionniers.

\subsection{Quand la technique devient mémoire}

\noindent L'archivage du Web s'inscrit dans la tradition longue des techniques d'élaboration et de conservation de la mémoire collective. Tradition qui remonte aux origines même de l'humanité où technique et mémoire se trouvaient étroitement liées. 

A. Leroi-Gourhan fait émerger, de l'étude de séries d'objets (silex taillés, percuteurs, harpons, etc.) et de figures préhistoriques (gravures et peintures des grottes ornées), une ligne de rencontre entre technique et mémoire \citep{leroi-gourhan_geste_1964}. Le préhistorien décrit la technique comme un système évolutif, soumis aux lois générales de la technologie et apparaissant comme transversal à des cultures parfois diverses et éloignées\footnote{\RaggedOuter 
Leroi-Gourhan associe les formes animales des grottes ornées à des signes, réalisant des couplages basés sur l'observation (comptages et statistiques) de dizaines de cavités. Il cherche à établir une échelle évolutive des styles pariétaux, transversale aux premiers âges de l'Europe de l'Ouest \citep{leroi-gourham_art_1984}.}. La technique est chargée, en elle même, de l'histoire passée des continuités, ruptures et transformations technologiques dont elle est l'aboutissement à un instant $t$.   

Avec Leroi-Gourhan, la technique devient mémoire. Elle peut en être chargée ou être conçue à dessein de la conserver. Involontairement, le silex taillé porte en lui la trace de l'homme qui l'a élaboré. Lorsque le tailleur finit par mourir, son geste continue à s'extérioriser à travers l'outil qui demeure. Précieux indice pour celui qui vient à sa suite ou pour l'archéologue qui, des millénaires après, saura grâce à cet objet assembler les traces fragmentées d'une pratique passée. Mais l'homme aurait aussi très bien pu choisir, en conscience, d'inscrire son expérience individuelle sur des supports de mémoire dédiés. L'écriture est ainsi l'une des premières techniques de la mémoire, utilisée par l'humanité depuis le néolithique. L'écriture est en cela une \textit{mnémotechnologie} \citep{stiegler_leroi-gourhan:_1998}. 

Poursuivant son évolution, l'humanité développe plus avant les techniques de transmission des savoirs pour sélectionner et agréger ses expériences individuelles en une mémoire collective. Des espaces et des structures voient le jour, appuyés par divers pouvoirs politiques ou religieux, avec le double objectif de préserver et d'administrer l'héritage collectif. J. Derrida décrit ainsi le geste d'archiver comme un \og \textit{geste de pouvoir} \fg{} \citep[p.60]{derrida_trace_2014}. Choisir ce que l'on garde ou non dans les archives ne peut être que le fruit d'une hégémonie, d'une hiérarchie et \og \textit{d'un certain nombre d'opérations de pouvoir} \fg{} rendues légitimes par une institution. L'État est ainsi caractérisé par \og \textit{sa capacité d'accumuler, contrôler et exploiter la mémoire collective} \fg{} \citep{stiegler_etat_1991}, capacité dont on retrouve divers incarnations au cours de l'histoire :

\begin{itemize}[leftmargin=*]  
\item Au IVe millénaire av.~J.-C., les tablettes d'argiles étaient accumulées par les mésopotamiens pour constituer les premières bibliothèques.
\item Entre 535 et 555, Cassiodore pense le Monastère de Vivarium comme un lieu de transmission où, pour la première fois, seraient associés culture savante et christianisme.
\item François Ier crée le dépôt légal\footnote{\RaggedOuter \RaggedOuter\og \textit{Nous avons délibéré de faire retirer, mettre et assembler en notre librairie toutes les œuvres dignes d'être vues qui ont été ou qui seront faites, compilées, amplifiées, corrigées et amendées de notre tems} \fg{}, extrait de l'ordonnance royale \citep{dougnac_depot_1960}.} en France, par l'ordonnance royale du 28 décembre 1537, à des fins de préservation culturelle mais également de contrôle politique.
\end{itemize}

\noindent Les siècles passent et les archives s'adaptent à la transformation des supports de mémoire et à l'émergence de formes nouvelles d'enre\-gistrement. Avec l'arrivée des technologies analogiques\footnote{\RaggedOuter Cinématographie, photographie, radiodiffusion, etc.}, il faut désormais capter et archiver des flux d'images et de sons, ce qui conduira en France à la création de l'Institut National de l'Audiovisuel (INA) en 1974. L'apparition du numérique\footnote{\RaggedOuter Bases de données, logiciels, interfaces, etc.} marque la dernière étape de ce cheminement en ouvrant la voie à un renouveau des formes de lecture et d'étude des archives. L'accès à distance de documents numérisés facilite leur consultation, mais il devient également possible de les qualifier, de les annoter ou de les mettre en relation, et ce, de manière large voire exhaustive \citep{borgman_digital_2000} :

\begin{itemize}[leftmargin=*]  
\item En 1971, le projet Gutenberg commence à collecter des copies numéri\-ques (recopiées et tapées \textit{à la main}) d'ouvrages du domaine public.
\item Le Thesaurus Linguae Graecae cherche, depuis 1972, à numériser la plupart des textes littéraires rédigés en grecs ancien et toujours subsistant.
\end{itemize}

\noindent Mais si le numérique permet aujourd'hui de revisiter des ressources anciennement archivées, il est aussi créateur d'objets nativement numé\-riques tout autant porteurs d'un héritage à préserver. Le web en est la parfaite illustration.

\subsection{Un héritage numérique}

\noindent Nous appelons \textbf{initiative d'archivage} tout projet d'archivage mené ou piloté par une personne seule, un collectif, une institution, etc. L'archivage du Web débute à la fin des années 90, et plus précisément en 1996 lorsque se développent les premières initiatives de préservation du Web, soit 4 années à peine après la publication de la première page sur la toile~(Section~\ref{sec:2_web}). La National Library of Australia est ainsi à l'initiative du projet Pandora\footnote{\RaggedOuter \url{http://pandora.nla.gov.au/}} qui vise à archiver les publications en ligne australiennes sur la base d'une collecte sélective et continue de sites Web australiens. La Swedish Royal Library, quant à elle, lance le projet Kulturarw3\footnote{\RaggedOuter \url{https://web.archive.org/web/20040206225053/https://www.kb.se/kw3}} qui s'essaye à une collecte \textit{intégrale} et espacée dans le temps des sites du Web suédois \citep{arvidson_kulturarw3_2000}.

Mais c'est avec la création d'Internet Archive par B. Kahle la même année \citep{kahle_preserving_1997}, que s'écrit véritablement la première page de l'histoire des archives du Web. Ingénieur et activiste, Kahle s'inspire de la Bibliothèque d'Alexandrie pour motiver la création d'une organisation à but non lucratif afin de rendre accessible au plus grand nombre le passé du Web\footnote{\RaggedOuter \url{https://archive.org/}}. Utilisant un crawler développé pour le compte de son autre société Alexa Internet, Kahle revendiquait, dans les premières années de la collecte, être capable d'archiver au moins une fois tous les deux mois chacun des sites de l'ensemble du Web \citep{mohr_introduction_2004}. La revente d'Alexa au groupe Amazon en 1999 va lui permettre de pérenniser financièrement Internet Archive, qui depuis ce temps n'a eu de cesse d'archiver le Web.

Ces pionniers de l'archivage sont rapidement suivis par la Finlande en 1997, le Danemark en 1998 et d'autres pays nordiques rassemblés autour du projet NWA\footnote{\RaggedOuter \textit{Nordic Web Archive}} \citep{hallgrinsson_nordic_2003}. En 2003, la publication par l'UNESCO de la \textit{Charte sur la conservation du patrimoine numérique} \citep{unesco_charter_2003} marque un nouveau tournant pour l'archivage du Web en reconnaissant la valeur universelle d'une telle démarche et l'urgence face à la disparition potentiel de tout, ou d'une partie, de l'héritage numérique mondial : \\

\begin{fullwidth}
\og\textit{Le  patrimoine  numérique  mondial  risque  d'être  perdu  pour  la  postérité.  Les  facteurs  qui  peuvent  contribuer  à  sa  perte  sont  l'obsolescence  rapide  du  matériel  et  des  logiciels  qui  servent  à  le  créer,  les  incertitudes  concernant  les  financements,  la  responsabilité  et  les  méthodes  de  la  maintenance  et  de  la  conservation et l'absence de législation favorable à sa préservation. L'évolution des attitudes n'a pas suivi celle des technologies. L'évolution numérique a été trop rapide et trop coûteuse pour que les pouvoirs publics et les institutions élaborent en temps voulu et en connaissance de cause des stratégies de conservation. La menace qui plane sur le potentiel économique, social, intellectuel et culturel du patrimoine, pierre angulaire de l'avenir, n'a pas été pleinement saisie.}\fg{} --- Charte sur la conservation du patrimoine numérique, Article 3, \citep{unesco_charter_2003}\\
\end{fullwidth}

\noindent Pour de nombreuses bibliothèques nationales, la charte de l'UNESCO fait l'effet d'un accélérateur (Figure~\ref{fig:date-initiative}). Les institutions sont encouragées dès 2003 à archiver leur Web national \citep{gomes_survey_2011}. Mais notons ici que la notion de Web national reste discutable \citep{abiteboul_first_2002}, il s'agira souvent de crawler le Web en fonction d'une extension de nom de domaine donnée (.fr, .jp, .uk, etc.), extension qui ne couvre pas exhaustivement l'ensemble des sites associés à un domaine national précis, elle est plutôt à considérer comme une borne inférieure de celui-ci \citep{koehler_analysis_1999}. Le cas des corpus de l'Atlas e-Diasporas en est un très bon contre-exemple, nombre de sites migrants possédant une extension générique (.com, .net) ou correspondant au pays d'accueil plutôt qu'au pays d'origine \citep{leclerc_cyberespace_2012}.  

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/initiatives-years}
  \caption{Évolution cumulée du nombre d'initiatives d'archivage du Web par année de création (sources : \citep{gomes_survey_2011} \& \url{https://en.wikipedia.org/wiki/List_of_Web_archiving_initiatives})}
  \label{fig:date-initiative}
\end{figure} 

\noindent Ces nouveaux acteurs de l'archivage du Web peuvent être classés suivant la terminologie introduite par J. Masanès \citep[p.76]{masanes_web_2006}, entre initiatives publiques ou privées, poursuivant un but lucratif ou non. L'accès aux corpus archivés peut être entièrement public ou restreint et limité, en ligne ou physique (machine de consultation dans une bibliothèque). Par exemple, Internet Archive est une initiative à but non lucratif, avec un accès public à l'ensemble de ses corpus en ligne\footnote{\RaggedOuter La Wayback Machine est officiellement lancée en 2001. Avant cette date les corpus d'Internet Archives n'étaient pas accessibles au public. En 2002, une copie intégrale des archives est consultable à la Bibliotheca Alexandrina, en Égypte.} depuis 2001. 

Une autre manière de catégoriser ces initiatives est de regarder la nature des corpus archivés. Nous avons déjà évoqué les corpus territoriaux censés capturer les contours d'un Web national. Cette notion peut être également transposée à plus fine échelle : celle d'une région ou d'une ville \citep{boudrez_archiving_2002}. Un corpus d'archive peut être conçu pour cibler une thématique donnée, souvent  centrée sur des événements politiques \citep{voerman_archiving_2002,schneider_building_2003} : élections, référendums, etc. Certaines initiatives s'affranchissent même de barrières géographiques devenues contraignantes en préservant des sites de domaines nationaux étrangers \citep{gomes_introducing_2009}.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/initiatives-map}
  \caption{Carte des initiatives d'archivage du Web par pays et années de création (sources : \citep{gomes_survey_2011} \& \url{https://en.wikipedia.org/wiki/List_of_Web_archiving_initiatives})}
  \label{fig:map-initiative}
\end{figure*} 

\noindent Enfin, il est possible de voir les corpus d'archives Web par rapport à l'utilisation que l'on en fait. Certains sont ouvertement tournés vers la consultation publique (Internet Archive, à nouveau), d'autres sont constitués à des fins universitaires (on pense au corpus japonais WARP\footnote{\RaggedOuter \url{http://warp.da.ndl.go.jp/search/}} de la National Diet Library). La British Library, de son côté, fait de ses archives Web une utilisation détournée, voire cachée, en chargeant les versions passées des pages Web des sites gouvernementaux (par exemple, \textit{gov.uk}) si celles ci sont momentanément ou définitivement inaccessible\footnote{\RaggedOuter \url{https://www.bl.uk/collection-guides/uk-web-archive}}. L'un des plus gros corpus d'archives Web reste en revanche celui détenu par Google qui permet d'accéder depuis le cache\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Mémoire_cache}} de son moteur de recherche à une version précédemment collectée d'une page. Notons, pour terminer ce tour d'horizon, que même si elles sont nombreuses de part le monde, les initiatives d'archivage du Web sont historiquement et géographiquement le fait d'états occidentaux (Figure~\ref{fig:map-initiative}). Les continents sud-américain et africain (hormis la Bibliotheca Alexandrina) sont absents de ce paysage, rendant encore plus précieux les corpus transnationaux archivés par l'Internet Archive et l'Atlas e-Diasporas. Notons, enfin, que certains corpus peuvent être dédiés à un ou plusieurs types précis de ressources Web. L'initiative Software Heritage\footnote{\RaggedOuter \url{https://www.softwareheritage.org/?lang=fr}} archive les logiciels et portions de codes informatiques régulièrement publiés en ligne. 

En vingt années d'existence, les archives du Web ont agrégé autour d'elles une communauté de chercheurs et d'ingénieurs participant à sa promotion. L'International Internet Preservation Consortium (IIPC) est fondé en 2003 dans l'idée de proposer des rapports et des suivis réguliers de l'archivage\footnote{\RaggedOuter \url{http://internetmemory.org/images/uploads/Web\_Archiving\_Survey.pdf}} et des workshops sont organisés (l'IWAW, International Web Archiving Workshops). Mais le fait est de constater que la dynamique visible à la fin des années 2000 est en train de se tasser. En 2017, une seule et unique initiative a vu le jour (en Belgique autour du projet Promise\footnote{\RaggedOuter \url{https://promise.hypotheses.org/}}) et les vastes projets de recherche et d'exploitation des archives Web que sont ARCOMEM \citep{risse_arcomem_2014}, LAWA \citep{spaniol_tracking_2012} et LIWA \citep{denev_sharc:_2009} n'ont pas trouvé de successeurs. Enfin, rappelons que la position centrale d'Internet Archive dans cet écosystème ne la met pas à l'abri d'une possible disparition. En 2016, B. Kahle prévoyait (notamment en réaction à l'élection de D. Trump à la tête des États Unis) de déplacer une nouvelle copie intégrale d'Internet Archive au Canada\footnote{\RaggedOuter \url{http://blog.archive.org/2016/11/29/help-us-keep-the-archive-free-accessible} \url{-and-private/}}. Et n'oublions pas que, jusqu'à présent, la survie d'Internet Archive est et reste étroitement liée à son seul fondateur.  

Mais alors que les institutions semblent s'en détourner, le futur des archives Web viendra peut être de ceux que M. Graham, directeur de la WayBack Machine, nomme les \og \textit{rogue archivists} \fg{}\footnote{\RaggedOuter \url{https://youtu.be/33_fnPwaEM0}}. S'inscrivant dans les pas d'A. Swartz\footnote{\RaggedOuter En 2011, A. Schwartz télécharge la base de données de l'éditeur JSTOR afin de \og \textit{libérer}\fg{} plusieurs millions d'articles scientifiques payants, dont une part importante appartenait au domaine public (voir \textit{The Internet Own Boy} réalisé par B. Knappenberger en 2014 \url{https://archive.org/details/TheInternetsOwnBoyEsp}). Les suites judiciaires de cette affaire mèneront au suicide de Swartz. Ses nombreuses contributions, à la fois sur des aspects techniques du Web et sur la question plus politique de l'accès universel aux connaissances, restent considérables.}, les rogues archivits sont des activistes et libristes militants s'appropriant politiquement la question des archives. Soit qu'ils considèrent le Web et son contenu comme un commun de l'Humanité \citep{coriat_retour_2015}, soit qu'ils voient dans les archives un moyen de faire perdurer la mémoire de minorités opprimées \citep{de_kosnik_rogue_2016}. Ils administrent de manière autonome certains des 7000 robots archivistes qui alimentent quotidiennement Internet Archive. Encore mineure, au regard des volumes globaux d'archives Web, il est néanmoins possible de déceler la trace de leurs contributions dans les travaux d'A. Ben David \citep{ben-david_internet_2018} qui révèle que les archives du Web nord-coréen (présentes dans le corpus d'Internet Archive) n'ont pas été collectées par des systèmes institutionnels mais par des indépendants, non assujettis à la géopolitique des proxys.       

\subsection{Le cas des archives Web Françaises}

\noindent En France, l'archivage du Web est l'aboutissement singulier de dix années d'expérimentations techniques et de construction d'un cadre législatif inédit. Aujourd'hui, deux institutions se partagent le périmètre du dépôt légal du Web : la Bibliothèque Nationale de France (BNF) et l'Institut National de l'Audiovisuel (INA). 

Crée par François 1er, le \textbf{dépôt légal} est l'obligation pour tout éditeur (imprimeur, producteur, importateur, etc.) de déposer chaque document dont il a la charge (en France) à la BNF ou auprès de l'organisme le plus adapté à la nature particulière de ce document. Tout ce qui se publie et s'édite en France est donc directement collecté par la BNF. L'INA, quant à elle, administre les archives de la radio et de la télévision. L'institut fut initialement créé pour en faire une exploitation commerciale destinée aux professionnels de l'audiovisuel. L'État français est l'un des premiers états au monde a avoir posé la question des conditions de la mémoire culturelle et patrimoniale du Web. Le Web devait rentrer dans le périmètre du dépôt légal et c'est ainsi que furent posée les bases d'un futur \textbf{dépôt légal du Web}.

Les tractations commencent officiellement en 2001. En s'appuyant sur la directive européenne 2001/29/EC\footnote{\RaggedOuter \url{https://en.wikipedia.org/wiki/Copyright\_Directive}}, dite \textit{Information Society Directive}, l'Assemblée Nationale ouvre au débat la discussion du \textit{Projet de loi sur la société de l'information}\footnote{\RaggedOuter \url{http://www.assemblee-nationale.fr/11/projets/pl3143.asp}}. Cette loi vise à adapter le droit français aux NTIC en matière de libertés de communication, de commerce en ligne, mais également de droit d'auteur. De ces débats découle, en 2006, l'adoption de la loi DADVSI\footnote{\RaggedOuter \url{https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000000266350}} relative \textit{au droit d'auteur et aux droits voisins dans la société de l'information} qui définit le cadre légale des archives Web à venir :\\

\begin{fullwidth}

\og\textit{Les logiciels et les bases de données sont soumis à l’obligation de dépôt légal dès lors qu’ils sont mis à disposition d’un public par la diffusion d’un support matériel, quelle que soit la nature de ce support. Sont également soumis au dépôt légal les signes, signaux, écrits, images, sons ou messages de toute nature faisant l’objet d’une communication au public par voie électronique.}\fg{} --- Loi DADVSI, Article 21\\

\end{fullwidth}

\noindent La BNF et l'INA souhaitant toutes deux se voir confier le plein contrôle du dépôt légal de Web par l'État, les équipes de J. Masanès (BNF) et de B. Bachimont (INA) se lancent l'une comme l'autre dans la course à l'archivage dès le tournant des années 2000, c'est-à-dire bien en amont de tout arbitrage politique. Comme nous le verrons dans la section suivante (Section~\ref{sec:3_constituer}), la masse de travail à mettre en place pour débuter une collecte est considérable. L'histoire de l'archive du Web en France est donc tout autant l'aboutissement d'une volonté politique que le fruit d'années de recherches et développements. Une profonde réflexion théorique est ainsi menée sur la nature même du Web en tant que matière à préserver et à restituer après collecte \citep{bachimont_archivage_2009}. 

Pourtant d'un point de vue purement technique, les deux institutions suivent des directions divergentes : la BNF et J.Masanès s'associent à la définition du format d'archivage WARC, l'INA et T. Drugeon créent le format DAFF et développent un crawler indépendant\footnote{\RaggedOuter Nous discuterons dans la Section~\ref{sec:3_constituer} des aspects techniques des divers formats d'archivage.}. L'INA lance rapidement sa collecte de sites Web de manière expérimentale \citep{bachimont_documenter_2005}, alors que l'État s'oriente vers un partage du dépôt légal : une solution à deux têtes. Le cadre de cette partition est défini par le décret du 19 Décembre 2011\footnote{\RaggedOuter \url{https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000025002022&categorieLien=id}} qui établit que :

\begin{itemize}[leftmargin=*]  
\item La BNF archivera l'ensemble du domaine national français et d'outre-mer au moins une fois par an. Par là, sont identifiés tous les sites Web en .fr ainsi qu'une liste blanche de sites en .com, .org, .net\ldots{} \og\textit{édités par des personnes physiques ou morales domiciliées en France}\fg{}.
\item L'INA archivera un sous-ensemble thématique du Web français centré sur les sites dit \textit{médias} (sites des services et des médias audiovisuels, Web TV et Web radios, programmes radio et TV, professionnels de l'audiovisuel, etc.). La fréquence de collecte sera variable et adaptée à la nature même des mises à jour de ces sites (chaque jour, semaine, mois, etc.)
\end{itemize}

\noindent Si le périmètre de la collecte de la BNF reste classique au regard de ses consœurs mondiales, le corpus archivé par l'INA, lui, est tout à fait singulier \citep{mussou_et_2012}. La collecte se concentre sur un jeu de 14.000 sites Web médias (sélectionnés manuellement). Seulement $30\%$ d'entre eux ont une extension .fr contre $50\%$ en .com \citep{drugeon_technical_2005}. Par ailleurs, l'INA intègre à son corpus des sources vidéos (de youtube et dailymotion dès 2010), des flux RSS, des Tweets (depuis 2014), etc. Les deux institutions offrent également la possibilité à des chercheurs de constituer des corpus tiers et portés sur une thématique précise : l'ANR Web90 est montée en partenariat avec la BNF\footnote{\RaggedOuter \url{https://web90.hypotheses.org/}} et porte sur l'étude des premières années du Web français \citep{schafer_web_2016}, l'INA réalise une collecte dédiée aux attentats de Paris fin 2015\footnote{\RaggedOuter \url{https://asap.hypotheses.org/173\#more-173}}. L'INA est enfin la seule des deux institutions à avoir encore aujourd'hui une équipe technique dédiée à la recherche et à l'exploitation de ses archives Web.

Les corpus de la BNF et de l'INA se veulent donc complémentaires. Ils appartiennent à la catégorie des initiatives publiques mais n'offrant qu'un accès physique aux contenus archivés : il n'y a pas de portail en ligne de consultation des archives. Le chercheur doit se déplacer dans l'un des 31 centres locaux de l'INA ou, s'il est a Paris, il reste possible d'accéder aux deux corpus depuis la BNF.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/ticket-bnf}
  \vspace*{0.2cm}  
  \caption{Demande d'accréditation pour accéder aux zones de consultations des archives Web à la BNF (site François Mitterand)}
  \label{fig:ticket-bnf}
\end{marginfigure} 

\begin{center}
	$\sim$
\end{center}

\noindent Je reprend ici le \textit{je} pour parler d'une expérience personnelle. Courant 2017, je me suis rendu à la BNF (site François Mitterrand) afin d'y consulter les archives de l'INA et de la BNF et tester les modalités d'accès aux corpus. Ce récit ne vaut pas généralité, mais doit être pris comme un témoignage d'une exploration d'une heure trente dans la bibliothèque avant de trouver les archives. Je pensais tout d'abord (en me fiant aux indications du site Web) qu'il était possible de consulter les archives depuis le réseaux Wifi du lieu. 

Après divers échecs, les bibliothécaires m'ont progressivement fait passer d'interlocuteur en interlocuteur jusqu'à finalement me faire accéder (moyennant une demande d'accréditation, Figure~\ref{fig:ticket-bnf}) à l'une des salles du Rez-de-Jardin de la BNF (Figure~\ref{fig:map-bnf}). Là les archives de l'INA ne sont consultables que depuis une poignée de postes labellisés \textit{Inathèque}. Les archives de la BNF, elles, sont accessibles depuis l'ensemble des  machines de la zone. Une fois connecté, un moteur de recherche classique nous permet de faire des recherches par URL (pour la BNF) et plein texte (pour l'INA), il n'est en revanche pas possible de sauvegarder ses recherches ou de les exporter d'une quelconque manière. Je me suis donc servi de mon téléphone pour photographier les pages Web qui m'intéressaient.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/BNF}
  \caption{Localisation (en bleu) des postes de consultation des archives Web à la BNF (Rez-de-Jardin, site François Mitterand)}
  \label{fig:map-bnf}
\end{marginfigure} 

J'ai été surpris de voir que la consultation des archives Web à Paris relève d'une véritable expédition et je remercie les bibliothécaires d'avoir finalement su me guider. Mais s'il ne faut pas faire grief de leur méconnaissance, force est de constater que nous ne devons pas être très nombreux à consulter les archives Web là bas et que celles ci ne sont pas particulièrement mise en avant après du public et du personnel.

\begin{center}
	$\sim$
\end{center}
  
\noindent Les conditions d'accès restreintes aux corpus de l'INA et de la BNF ne jouent pas en la faveur d'une démocratisation de leur exploitation. Auprès du grand public d'une part, mais également vis-à-vis de potentiels chercheurs voulant questionner les archives. S'il reste tout à fait possible de venir étudier une liste prédéfinie d'URL et de sites (en lecture seule), les modalités d'accès n'encouragent pas à l'exploration des corpus ni à la possibilité de mener des recherches larges et/ou automatisées (il n'y a pas d'API\footnote{\RaggedOuter Point d'entrée à une source de données depuis l'extérieur de son environnement de stockage.} par exemple). 

\section{Sélectionner, collecter et consulter les corpus}
\label{sec:3_constituer}

\noindent D'un point de vue purement technique, il a fallu penser de toute pièce de nouveaux processus d'archivage. Alors que la préservation du Web a rapidement été considérée comme une nécessité, des équipes de pionniers ont rassemblé des connaissances éparses et les ont conjuguées pour créer les outils de sélection, collecte et fouille des futurs corpus d'archives Web. 

\subsection{Un objet éphémère et multiforme}  
 
\noindent À l'époque où le Web ne contenait qu'une poignée de pages et de sites, la question de son auto-préservation\footnote{\RaggedOuter traduit ici de l'anglais \textit{self preserving} \citep{spinellis_decay_2003}} fut posée. Le Web s'archivait-il déjà de lui même ? Pourquoi faire intervenir un archiviste ?

Lorsqu'un nouveau contenu est publié, il est possible de reléguer en bas de page les élément plus anciens, à la manière d'une pile. Les \textbf{content management systems} (CMS\footnote{\RaggedOuter Système permettant de gérer automatiquement et de manière dynamique le contenu d'un site Web, comme Wordpress, Drupal, Joomla!, etc.}), apparus avec l'essor des blogs, avaient ainsi pour vocation de stabiliser ce processus de création et suppression de contenus en ligne, en reléguant les publications passées dans une section dédiée. Rien n'empêche également un site Web d'être copié dans son intégralité puis redéployé sur de nouveaux serveurs pour le préserver. Le numérique facilite et rend possible la reproduction à l'infini de ses objets. Ainsi, une page Web aurait théoriquement pu ne jamais disparaître de la toile. Mais il fut montré, dès le début des années 2000, que, malgré ces possibilités, le Web restait un milieu hautement instable. La disparition de contenu est un phénomène inhérent au Web. 

La durée de vie d'un site Web, peut être calculée par rapport à la mesure de sa demi-vie, soit la durée qu'il faut pour que la moitié de son contenu (ici ramené au nombre de pages\footnote{\RaggedOuter La demi-vie peut être appliquée à d'autres objets numériques comme des bases de données ou des documents scannés. Cette mesure est elle même dérivée des techniques de datation des atomes.}) disparaisse du Web \citep{koehler_longitudinal_2004}. Dès 1999, la demi-vie moyenne d'un site Web est ramenée à 50 jours \citep{cho_evolution_1999}, estimation qui doit être relativisée par rapport au contexte de publication du site et à la nature de ses pages \citep{mcdonnell_cataloging_1999,fetterly_large-scale_2003}. De même, 80\% des pages Web collectées entre 2003 et 2004 par les archives du Web japonais ont été effacées en moins d'un an du Web vivant \citep{toyoda_whats_2006}. Pour préserver le Web il faut donc intervenir et archiver avant qu'une page ne soit détruite. Ainsi, avant toute collecte, l'archiviste doit prendre en compte les changements susceptibles d'intervenir sur une page ciblée, afin de minimiser la perte d'information.

Les changements subis par une page Web au cours de son existence sont multiples \citep{douglis_at&t_1998, adar_web_2009}, allant de la modification de son contenu jusqu'à une évolution de la structure des liens qui la relie au reste du site. La fréquence de changement d'une page peut être estimée et prédite en s'appuyant sur des versions précédemment archivées \citep{chawathe_meaningful_1997,khoury_efficient_2007}. Il est possible d'affiner l'estimation de cette fréquence en catégorisant les changements par types (structurels, sémantiques ou cosmétiques) \citep{yadav_change_2007}. Plutôt que de considérer chaque page indépendamment les unes des autres, les changements peuvent être détectés à l'échelle d'un site ou d'un réseau. On s'appuiera alors sur la présence de liens hypertextes \citep{liu_webcq-detecting_2000} ou sur des relations hiérarchiques plus marquées \citep{lim_automated_2001}. Dans la suite de ce manuscrit, nous nous limiterons à considérer comme changements les seuls actes de création, de modification ou de suppression d'une partie ou de l'ensemble d'une page Web.

Il faut finalement attendre qu'il soit archivé, pour pouvoir considérer le Web comme un support d'informations capable de s'auto-préserver. Ce n'est qu'une fois les corpus d'archives rendus accessibles depuis le Web lui même \citep{brugger_website_2009}, que l'on peut considérer qu'il garde en lui la trace (mesurée et mesurable) de ses états passés.\\

\noindent Par ailleurs et à la différence d'autres types de documents à archiver, une page Web possède ce que J. Masanès \citep[p.47]{masanes_web_2006} nomme une \textbf{double cardinalité}. 

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/web-ressource}
  \caption{La double cardinalité d'une ressource Web, d'après \citep{masanes_web_2006}}
  \label{fig:web-ressource}
\end{figure} 

\noindent La cardinalité est le nombre d'instances en circulation d'un artéfact donné : un musée conservera des pièces uniques et originales, une librairie mettra à disposition de ses visiteurs des copies. La cardinalité donne toute sa valeur à un objet archivé et influence les techniques de préservation. Jusqu'à l'invention de l'imprimerie, pour archiver un livre il fallait le copier à la main. L'original était conservé dans un lieu donné et les copies envoyées vers d'autres bibliothèques \citep{canfora_vanished_1990}. L'original se perdant parfois, la copie (rectifiée ou annotée) devenait à défaut œuvre de référence. Mais la notion d'original disparait avec l'imprimerie. Le livre dans sa forme est stabilisée, les bibliothèques possédant toute la même version d'un ouvrage devenu reproductible à l'identique \citep{febvre_apparition_2013}. Contrairement au livre, les sites et les pages Web ont la singularité de présenter une double cardinalité : 

\begin{enumerate}[leftmargin=*]  
\item les fichiers sources, hébergés sur un serveur donné 
\item l'infinité d'accès possibles à cette source
\end{enumerate}

\noindent D'une machine à l'autre ou d'un écran à l'autre, une page Web sera toujours vue différemment \citep{bon_apres_2014}. Soit que la taille de l'écran (ordinateur, smartphone, tablette, etc.) aura modifié son aspect, soit que la qualité de la connexion à Internet n'aura pas permis de tout charger, ou encore que l'historique de navigation aura influencé l'affichage de la page à nos yeux. 

C'est pour cela que J. Masanès propose de parler de \textbf{ressource Web} \citep[p.48]{masanes_web_2006} pour nommer tout objet Web susceptible d'être archivé. Une ressource Web est un document unique dont la source peut être identifiée précisément mais interprétée d'une infinité de ma\-nière possibles. Depuis son navigateur, derrière son écran. Pour l'archiviste se pose alors la question de quoi archiver ? L'original ou toutes les interprétations d'une même page ? 

Arrivé à ce point, archiver le Web revient donc à prendre en compte l'ensemble des états successifs d'une ressource Web afin de ne rien rater. Une fois la fréquence d'archivage décidée, la collecte peut être opérée du point de vue de la source ou du point de vue de l'internaute naviguant derrière son écran. Où l'archiviste choisira-il de se positionner, lui et ses outils de collecte~?

\subsection{Sélection}

\noindent Toute collecte sur le Web débute par le choix d'un point d'entrée clairement identifié. L'archiviste ne peut se permettre de dériver au hasard du Web pour trouver les sites qui l'intéressent. La \textbf{sélection} désigne donc l'ensemble des techniques mises en place pour définir ce ou ces points d'entrée. S'agit-il d'un site Web précis ? D'une liste de pages Web ? D'un masque ou d'un motif d'URL à satisfaire ? À quelle profondeur débuter l'archivage ? Doit-on commencer par collecter la page principale d'un site, la \textit{front page}\footnote{\RaggedOuter Page principale d'un site Web, on peut également parler de page d'accueil.}, ou un sous-ensemble de pages contenant un mot clé donné ?     

Le principal critère de sélection définissant le périmètre d'un corpus à archiver reste l'extension d'URL. Les .fr, .uk et autres .ma définissent le cadre grossier d'un domaine national sur le Web (Section~\ref{sec:3_20ans}). La sélection s'opère alors en validant un masque d'URL ou une heuristique prédéfinie\footnote{\RaggedOuter Dans un script cherchant à sélectionner les sites du domaine français, on ne conservera que les noms de domaine qui valident l'expression régulière suivante : $.*\backslash.fr\$$}. Il est également possible de dessiner les contours d'une archive en partant d'une liste initiale de sites Web, appelés sites sources et liés à une thématique précise. Il faut pour cela faire appel, en amont de toute collecte, à des experts (sociologues, historiens, etc). L'INA, par exemple, a procédé par expertise pour identifier les 14~000 sites média de son périmètre d'archivage. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/degree}
  \caption{Graphe dont les nœuds sont labellisés par degré. En théorie des graphes, le degré $deg(v)$ d'un nœud $v$ correspond au nombre de liens incidents (entrants ou sortants) à ce nœud.}
  \label{fig:degree}
\end{marginfigure} 

Lors d'une collecte plus large, les archivistes peuvent s'appuyer sur des indices traduisant la valeur d'un site ou d'une page visitée. Le degré d'un site Web (Figure~\ref{fig:degree}) permet ainsi d'estimer son autorité au sein d'un environnement hypertexte \citep{abiteboul_first_2002}. Une autre stratégie consiste à identifier les sites sources par rapport aux habitudes de navigation des internautes. Quels sites sont fréquemment visités ? Quelles pages en particulier ? Il s'agit alors d'exploiter les requêtes adressées à un moteur de recherche en ligne \citep{pandey_user-centric_2005}. Ou encore, de se baser sur les motifs d'accès \citep{alnoamany_access_2013} afin de privilégier, au sein d'un même site, l'archivage de séquences de pages fréquemment visitées. Le système de sélection d'Internet Archive, en particulier, utilise cette dernière méthode \citep{kimpton_year-by-year:_2006}. Dans la même veine, un historique de navigation personnel pourra faire office de liste de primo-candidats à archiver \citep{dumais_stuff_2016}. Cette fonctionnalité a récemment été ajoutée aux archives du Web danois\footnote{\RaggedOuter Une version bêta du système danois est disponible ici : \url{https://github.com/netarchivesuite/solrwayback}}. Mais précisons, qu'aucune stratégie de sélection ne prévaut sur une autre. Elles sont d'ailleurs souvent combinées pour former une chaine complexe en amont de tout collectage (Section~\ref{sec:3_edias}). 

Par ailleurs, il est possible d'opérer une sélection par \textit{crowd sourcing} en faisant appel à des archivistes tiers. C'est toute l'idée du service payant \textit{Archive-it}\footnote{\RaggedOuter \url{http://www.archive-it.org}}, lancé en 2006 par Internet Archive, permettant à tout un chacun de se constituer des corpus d'archives Web. Quelques 230 millions d'URL ont ainsi été recueillies entre 2006 et 2007 avant d'être reversées dans le fond d'archives principales de la Wayback Machine. Dans l'idée de démocratiser encore d'avantage leur exploitation, les archives portugaises offrent la possibilité à chaque internautes de suggérer une liste de pages ou de sites Web (pas nécessairement appartenant au domaine portugais .pt) à ajouter aux  collectages\footnote{\RaggedOuter \url{http://sobre.arquivo.pt/en/collaborate/suggest/}}. L'utilisateur devient ainsi acteur de la préservation du Web.

Terminons en soulignant que le choix d'archiver une page plutôt que l'ensemble d'un site (et inversement) n'est pas trivial. À quelle échelle doit-on archiver ? L'arbitrage est souvent décidé au cas par cas et peut faire l'objet de compromis. Même si l'on demande à Internet Archive de sauvegarder une page précise, le système remontera toujours à la front page du site afin d'en archiver la racine  \citep{kimpton_year-by-year:_2006}. Ce genre de mécanisme permet d'amender et d'enrichir les points d'entrée après chaque collecte. La découverte de nouveaux sites appelant à réévaluer sans cesse la liste d'origine.    

\subsection{Collecte}

\noindent Par \textbf{collecte} nous désignons l'ensemble des techniques visant à transformer une page du Web vivant en une page archivée. Comme nous l'indiquions précédemment le Web peut, sous certains aspects, être considéré comme capable de s'auto-préserver. Une fois archivés, l'ensemble des éléments collectés restent accessible depuis le Web. Le Web contient en lui même les traces de son passé. Lorsque l'on scanne une pellicule, image par image, pour archiver un film, on fait subir à ce support de mémoire une transformation. De l'analogique au numérique. Dans le cas d'une ressource Web, la transformation induite par la collecte est minime. Il s'agit grossièrement de venir prélever les fichiers d'origines d'une page, sans les altérer et de les dater avant de les réintroduire dans les archives Web.     

Or le protocole HTTP qui régit les règles de communication sur le Web, entre client (l'internaute) et serveur (la page), n'autorise qu'un accès unitaire aux ressources Web. Il n'est possible d'accéder au Web qu'une page à la fois. La page Web (identifiée par une URL unique) est en cela l'unité de consultation de base du Web. La collecte doit donc s'effectuer page après page et non par lot, comme illustré ci-dessous :   

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/collecte}
  \caption{Archivage du Web vivant page après page, de $p_1$ à $p_3$, entre les instants $t_1$ et $t_3$}
  \label{fig:collecte}
\end{figure*} 

\noindent Il existe ainsi trois grandes familles de techniques d'archivage du Web, qui témoignent du déplacement progressif des outils de collecte du serveur vers le client. 

La première, nommée \textbf{archivage côté serveur}, consiste à collecter les ressources directement depuis le serveur hébergeant un site ou une page Web. Cette technique est plutôt employée par les producteurs de données eux même, s'ils souhaitent archiver l'ensemble des ressources d'une de leurs plateformes Web par exemple. Mais les moyens à mettre en place sont considérables car, à la différence d'une simple copie, l'archivage côté serveur induit la réplication du site (les fichiers HTML, CSS, etc. d'origine) et de l'entièreté de son environnement de dévelop\-pement et d'hébergement. On utilisera plutôt cette méthode pour archiver le Web dit profond\footnote{\RaggedOuter À opposer à la portion visible du Web (ce que l'on voit derrière son écran), le Web profond désigne tout élément qui n'est pas accessible directement depuis un crawler : les formulaires, bases de données, etc. \citep{lawrence_accessibility_2000}. Une discussion sur l'exploration d'archives du Web profond sera menée au chapitre~\ref{chap:7}.}.

La seconde approche, dite \textbf{archivage des transactions}, se situe à la frontière entre serveur et client. Il s'agit ici de positionner l'outil de collecte au niveau du système d'entrées/sorties du serveur hébergeant le site Web ciblé \citep{fitch_web_2003}. Ce que l'on archivera sera le couple [requête, réponse] du client au serveur, soit la demande d'un internaute cherchant à visiter une URL donnée et la page Web telle que retournée par le serveur. Cette forme d'archive dessine une vision non-exhaustive d'un site Web mais néanmoins fidèle à la réalité du flot d'internautes qui le parcourent. En capturant la trace des pages effectivement visitées et la manière toujours unique dont celles-ci sont affichées à l'écran des utilisateurs, cette technique est la seule qui intègre directement l'humain et ses gestes dans les archives Web\footnote{\RaggedOuter Ce type d'archive fera l'objet d'une exploration dédiée au Chapitre~\ref{chap:7}, où nous interrogerons les logs de navigation Web de la Bibliothèque du Centre Pompidou.}.  

La dernière famille, connue sous l'appellation d'\textbf{archivage côté client}, est aussi la plus répandue. Ayant acté qu'une ressource Web pouvait être visualisée d'une infinité de manière possible par le client (l'internaute), l'archiviste choisit ici de placer son outil de collecte en lieu et place de l'utilisateur. L'outil devient client et cherche à reproduire les interactions d'un internaute pour accéder au contenu ciblé~: la page Web à archiver. Tout l'enjeu est donc de définir et de contrôler l'exhaustivité de ces interactions pour construire une copie fidèle d'une page ou d'un site. 

Comme la collecte doit être menée page par page, programmée à l'avance et conduite à échelle large, les archivistes du Web se sont inspirés des crawlers développés pour les moteurs de recherche \citep{pant_crawling_2004} à la fin des années 1990. Un \textbf{crawler} est un robot programmé pour parcourir un site ou un ensemble de sites, une page à la fois, en capturant au passage l'ensemble de ses fichiers d'origine. Un crawler, pour bien fonctionner, doit respecter des règles de politesse~: éviter les dénis de services (DNS, Serveurs HTTP), les listes noires officielles (par exemple robots.txt) et officieuses (\textit{cloaking}, pièges à robot)\footnote{\RaggedOuter Ce manuscrit n'étant pas spécifiquement centré sur la question des crawlers, il est possible d'en apprendre d'avantage en se référant aux cours de C. Maussang (\url{https://frama.link/FrFrZ5EC}) ou en se tournant vers des ouvrages dédiés \citep{chakrabarti_mining_2002,mitchell_web_2015}.}. Dans le cadre spécifique des archives du Web, un crawler doit en plus intégrer les contraintes temporelles évoquées précédemment. Il a pour mission de capter l'ensemble des changements intervenant sur une page ou un site cible. Enfin, nous appelons \textbf{crawl} une campagne d'archivage menée par un crawler et (par abus de langage) le résultat même de cette campagne. 

Les caractéristiques d'un corpus d'archives Web sont directement le fait du crawler qui a mené la collecte. Un crawl peut ainsi être conduit de plusieurs manières. Une première possibilité revient à entreprendre une collecte en profondeur d'abord (\textit{depth-first}, Figure~\ref{fig:crawl} (a)). Le crawler capturera en priorité les pages filles de la page sur laquelle il se trouve. Un autre approche consiste à travailler en largeur d'abord (\textit{breadth-first}, Figure~\ref{fig:crawl} (b)). Le crawler privilégiera cette fois les pages sœurs. Mais ces techniques sont lentes et il faudra prévoir un temps considérable pour parcourir l'entièreté d'un site, or l'archiviste cherchera au contraire à minimiser le temps de capture. Aussi, on peut envisager l'instauration d'une limite en profondeur pour ne pas archiver des pages trop éloignées de la racine du site (Figure~\ref{fig:crawl} (c)).

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/crawl}
  \caption{Différentes stratégies adoptées par un crawler $c$ pour collecter les pages $\{p_1,...p_n\}$ d'un même site}
  \label{fig:crawl}
\end{figure*}

\noindent En pratique, l'archiviste optera plutôt pour un compromis entre largeur et profondeur. Avec la démocratisation des moteurs de re\-cherche en ligne, l'internaute n'est plus obligé de passer par la front page d'un site pour en consulter le contenu. Les profils de navigation se diversifient rapidement \citep{holscher_web_2000}. Pour identifier les pages pertinentes, les crawlers doivent donc intégrer à leurs programmations divers indicateurs topologiques ou sémantiques. Le pageRank \citep{page_pagerank_1999} ou le degré entrant d'un site (Figure~\ref{fig:degree-in}) traduisent tous deux l'importance d'une page crawlée \citep{cho_efficient_1998}. Ces mesures peuvent être enrichie au regard de l'historique du crawl ou d'une possible hiérarchie entre pages \citep{baeza-yates_crawling_2005}. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/degree-in}
  \caption{Graphe dont les nœuds sont étiquetés par degré entrant. En théorie des graphes, le degré $deg^-(v)$ d'un nœud $v$ correspond au nombre de liens incidents entrant à ce nœud.}
  \label{fig:degree-in}
\end{marginfigure} 

Nous le verrons lorsque dans la chapitre~\ref{chap:4} nous changerons de point de vue, passant de l'archiviste à l'explorateur d'archives, la cohérence est une notion fondamentale. Un crawl doit garantir une forme de cohérence topographique et temporelle vis-à-vis du corpus qu'il cherche à constituer. Sur ce point, il faudra poser la question de l'ordonnancement des sites les uns par rapport aux autres. Certains sites, larges ou volatiles, feront l'objet d'une collecte rapide (\textit{short-term scheduling}) qui mobilisera toutes les ressources du crawler.  Pour les autres, le crawl s'inscrira dans le temps long (\textit{long-term scheduling}) et pourra prendre plusieurs jours \citep{castillo_scheduling_2004}. Néanmoins, certaines contraintes de politesse peuvent obliger à traiter en parallèle une grande quantité de sites. Mais si cela est possible, ne crawler que lorsqu'un site est le moins susceptible de subir des changements peut garantir une cohésion temporel au corpus \citep{saad_coherence-oriented_2011}. S'appuyant sur toutes ces réflexions, les équipes d'Internet Archive présentent en 2004 un crawler open-source, l'Heritrix \citep{mohr_introduction_2004} capable de s'adapter à divers type de collecte : large (\textit{broad crawling}), en continu (\textit{continuous crawling}) ou focalisée (\textit{focused crawling}). Heritrix reste encore aujourd'hui le crawler le plus répandu pour l'archivage du Web. 

Face à l'évolution du Web, les crawlers s'adaptent et archivent de nouveaux objets : allant des sites Flash\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Adobe_Flash}} aux vidéos Youtube ou Dailymotion \citep{pop_archiving_2010}. Mais alors que les contenus publiés incorporent de plus en plus d'éléments dynamiques, se syndiquer à un flux RSS devient une stratégie à part entière pour collecter de l'information en continu \citep{oita_archiving_2010}. Des bibliothèque sont développées pour interpréter les portions de code utilisant du Javascript\footnote{\RaggedOuter \url{https://github.com/ariya/phantomjs}} et les crawlers commencent à se spécialiser pour archiver certains réseaux sociaux. Les interfaces de programmation applicatives (API) s'imposent comme des sources de données auxquelles il convient de se connecter. Si certaines API ouvertes permettent de crawler l'entièreté d'une plateforme\footnote{\RaggedOuter Voir la crawl de Github réalisé en 2010 par F. Cunny et Linkfluence (\url{http://www.visualcomplexity.com/vc/project.cfm?id=785}).}, d'autres plus limitées obligent les archivistes à faire preuve d'inventivité. Ainsi, Internet Archive possède, depuis Mars 2016, un compte Facebook \textit{charlie.archivist} dont la timeline est régulièrement archivée\footnote{\RaggedOuter \url{https://frama.link/7fzU_DbR}}. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/new_crawl_ina}
  \caption{Fonctionnement général du système de collecte de l'INA}
  \label{fig:crawl-ina}
\end{figure*}

\noindent Terminons ce descriptif des techniques de collecte, par une présentation plus poussée du crawler de l'INA. Développé par les équipes de T. Drugeon \citep{drugeon_technical_2005}, ce crawler fut en charge (de 2010 à 2014) de l'archivage des sites Web de l'Atlas e-Diasporas. Pour commencer (Figure~\ref{fig:crawl-ina}), un ordonnanceur général (\textit{scheduler}) gère la liste des sites sources auxquels une fréquence de collecte a été associée. En se basant sur cette fréquence, l'ordonnanceur choisit les sites à archiver en priorité et leur dédie à chacun un crawler (\textit{site crawler}). Plusieurs centaines de crawlers peuvent ainsi être lancés en parallèle. Ces crawlers procèdent à une récolte en largeur d'abord, mais sans sortir du périmètre du site qui leur est alloué. Une fois les pages visitées, le contenu est indexé et stocké sur fichiers. À ce niveau, si des liens hypertextes sortants sont détectés dans une page, les sites pointés par ces derniers sont conservés afin de potentiellement venir enrichir la liste des sites sources. La fréquence de collecte est mise à jour entre deux crawls successifs. Soit en analysant les informations venues de l'agrégateur de flux RSS, soit en comparant l'évolution d'une page archivée d'une version à l'autre. Cette architecture fait du crawler de l'INA un outil extrêmement réactif, adapté à la nature même des sites médias et, de fait, très efficace lorsqu'il s'agit de constituer rapidement des corpus portant sur un événement singulier\footnote{\RaggedOuter Voir la collecte réalisée pour les attentats de Paris en 2015 (\url{https://asap.hypotheses.org/173})}.

\subsection{Stockage}

\noindent Le \textbf{stockage} représente l'ensemble des techniques d'enregistrement d'une ressource Web crawlée. Ainsi, parallèlement à son crawler, l'INA développe son propre format de fichier destiné au stockage des archives Web : le Digital Archive File Format (DAFF). L'INA prend ainsi le contre-pied du reste de la communauté qui, elle, continue de s'en tenir au format Web ARChive (WARC) pour sauvegarder la grande majorité des corpus existants.

C'est en 1996, s'inspirant du format de compression et d'archivage ARC (popularisé à la fin des années 80), qu'Internet Archive définit le ARC\_IA\footnote{\RaggedOuter \url{https://www.loc.gov/preservation/digital/formats/fdd/fdd000235.shtml}}. L'idée étant de combiner plusieurs ressources collectées en un seul et même fichier avant de les compresser pour en réduire la taille sur disque.

Mais l'ARC\_IA évolue rapidement, suivant les avancées des techniques de crawl, et ce, jusqu'à atteindre sa version actuelle : le WARC. Devenu le format standard d'archivage Web en 2009\footnote{\RaggedOuter \url{https://www.iso.org/standard/44717.html}}, un fichier d'ar\-chives WARC peut être vu comme la concaténation de plusieurs enregistrements (ou blocs), chaque enregistrement correspondant à une ressource Web crawlée\footnote{\RaggedOuter Une page, une image\ldots{} Chez Internet Archive, toute objet associé à une URL unique sera archivé comme ressource Web.}. Les informations contenues dans un bloc WARC sont de deux natures : des méta-données et des données. Les \textbf{méta-données} (stockées dans l'en-tête du bloc) couvrent toutes les informations relatives au crawl : date de collecte, taille de la ressource, URL de la ressource, ID du bloc\ldots{} Ces méta-données sont directement suivies des données à proprement parler : soit l'enregistrement brut des fichiers .HTML, .CSS, etc. collectés. Ainsi, chaque fois qu'une page Web est archivée (qu'elle ait évolué ou non depuis le précédent crawl) un bloc est ajouté au fichier WARC courant (Figure~\ref{fig:daff-warc} (a)). 

Directement liés au WARC, il est possible d'extraire d'un bloc deux sous-formats spécialement dédiés à l'exploitation des corpus : les WAT et WET. Un fichier WAT (Web Archive Transformation) ne contient que des méta-données. Contrairement au WET (Web Extracted Text) et à ses dérivés (LGA ou WANE\footnote{\RaggedOuter \url{https://webarchive.jira.com/wiki/spaces/ARS/pages/90997507/Datasets+Available}}) qui, eux, ne stockent que des éléments de texte issus de la partie données d'un bloc WARC. Pourtant utilisé par la quasi-totalité des initiatives d'archivage, le format WARC introduit un point hautement critiquable : l'existante de redondances dans les fichiers d'archives Web.

En effet, entre deux crawls successifs, un bloc WARC sera invariablement crée (que la ressource Web collectée ait évolué ou non). Une page Web stable dans le temps, verra ainsi son contenu archivé autant de fois qu'elle aura été crawlée, conduisant à une consommation d'espace de stockage considérable. C'est donc en partant de l'intuition selon laquelle méta-données et données devraient être stockées séparément (pour ne pas surcharger les corpus) que l'INA a développé le format DAFF.  

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/daff-warc}
  \caption{Différences entre les formats WARC (a) et DAFF (b)}
  \label{fig:daff-warc}
\end{figure*}

\noindent Une archive DAFF est en réalité l'association de deux fichiers complémentaires : un fichier de méta-données et un fichier de données. Comme pour le WARC, chaque fichier est une suite de blocs correspondant à une ressource Web crawlée. Le fichier de méta-données contient divers champs relatifs à la collecte (voir Table~\ref{tab:daff}). Le fichier de données, quant à lui, ne renferme que deux champs : un identifiant unique et le contenu (HTML, CSS, etc.) de la page Web archivée. Avec le DAFF, données et méta-données sont stockées séparément. Ainsi, d'un crawl à l'autre, si la page Web visitée n'a pas évolué, alors son contenu ne sera pas re-téléchargé : seul un nouveau bloc de méta-données sera ajouté pour témoigner du passage du crawler. Chaque bloc de données est donc associé à un ou plusieurs blocs de méta-données (le champ \textit{content} des méta-données correspondant au champ \textit{id} des données). Ce mécanisme permet, d'une part de ne pas dupliquer inutilement le contenu d'une page Web archivée et, d'autre part, de pouvoir pratiquer rapidement divers calculs statistiques sur le seul fichier de méta-données. Celui-ci étant par nature plus léger qu'un WARC complet, donc moins long à traiter.

Notons que pour tester si une page a évolué depuis sa précédente visite, le crawler de l'INA compare la valeur des champs \textit{id} des blocs de données concernés. En effet l'\textit{id} est une clé SHA-256 résultant du hachage\footnote{\RaggedOuter En cryptographie, le hachage consiste à transformer une donnée de taille arbitraire, une image (ou clé) de taille fixe et unique.} du contenu même de la page Web archivée. On dira donc d'une page Web qu'elle s'est transformée si et seulement si les deux clés successives sont différentes. La nature de ce changement ne sera en revanche pas connue, celui-ci pouvant aller de la refonte entière de la page à la simple suppression d'une virgule.        

\begin{table*}
  \label{tab:daff}
  \begin{tabular}{lrl}
    \toprule
    Méta données& Champ & Description\\
    \midrule  
    \multirow{5}{*}{\emph{obligatoire} \vastt\{ }&id&identifiant unique du bloc\\
    &url&url associée à la ressource\\
    &date&date de téléchargement (ISO 8601)\\
    &content&identifiant unique du bloc de données associé\\     
    &status&statut de retour du crawler (ok, request\_error, server\_error, etc.)\\
    \midrule     
    \multirow{12}{*}{\emph{facultatif   } \Vastt\{ }&crawl\_session&identifiant unique de la campagne de crawl\\
    &charset&encodage de la ressource\\
    &type&Type MIME (identifiant du format de donnée de la ressource)\\
    &corpus&nom du corpus d'archives associé\\
    &ip&adresse ip associée au crawl\\
    &level&profondeur du crawl\\
    &page&la ressource est elle une page Web (0|1)\\
    &client\_country&pays associée à la page\\
    &length&taille du bloc de données associé\\
	&active&la ressource était elle active au moment du crawl\\
	&client\_lang&langue associée à la ressource\\
	&referer\_url&url précédemment visitée par le crawler\\
    \midrule
    Données& Champ & Description\\
    \midrule 
    &id&clé SHA-256 unique\\
    &content&contenu (HTML, CSS, etc.) de la ressource\\    	
    \bottomrule
\end{tabular}
  \bigskip
  \caption{Ensemble des champs disponibles dans les fichiers de méta-données et de données DAFF}
\end{table*} 

\noindent Outre le stockage sous formats WARC et DAFF, J. Masanès \citep[p.64]{masanes_web_2006} rappelle qu'il existe des méthodes alternatives de sauvegarde des archives. Associées aux stratégies de collecte situées côté serveur on trouvera les formes dites d\textbf{archivage sur fichiers servis en local} qui consistent à transformer un site Web archivé en une copie locale de l'ensemble de ses ressources. Ainsi les URIs absolues, permettant (sur le Web) de naviguer d'une page à l'autre, seront transformées en URIs relatives à l'intérieur du fac-similé. Très coûteuse, cette méthode nécessite de transformer en profondeur la nature des pages archivées et devient vite ingérable à mesure qu'augmente le nombre de collectes.

Enfin, il reste toujours possible de copier un site, page après page, sous format PDF ou image (capture d'écran ou vidéo). Bien que facile à mettre en place (techniquement parlant) cette stratégie ne passera pas non plus à l'échelle\footnote{\RaggedOuter En 2013, K. Goldsmith imprime littéralement plusieurs centaines de milliers de pages Web en soutient à A. Schwartz, remplissant l'équivalent d'une pièce de 1,100 $\mathrm{m}^2$} et aura pour conséquence d'arracher les sites et pages Web archivés à leur environnement hypertexte d'origine.  

Pour terminer, les corpus d'archives Web répartis dans le monde se comptent par centaines. Alors que le Web vivant continue son expansion, le volume du Web archivé ne cesse de croitre. En 2017, la BNF avait archivé 18 milliards de pages Web (soit environ 370~TB) tandis que l'INA plafonnait à 43 milliards de pages pour un total avoisinant les 420~TB. Et depuis sa création, l'Internet Archive a collecté à elle seule pas moins de 650 milliards de ressources Web (pages, images, vidéos\ldots{}) soit 40~PB de données. Ainsi, face à ces corpus qui s'amassent et à la nécessité de les exploiter, les archivistes du Web ont dû développer des outils dédiés à leur exploration.

\subsection{Consultation}

\noindent Par \textbf{consultation}, nous désignons les stratégies d'interrogation et les systèmes d'exploration des archives Web. Ainsi, pour permettre aux chercheurs d'ana\-lyser le résultat des collectes, les archivistes déploient des dispositifs techniques \textit{au-dessus} des corpus existants. 

Comme nous l'évoquions en Section~\ref{sec:3_20ans}, la fouille est tributaire des modalités d'accès aux données qui, pour $50\%$ des initiatives \citep{costa_survey_2013}, passent par la mise en place d'un portail en ligne. Mais cela ne signifie pas pour autant que les archives sont entièrement accessibles. Su ce point, $38\%$ des initiatives restreignent la consultation de leurs corpus : soit l'analyse doit se faire localement (INA, BNF, etc.), soit les archives ne sont pas intégralement mises à disposition du public (The Library of Congress, Australia's Web Archive, etc.). Contrairement à Internet Archive et aux Portuguese Web Archives qui proposent un plein accès, en ligne, à leurs collectages.  

Les dispositifs de consultation, déployés par dessus les archives, reprennent l'architecture générale de la plupart des système de moteurs de recherche\footnote{\RaggedOuter L'anglicisme \textit{search} désigne tout autant les systèmes de moteurs de recherche eux même, que les stratégies déployées par ces derniers.} \citep{grainger_solr_2014,hatcher_lucene_2004}. Les archives sont ainsi indexées puis mises à disposition d'un serveur de \textit{search} qui les rend interrogeables\footnote{\RaggedOuter Nous développerons le processus d'indexation des archives Web plus en détail dans la Section~\ref{sec:4_moteur}}. L'\textbf{indexation} définie l'étape de transformation d'un document texte en une liste de mots ou d'ensembles de mots, cette étape est nécessaire à toute construction d'un moteur de recherche. On appelle \textbf{index} la structure de données obtenue après indexation. 

Côté utilisateur, la recherche se traduit par une interface Web, dans laquelle il est possible de rentrer une requête (un texte, un ensemble de mots clé, des filtres, etc.), puis de consulter les résultats correspondants sous la forme d'une liste ou d'un histogramme (Figure~\ref{fig:ia-search}). Tout l'enjeu pour ces moteurs d'exploration d'archives est de proposer la meilleure technique de recherche possible pour fouiller efficacement un corpus d'archives Web. Ou comment, partant de la requête d'un chercheur, proposer avec justesse un ensemble de page archivées qui satisfasse ses interrogations ?

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/IA-search}
  \caption{Interface de search de la WayBack Machine (\url{https://web.archive.org/web/*/yabiladi})}
  \label{fig:ia-search}
\end{marginfigure} 

Dans ce domaine, la recherche dite \textbf{plein texte} (\textit{full-text}) est ce vers quoi tendent toutes les initiatives d'archive du Web \citep{costa_characterizing_2011,costa_evaluating_2012}. En recherche d'information, le full-text revient à faire correspondre les mots d'un document ou d'un ensemble de documents avec les critères fournis par un utilisateur (des mots clés, une phrase, etc.). Popularisée sur le Web par AltaVista, c'est la recherche telle que nous l'expérimentons quotidiennement en interrogeant Google. Mais, encore aujourd'hui, son application aux moteurs d'exploration d'archives Web reste limitée. Si l'INA, les portugais d'Arquivo.pt ou encore The Web Archive of Catalonia\footnote{\RaggedOuter \url{https://www.padicat.cat/en}} proposent d'étendre cette fonctionnalité à l'ensemble de leurs corpus \citep{stack_full_2006}, à la BNF, au contraire, le full-text n'est applicable que sur les seules URL des pages archivées. c'est-à-dire qu'à une requête utilisateur donnée, le moteur de la BNF ne pourra faire correspondre qu'une recherche stricte par URL, sans regard pour le contenu même des pages. En 2016, Internet Archive ajoute à la Wayback Machine un système full-text basé sur le titre des pages Web collectées\footnote{\RaggedOuter Si et seulement si le titre est présent dans la balise \textit{title} du HTML de la page (\url{https://frama.link/K4CMmzHU}, \url{https://www.w3schools.com/html/html_head.asp}).}, avant cette date seule une recherche stricte par URL était proposée. Selon M. Costa \citep{costa_survey_2013}, $67\%$ des initiatives d'archivage du Web proposaient en 2013 une recherche full-text complète, limitée ou dégradée. 

La taille importante des corpus ou la difficulté des archivistes à définir quelles doivent être les éléments d'une page Web à indexer peuvent expliquer que le full-text soit si compliqué à mettre en place. Mais des alternatives existent : on peut ainsi envisager une recherche par catégories \citep{holzmann_tempas:_2016}, par entités nommées \citep{spaniol_tracking_2012} ou en se basant sur des tendances issues des réseaux sociaux \citep{risse_arcomem_2014}. Une solution originale consiste à ne pas construire de moteur d'exploration mais à s'adosser à des systèmes existants. Le système Memento\footnote{\RaggedOuter \url{http://mementoweb.org/about/}}, par exemple, permet d'interroger les corpus d'Internet Archive directement depuis un navigateur Web, à la manière d'une extension. 

Créée en 2001, la Wayback Machine est le plus emblématique des systèmes de consultation d'archives Web \citep{tofel_waybackfor_2007}. L'ensemble des res\-sources archivées y sont indexées page par page (bloc WARC par bloc WARC). Les index sont ensuite répartis sur les quelques 2500 serveurs de stockage du centre de stockage (\textit{data center}) principal d'Internet Archive. Un ordonnanceur central envoie les requêtes des utilisateurs à l'ensemble des serveurs avant d'agréger les résultats. Il existe un système de cache destiné à améliorer les temps de réponse de la Wayback Machine, ainsi l'attente variera en fonction de la popularité de chaque requête. Le moteur des Portuguese Web Archives propose, lui, d'indexer les archives d'abord par date de téléchargement puis page par page \citep{costa_survey_2013}. Si l'utilisateur associe à sa requête une année ou un intervalle de temps précis, le résultat de ses recherches lui sera plus rapidement retourné. Les moteurs d'exploration peuvent aussi être entièrement décentralisés. A. Anand décrit Everlast \citep{anand_everlast:_2009} comme un système de consultation pair-à-pair (\textit{peer-to-peer}) où chaque élément du réseau est à la fois serveur et client, plus scalable donc. 

Bénéficiant d'une distribution open source, la Wayback Machine est aujourd'hui réutilisée ou sert de base\footnote{\RaggedOuter Dans son intégralité ou élément par élément : Heritrix pour la partie crawl, NutchWAX pour la partie recherche full-text.} à l'architecture de $62\%$ des initiatives d'archivage du Web \citep{costa_survey_2013}. Mais force est de constater que les systèmes existants n'encouragent pas particulièrement à l'exploration des archives, à la découverte des corpus, ou plus simplement à leur exploitation à grande échelle (en terme de quantité de pages ou de temporalité). Il est de plus difficile de s'évader du cadre strict imposé par des interfaces invariablement semblables, proposant une expérience des archives Web toujours identique.

La Wayback Machine est redoutablement efficace lorsqu'il s'agit de rechercher une version précise d'une page déjà connue. Notons aussi qu'elle propose une API\footnote{\RaggedOuter \url{https://archive.org/help/wayback_api.php}} pour accélérer les traitements. Mais sans la possibilité de filtrer à priori le contenu des pages, tout le dispositif de consultation sera à développer du côté de l'explorateur qui bien souvent n'a pas les compétences ou les moyens techniques pour y arriver. Et si l'INA offre de meilleures fonctionnalités de recherche (plein text complet, n-grammes, etc.), le fait que l'on ne puisse accéder aux corpus que depuis des lieux dédiés reste un frein majeur à toute analyse. Ainsi, une asymétrie se dessine rapidement lorsque l'on parcourt la littérature basée sur les archives Web. Beaucoup de travaux portent sur la constitution en amont de corpus d'archives (sélection, collecte, etc.), très peu en revanche se lancent dans l'exploitation ou l'interrogation de corpus existants. Ces derniers, bien que précieux à juste titre, se \textit{limitent}\footnote{\RaggedOuter Pas forcément en conscience, mais nous pensons que les outils d'exploration jouent un rôle quand il s'agit de définir de la portée de ces travaux.} soit à l'analyse de versions passées de sites identifiés à priori \citep{schafer_web_2016,gebeil_les_2016}, soit à l'extraction d'éléments singuliers d'un contenu archivé : des images \citep{ben-david_colors_2018} ou des liens hypertextes \citep{weltevrede_where_2012}. 

\section{Les archives Web de l'Atlas e-Diasporas}
\label{sec:3_edias}

\noindent Parallèlement au travail de cartographie présenté en Section~\ref{sec:2_atlas}, les chercheurs pilotant la construction de l'Atlas e-Diasporas prennent la décision d'archiver l'ensemble des sites Web déjà répertoriés. Tout autant pour les préserver des assauts du temps \citep{khouzaimi_e-diasporas_2015} que pour permettre la tenue de recherches futures : se donner la possibilité d'un retour arrière, analyser les évolutions et transformations subies par ces réseaux. Déjà associée à la collecte des sites, l'INA se voit confier la charge de l'archivage. Toutes les e-Diasporas seront concernées par cette campagne de sauvegarde, mais  nous nous attarderons ici sur la seule description de la section marocaine de l'Atlas. 

L'archivage du corpus marocain débute en Mars 2010 et se termine en Septembre 2014 après une collecte patiente et continue. Le collectage couvre l'ensemble des 156 sites de l'e-Diasporas marocaine. La fréquence de collecte associée à chaque site est définie en amont par les chercheurs. Celle-ci est sera au final soit hebdomadaire (pour $56\%$ des sites), soit mensuelle (pour les $44\%$ restants). La majorité des sites archivés à la semaine sont les plus fréquements mis à jours : des blogs, des portails communautaires ou des médias. Les archives sont stockées suivant le format DAFF, vu comme l'union d'un fichier de méta-données (\textit{metadata-r-00006.daff} : 13~GB) et d'un fichier de données (\textit{data-r-00006.daff} : 151~GB). Ces fichiers représentent un total de 17~043~833 ressources collectées, parmi lesquelles nous comptons 16~897~787 pages Web ($99\%$), 145~301 images, 700 vidéos et 44 enregistrements audio. Dans le Chapitre~\ref{chap:6} nous explorerons les sites \textit{yabiladi.com} et \textit{larbi.org} dont une présentation détaillée est donnée dans la Table~\ref{tab:detail-archive}. Cette table introduit un premier élément de comparaison entre les archives e-Diasporas et leurs équivalents chez Internet Archive.

Si la fréquence d'archivage (telle que mise en place par l'INA) semble plus élevée du côté d'e-Diasporas, la durée de collecte est importante chez Internet Archive. L'idée ici n'est pas de prouver qu'un corpus est mieux qu'un autre, mais de saisir les particularités de chacun. Un corpus d'archives Web n'est jamais parfait, bien au contraire, et nous émettons ici l'hypothèse que c'est par une approche mixte, en conjuguant diverses sources de données que nous maximiserons la précision scientifique des explorations à venir. Ainsi, sur la période 2010-2014 et dans les cas précis de \textit{yabiladi.com} et \textit{larbi.org}, la capture réalisée pour e-Diasporas semble plus fidèle. Il faudra en revanche l'associer à Internet Archive lorsque nous chercherons à remonter au delà de 2010.

\newpage 

\begin{table}
\centering
  \label{tab:detail-archive}
  \begin{tabular}{lrr}
    \toprule
    &larbi.org&yabiladi.com\\
    \midrule
    Nbr de pages archivées (e-Diasporas)  & 78~311 & 2~683~928\\
    Nbr de pages archivées (Internet Archive) & 24~537 & 887~981\\
    \midrule
    Début de l'archivage  (e-Diasporas) & Mars 2010 & Mars 2010\\
    Début de l'archivage  (Internet Archive) & Oct. 2002 & Fév. 2001\\
    \midrule
    Fin de l'archivage  (e-Diasporas) & Sept. 2014 & Sept. 2014\\
    Fin de l'archivage  (Internet Archive) & Sept. 2018 & Sept. 2018\\    
  \bottomrule
\end{tabular}
  \bigskip
  \caption{Décompte des archives Web des sites \textit{yabiladi.com} et \textit{larbi.org}}
\end{table} 

\noindent Mais essayons maintenant d'étendre cette comparaison à l'ensemble des sites du corpus marocain. Voyons comment ces sites ont été archivés par différentes initiatives. Comme beaucoup de ces observations devront être faites à la main (notamment à la BNF), nous nous limitons tout d'abord aux seules front pages (pages racines) de chaque site Web de l'e-Diasporas marocaine. Pour chacune de ces pages, nous consultons successivement les archives e-Diasporas (produites par l'INA), les archives de la BNF et les archives d'Internet Archive, puis nous notons leurs dates de premier et dernier crawl afin de se donner une idée de l'étendue des collectes. Les résultats sont présentés et agrégés par les Figures \ref{fig:date-crawl-ina} (pour l'INA), \ref{fig:date-crawl-bnf} (pour la BNF) et \ref{fig:date-crawl-ia} (pour Internet Archive). Le nom de domaine des sites est inscrit en ordonnée, le temps en abscisse. Chaque ligne est divisée en années puis en mois (1 mois = un tiret). Si un tiret est colorié c'est qu'il se trouve entre les dates de premier et de dernier crawl du site correspondant.

\iffalse

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/crawl-1}
  \caption{Préservation dans le temps des sites de l'e-Diaspora marocaine par l'INA (tirets jaunes)}
  \label{fig:date-crawl-ina}
\end{figure*}

%\iffalse

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/crawl-2}
  \caption{Préservation dans le temps des sites de l'e-Diaspora marocaine par la BNF (tirets rouges)}
  \label{fig:date-crawl-bnf}
\end{figure*}

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/crawl-3}
  \caption{Préservation dans le temps des sites de l'e-Diaspora marocaine par Internet Archive (tirets bleus)}
  \label{fig:date-crawl-ia}
\end{figure*}

\fi

L'intuition précédente est confirmée par ces trois figures : les corpus vus depuis Internet Archive et (dans une moindre mesure) depuis la BNF couvrent naturellement une plus grande étendue temporelle que la collecte de l'INA, limitée aux seules années 2010-2014. En revanche, leurs collectages sont incomplets, les sites marocains ne sont pas tous archivés. C'est assez naturel au regard du périmètre d'archivage de la BNF notamment, qui ne doit théoriquement couvrir que les sites du domaine français, ici la BNF aura archivé par effet de bord des sites marocains en .com ou .org ce qui nous amène à relativiser la notion de domaine Web national telle que présentée plus tôt (Section~\ref{sec:3_20ans}). Ce qui frappe, enfin, est la cohérence générale de notre corpus tel qu'il est présenté par l'INA. L'ensemble des sites sont archivés, collectés au moins une fois entre 2010 et 2014 et forment un ensemble thématiquement homogène. 

Mais ces figures ne doivent pas non plus nous induire en erreur, nous ne voyons pas le détail des collectes : ni ce qu'il s'est passé entre les dates de premier crawl et de dernier crawl, ni le comportement du crawler vis-à-vis de pages éloignées de la racine des sites. Or, nous le découvrirons dans le chapitre suivant, archiver est avant tout une question de choix et de sélections, ce qui posera nombre de problèmes à l'explorateur d'archives Web. 

\begin{center}
	\textbf{***}
\end{center}

\noindent Les archives Web ont été construites pour inscrire la mémoire du Web sur un support durable et préserver notre héritage numérique. Offrir ainsi la possibilité aux chercheurs de demain d'interroger, de questionner et de critiquer le Web qui nous est contemporain. Mais plus on archive et plus la taille de ce Web passé grandit, laissant parfois les chercheurs seuls face à des corpus trop larges et trop vastes pour être explorés sans méthode ni stratégie clairement définies. Les archives Web doivent rester une matière vivante. Prenons garde à ce qu'elles ne deviennent pas des capsules temporelles\footnote{\RaggedOuter \url{https://en.wikipedia.org/wiki/Westinghouse\_Time\_Capsules}} que l'on enterre dans l'espoir, qu'un jour, peut être, quelqu'un se décide à les rouvrir.

Il existe, selon nous, un espace et un intérêt scientifique indéniable pour des recherches portants sur de larges corpus d'archives Web. Mais cet espace appelle la création de méthodes d'exploration capables de changer d'échelle analytique au cas par cas. Aussi, nous faisons l'hypothèse qu'une stratégie quantitative ne pourra se concevoir sans une approche qualitative complémentaire (Chapitre \ref{chap:6}) et que l'automatisation des traitements ne pourra se faire sans une part de travail manuel (Chapitre~\ref{chap:5}).

Au cours de ce chapitre, nous nous sommes attachés à décrire la genèse de l'archivage du Web comme technique de préservation d'un nouvel héritage numérique. L'idée étant de comprendre la nature des corpus que nous manipulerons dans la suite de cette thèse. Au tournant des années 2000, de nombreuses initiatives privées et publiques se sont emparées du sujet, déployant en un temps record (à l'échelle du Web) des moyens humains et techniques. Néanmoins cette dynamique semble aujourd'hui s'essouffler et force est de constater que, même si les corpus grandissent toujours plus, peu de chercheurs se sont déjà aventurés dans les archives. Le Web passé reste un terrain en partie inexploré. 

Pour se saisir du Web, il aura fallu, aux pionniers de l'archivage, inventer et déployer de nouvelles méthodes de collecte et de stockage. Ces choix techniques façonnent et régissent les archives Web telles que nous les découvrons aujourd'hui. Détachée du Web vivant, l'archive Web se consulte dans des lieux sanctuarisés, souvent à la main et à travers des outils qui, malgré eux, réduisent les archives Web à de simples documents. La sensation du Web comme environnement n'est pas restituée dans les archives. L'exploration y est forcément ciblée, réduite à une URL ou un mot-clé. 

Cependant, comme pour le Web vivant, l'unité d'exploration des archives reste la page Web. WARC et DAFF sont deux formats construits au-dessus des pages qu'ils capturent et qu'ils dotent, par là même, d'une nouvelle temporalité. Une fois archivée chaque version d'une même page se voit associée une date de téléchargement. Cette date devient dès lors le seul marqueur temporel par lequel nous pouvons explorer les archives Web. Dans le chapitre suivant, nous exposerons les divers implications et biais d'analyse que peut causer cette datation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\begin{minipage}[t,leftmargin=5em]{1.5\linewidth}%
\begin{adjustwidth}{-0.5cm}{}
\chapter{Traces discrétisées et temporalité figée} 
\label{chap:4}
\end{adjustwidth}
\end{minipage}
\hfill

\noindent Au cours de ce chapitre, nous amorcerons un changement de point de vue, glissant du regard de l'archiviste vers celui de l'explorateur d'archives Web. 

Un \textbf{explorateur d'archive} est une personne ayant l'intention de découvrir ou d'étudier un corpus d'archives Web donné (fini ou toujours en construction). Son geste pourra tout autant être motivé par une question de recherche précise que par sa seule curiosité. Ce faisant, l'explorateur devra démêler les traces d'un Web passé pour faire émer\-ger une information ou un savoir de cette masse de données. 

Dans un premier temps, nous déconstruirons la structure des ar\-chives Web pour en saisir les règles et la grammaire interne. En effet, selon N. Brügger \citep{brugger_website_2009}, le Web archivé n'est déjà plus le Web. C'est un autre espace, un autre environnement. Lorsqu'un site du Web vivant est sélectionné, stocké et collecté, il subit une série de transformations qui forcent les archivistes à recréer, en totalité ou en partie, le système d'information de la toile. Pour explorer les archives, il faut se détacher des automatismes acquis en parcourant le Web vivant. Ce faisant, nous présenterons ici certaines propriétés et certains biais inhérents au Web archivé. Biais qu'il nous faudra prendre en considération avant toute analyse. 

Pour l'explorateur, les archives Web se présentent d'abord comme des traces discrétisées du Web vivant, arrachées à un flux d'information en continu. En effet, la discrétisation du Web par les archives est le fruit d'une sélection, mais surtout d'un ensemble de destructions, comme le souligne J. Derrida \citep[p.60]{derrida_trace_2014} : archiver c'est avant tout détruire ce que l'on ne peut conserver.

Par ailleurs, la collecte propulse les ressources archivées dans une nouvelle temporalité. Les pages du Web passé n'appartiennent plus au temps du Web vivant mais au temps des archives : une temporalité faite d'instantanés figés et sans possibilité d'extension. Il n'y a pas de continuité absolue entre deux versions d'une même page archivée. D'un crawl à l'autre tout peut changer (Section~\ref{sec:3_constituer}). Ainsi, il nous faudra discuter des phénomènes de leurres et de cécité des collectes\footnote{\RaggedOuter \textit{crawl blindness} en anglais}, de la notion de cohérence entre pages et de la présences de contenus sur-archivés qui peuvent être source de nombreux biais d'analyse. 

Passées ces mises en gardes, nous décrirons le développement de notre propre moteur d'exploration d'archives Web. Un moteur adapté au format DAFF et suffisamment flexible pour être le support de nos expérimentations à venir. Nous détaillerons notre chaine d'extraction et d'enrichissement des archives, ainsi que la pièce maitresse de tout moteur de recherche : le schéma d'indexation et ses implications. 

Enfin, nous constaterons que les archives Web ne sont pas des traces directes du Web vivant, mais plutôt les traces directes des crawlers. Nous donnerons ainsi des exemples d'artéfacts de crawl, présents dans les archives de l'Atlas e-Diasporas et qui, à nos yeux, sont des freins majeurs à toute exploration large des corpus. Ce sera l'occasion de porter un regard critique sur les archives telles que nous les connaissons et d'ouvrir la voie à une exploration fragmentée du Web passé.\\


\section{Détruire pour mieux archiver}
\label{sec:4_derrida}

\noindent J.L. Borges ouvre la seconde partie de son recueil de nouvelles \textit{Fictions} \citep{borges_fictions_1974} par un court texte intitulé \textit{Funes ou la mémoire}. Il y fait le compte rendu concis de la rencontre entre son narrateur et le mystérieux Irénée Funes, personnage ayant la capacité de ne rien oublier, jamais. Funes a une mémoire prodigieuse : \\

\begin{fullwidth}
\og\textit{En effet, non seulement Funes se rappelait chaque feuille de chaque arbre de chaque bois, mais chacune des fois qu'il l'avait vue ou imaginée. Il décida de réduire chacune de ses journées passées à quelque soixante-dix mille souvenirs, qu'il définirait ensuite par des chiffres. Il en fut dissuadé par deux considérations : la conscience que la besogne était interminable, la conscience qu'elle était inutile. Il pensa qu'à l'heure de sa mort il n'aurait pas fini de classer tous ses souvenirs d'enfance.}\fg{} --- \citep[p.116-117]{borges_fictions_1974}\\
\end{fullwidth}

\noindent L'esprit de Funes est engorgé de souvenirs d'une infinie précision, enregistrés en continus. Mais la mémoire pour fonctionner, nous dit Borges, a besoin d'oublier, de sélectionner et de généraliser. C'est en substance la thèse soutenue par J. Derrida qui décrit le geste de l'archiviste comme un geste de pouvoir : le pouvoir de choisir ce qui doit être préservé ou non. L'archivage est le résultat d'une sélection féroce qui doit détruire avant de sauver : \og\textit{Il n'y a pas d'archives sans destruction, on choisit, on ne peut pas tout garder.}\fg{} \citep[p.60]{derrida_trace_2014}. C'est ainsi que l'organisation légitime de l'héritage collectif revient aux seuls archivistes qui définissent au présent la mémoire de demain, en classifiant et hiérarchisant dans les bibliothèques les traces de nos expériences passées. Ce faisant, pour Derrida \og\textit{l'archive commence là où la trace s'organise, se sélectionne}\fg{} \citep[p.61]{derrida_trace_2014}, car toute expérience finit tôt ou tard par s'effacer, il en va de sa nature même. Ainsi, pour maintenir le lien qui nous renvoie à ce qui n'est plus là, il faut archiver nos traces avant qu'elle ne disparaissent. 

Le Web vivant est tout autant un flux continu d'information qu'un territoire en perpétuelle expansion (Section~\ref{sec:2_web}). Pour en archiver les traces, il faut procéder par \textbf{discrétisation}, c'est-à-dire : diviser une forme continue en une ou plusieurs valeurs individuelles. Les systèmes de stockage WARC et DAFF (Section~\ref{sec:3_constituer}) réduisent le Web en un ensemble discret de pages archivées. Or, depuis le lancement d'AltaVista en 1995\footnote{\RaggedOuter AltaVista fut le plus important moteur de recherche pré-Google, capable d'indexer une grande partie des pages du Web et de les rendre accessibles via des requêtes plein-texte (\url{https://en.wikipedia.org/wiki/AltaVista}).}, la page Web est considérée comme valeur élémentaire d'indexation, de fouille et d'exploration de la toile. Il en va de même pour les archives Web pour qui la page demeure l'unité de base de toute collecte. Ainsi, dans la suite de ce manuscrit, nous schématiserons une campagne de crawl comme telle : 

Un site Web archivé consiste en \textit{n} pages Web numérotées $\{p_1$,...,$p_n\}$. Un corpus d'archives Web est le résultat d'un ou plusieurs crawls successifs $\{c_1$,...,$c_l\}$. Nous appelons crawl $c_i$ le processus de collecte des pages Web $\{p_1$,...,$p_n\}$ d'un site Web donné. Le temps nécessaire au téléchargement des pages est supposé négligeable. Nous appelons $t_i(p_j)$ la date de téléchargement de la page $p_j$ au cours du crawl $c_i$. La première date de téléchargement d'une page $p_j$ est, enfin, notée $\min\limits_{i} t_i(p_j)$. La Figure~\ref{fig:discret} illustre cette mécanique pour les pages $p_1, p_2, p_3$, l'ordre de crawl entre deux collectes et la fréquence des visites pouvant, par ailleurs, varier. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/discretisation}
  \caption{Archivage (cercles bleus) des pages $p_1, p_2, p_3$ au cours de deux crawls $c_1, c_2$}
  \label{fig:discret}
\end{figure*}

\section{Un temps sans durée}
\label{sec:4_temporalite}

\noindent Au cours d'une collecte, les pages archivées sont propulsées dans une nouvelle temporalité. Elles n'ap\-partiennent plus au temps présent du Web vivant, mais au temps figé des archives passées. Comment dès lors capturer le temps présent ? Cette question nous ramène à Saint Augustin, dont l'expression du  présent à partir de l'instant influence encore aujourd'hui la pensée occidentale. Pour saint Augustin, le présent est une suite infinie de points élémentaires, des instantanés sans étendue :\\ 

\begin{fullwidth}
\og\textit{[\ldots{}] Et cette même heure se compose elle-même de parcelles fugitives. Tout ce qui s'en détache, s'envole dans le passé; ce qui en reste est avenir. Que si l'on conçoit un point dans le temps sans division possible de moment, c'est ce point-là seul qu'on peut nommer présent. Et ce point vole, rapide, de l'avenir au passé, durée sans étendue; car s'il est étendu, il se divise en passé et avenir. Ainsi, le présent est sans étendue.}\fg{} ---  \citep[livre XI, chap. XV, 20]{saint_augustin_confessions_421}\\
\end{fullwidth}

\noindent Le présent se déploie sous nos yeux comme un temps insaisissable qui, à peine éprouvé, cesse déjà d'exister pour se diluer dans le passé. La seule manière de le capturer reste donc de le diviser et de le réduire à ses plus petits éléments. Ainsi en va-t-il des archives Web qui sont, par construction, des instantanées du Web vivant : une suite de blocs DAFF régulièrement collectés et associés à des date de téléchargement. 

Mais dans le temps des archives il n'y pas de durée. Toute page collectée n'a d'étendue temporelle que sa seule date de téléchargement. Sur ce point, l'un des enjeux des explorations à venir sera justement de réinstaller de la durée dans les corpus archivés. Les phénomènes que nous souhaitons observer et étudier ont besoin d'être rapportés à une durée. Que l'on parle de l'évolution lente d'une communauté de bloggeurs ou de l'éruption soudaine d'un événement dans un forum de discussion, il faudra à chaque fois pouvoir en éprouver l'étendue dans le temps. 

Pour réintégrer de la durée dans les archives, nous nous proposons de discuter de la notion de \textbf{persistance}. Une page archivée sera dite persistante si d'une version à l'autre, son contenu reste inchangé. Dans la formalisme DAFF, les données des pages sont identifiées par des clés SHA-256 (Section~\ref{sec:3_constituer}). Ces clés sont des signatures uniques construites à partir du contenu même des pages archivées. Ainsi, en comparant les deux clés SHA-256 de deux versions successivement crawlées d'une même page, il est possible de savoir si cette page a évolué ou non. Par ce procédé, nous pouvons identifier des chaînes de persistance entre différents collectages.

Chaque chaîne de persistance s'ouvre sur une date de \textbf{dernière modification}. Nous appelons ainsi $\mu_i(p_j)$ la date de dernière modification d'une page $p_j$ au cours d'un crawl $c_i$, avec $\mu_i(p_j) \leq t_i(p_j)$. Par définition, au sein d'un même crawl, la date de dernière modification d'une page précédera toujours (ou sera égale à) sa date de téléchargement. La Figure~\ref{fig:last_modified} donne à voir des chaînes de persistance entre les multiples captures de la page $p_1$. Notons tout de même, que nous faisons ici l'hypothèse qu'il n'existe pas de changements cachés\footnote{\RaggedOuter Par exemple, un article est publié sur une page puis supprimé dans la foulée, et ce, entre deux crawls successifs.} entre deux versions identiques de la même page.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/last_modified}
  \caption{Chaînes de persistance entre captures (bleu) et dates de dernière modification (rouge) pour la page $p_1$}
  \label{fig:last_modified}
\end{figure*}

\noindent Intuitivement, il devient alors possible de dire d'une page archivée qu'elle n'a pas évolué depuis telle ou telle collecte, qu'elle a duré dans le temps. De plus, grâce aux chaînes de persistance, la datation des corpus d'archives Web s'affine, se fait plus précise. Une page ne sera plus maintenant seulement rapportée à sa seule date de téléchargement mais également à sa date de dernière modification, potentiellement bien antérieure. La Table~\ref{tab:datation_1} propose ainsi une échelle de datation, utile pour évaluer la précision historique d'un élément du Web passé dont l'unité d'analyse reste, pour le moment, la page Web :\\

\begin{table}
\hspace{2em}%
  \label{tab:datation_1}
  \begin{tabular}{lll}
    \toprule
    Unité & Nature de la date &\\
    \midrule
    page&lancement du crawl & \tikzmark{start}\\
    page&téléchargement &\\
    page&dernière modification & \tikzmark{end}\\         
  \bottomrule
\end{tabular}
  \bigskip
  \caption{Échelle de datation d'une page Web archivée}
\end{table} 

\begin{tikzpicture}[overlay,remember picture]
\draw[->] let \p1=(start), \p2=(end) in ($(\x1,\y1)+(0.8,0.2)$) -- node[label={[xshift=2.0cm, yshift=-0.3cm]précision historique}] {} ($(\x1,\y2)+(0.8,0)$);
\end{tikzpicture}

\noindent En nous appuyant sur cette grammaire, nous souhaitons maintenant discuter de trois biais majeurs dont il faut prendre connaissance avant de débuter toute exploration.

\subsection{Cécité de crawl}

\noindent À ce que nous appelons \textbf{cécité de crawl}\footnote{\RaggedOuter \textit{Crawl blindness} en anglais} correspond l'ensemble des changements subis par une page Web mais non captés par le crawler ou, tout au moins, mal daté par ce dernier. C'est une notion assez intuitive, dont nous donnons une illustration avec la Figure~\ref{fig:crawl_blind}. Dans cet exemple, une page $p_1$ subit quatre évolutions successives $e_1, e_2, e_3, e_4$ correspondant respectivement à : la publication d'une image accompagné d'un texte ($e_1$ puis $e_2$), la publication d'une seconde image directement suivie par sa suppression ($e_3$ puis $e_4$). Aux yeux de l'explorateur seul le résultat de $e_2$ restera gravé dans les archives (points bleus). Jamais il n'aura connaissance de l'état $e_1$ ni même de l'existence de $e_3$.     

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/crawl_blind}
  \caption{Cécité de crawl pour une page $p_1$}
  \label{fig:crawl_blind}
\end{figure*}

\noindent Ces loupés sont essentiellement dus à la difficulté de calibrer un crawler vis-à-vis de la fréquence de mise à jour d'un site (Section~\ref{sec:3_constituer}).

\subsection{Cohérence entre pages}

\noindent Dans les archives discrétisées du Web, deux pages collectées ne sont pas forcément cohérentes entre elles. Prenons l'exemple de deux pages du Web vivant connectées par un lien de citation hypertexte. L'une citant l'autre. Depuis la présentation de l'Atlas e-Diasporas (Section~\ref{sec:2_atlas}), nous savons à quel point la nature de ces liens est importante aux yeux des sociologues et des historiens.

Mais qu'en est-il, si dans les archives la capture de ces sites est espacée de plusieurs mois ou de plusieurs années ? Ce lien a-t-il encore du sens ? Peut on dire que ces pages sont toujours cohérentes entre elles ? Sur ce point, M. Spaniol \citep{spaniol_data_2009} propose une définition générale de la \textbf{cohérence} entre deux pages archivées, ainsi :

\begin{itshape}
\begin{enumerate}[leftmargin=*]  
\item Une page est toujours cohérente avec elle même
\item L'intervalle d'invariance $[\mu_i(p_j),\mu^*_i(p_j)]$ de la page $p_j$ est borné par la date de dernière modification $\mu_i(p_j)$ par rapport à $ t_i(p_j)$ et le prochain changement $\mu^*_i(p_j)$ subit par $p_j$ directement après $t_i(p_j)$
\item Deux pages ou plus sont cohérentes si il existe un seul point dans le temps (ou un intervalle) $t_{\mathrm{coherence}}$ tel que l'on puisse trouver une intersection non vide des intervalles d'invariance de toutes ces pages :
\end{enumerate}
\[
	\forall p_j, \exists t_{\mathrm{coherence}}:t_{\mathrm{coherence}} \in \bigcap_{j}[\mu_i(p_j),\mu^*_i(p_j)] \neq \emptyset
\]
\end{itshape}

\noindent La cohérence, telle qu'énoncée ici, est une cohérence absolue et théorique. Or, en pratique il est impossible d'anticiper la date de prochain changement $\mu^*_i(p_j)$, celle-ci étant inconnue au moment du crawl\footnote{\RaggedOuter Le crawler ne connait que les changements antérieurs à sa propre campagne de collecte.}. Ce faisant, une autre notion doit être introduire \citep{spaniol_data_2009}. Nommée \textbf{cohérence par observation}\footnote{\RaggedOuter \textit{Observable coherence} en anglais}, elle est définie comme suit :\\

\begin{itshape}
\noindent Deux pages ou plus sont cohérentes par observation, si il existe un seul point dans le temps $t_{\mathrm{coherence}}$ tel que l'on puisse trouver une intersection non vide d'intervalles couvrant respectivement la date de téléchargement $t_i(p_j)$ et la date de dernière modification correspondante $\mu_i(p_j)$ (avec $\mu_i(p_j) \leq t_i(p_j)$) :
\[
	\forall p_j, \exists t_{\mathrm{coherence}}:t_{\mathrm{coherence}} \in \bigcap_{j}[\mu_i(p_j),t_i(p_j)] \neq \emptyset
\]
\end{itshape}

\noindent La Figure~\ref{fig:coherence} illustre, la notion de cohérence par observation entre deux pages crawlées $p_1$ et $p_2$. Les intervalles d'invariance respectifs de chacune de ces pages se chevauchent et forme un \textbf{intervalle de cohérence} non vide, $p_1$ et $p_2$ sont donc cohérentes entre elles.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/coherence_observation}
  \caption{Cohérence par observation entre les pages $p_1$ et $p_2$ et intervalle de cohérence (jaune)}
  \label{fig:coherence}
\end{figure*}

\noindent Rappelons que les définitions de cohérence et de cohérence par observation sont proposées dans le cadre d'un crawl unique et en cours de collecte, il pourrait être intéressant d'étendre leurs énoncés dans le cas de plusieurs crawls successifs et terminés.

\newpage

\subsection{Contenus dupliqués}

\noindent L'une des particularités du formalisme DAFF est justement de ne pas dupliquer dans les archives des ressources Web qui n'auraient pas évolué (Section~\ref{sec:3_constituer}). Seules les pages ayant subi une transformation sont ainsi re-collectées. Néanmoins, d'un crawl à l'autre, il est possible qu'une partie du contenu de la page soit similaire à la version précédemment capturée et ce malgré les divers changements qu'elle aurait pu subir. On pense notamment aux pages d'accueil des sites d'actualités ou des forums qui présentent des informations publiées sous la forme de listes où chaque nouvel élément est inséré en en-tête. Mécaniquement certains éléments peuvent se retrouver, à plusieurs reprises, enregistrés dans les archives comme le présente la Figure~\ref{fig:duplicate}.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/duplicate}
  \caption{Contenu d'une page (en rouge) collecté plusieurs fois}
  \label{fig:duplicate}
\end{figure*}

\noindent Cela peut poser de lourds biais d'analyse si l'on cherche par exemple à connaitre la distribution d'un mot-clé extrait des pages archivées. Ce dernier pourra, du fait de la structure même du corpus, être artificiellement sur-représenté dans les résultats. 

\section{Construire un moteur d'exploration d'archives Web}
\label{sec:4_moteur}

\noindent Ces différents biais maintenant présentés, nous pouvons nous tourner vers la description de l'architecture de notre moteur d'exploration d'archives Web. Nos corpus étant en DAFF, il n'a pas forcément été possible de réutiliser des éléments open-source issus d'autres moteurs (quasiment tous conçus pour accueillir du WARC). De fait cette section est intéressante pour qui souhaite mettre en place ou comprendre dans le détail la mécanique d'une tel système. Notre architecture suit néanmoins la structure classique d'une chaîne d'extraction, d'analyse et de visualisation de données à grande échelle \citep{marz_big_2015}. La Figure~\ref{fig:architecture} donne à voir une illustration de son fonctionnement.  Il s'agira donc ici d'une description plutôt orientée ingénierie dont la majeure partie a fait l'objet d'une publication démonstration\footnote{\RaggedOuter Lobbé, Q. (2018), \textit{Revealing Historical Events out of Web Archives}, TPDL 2018}.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/architecture}
  \caption{Architecture de notre moteur d'exploration d'archives Web}
  \label{fig:architecture}
\end{figure*}

\subsection{Extraction et enrichissement}

\noindent Nous suivons ici l'hypothèse selon laquelle notre moteur doit rendre accessible les archives Web d'une seule e-Diaspora à la fois. Nous prendrons comme exemple les archives du corpus marocain.
 
La première étape consiste à extraire les informations contenues dans les fichiers DAFF. Rappelons que chaque corpus est divisé en deux fichiers DAFF : les données d'une part (\textit{data}) et les méta-données (\textit{metadata}) d'autre part. Pour ce faire, nous commençons par adapter une librairie Java (fournie par les équipes de l'INA, \textit{dlweb-commons}) qui cherche à transférer les archives des fichiers DAFF vers le système de stockage d'Hadoop\footnote{\RaggedOuter \url{https://hadoop.apache.org/}, \url{https://fr.wikipedia.org/wiki/Hadoop}}, le Hadoop Distributed File System (HDFS). Le HDFS est un système de fichiers qui permet de manipuler de larges volumes de données, de manière distribuée (c.-à-d., réparti entre plusieurs machines) et passant relativement bien à l'échelle (pouvant supporter une forte montée en charge). Le format DAFF a ceci de limitant, qu'il reste pensé pour le stockage et non pour la manipulation des données. Filtrer un fichier DAFF par URL ou date de téléchargement n'est, par exemple, pas trivial.

Une fois chargées dans le HDFS, les données et méta-données DAFF sont envoyées dans un système de traitement nommé Spark\footnote{\RaggedOuter \url{https://spark.apache.org/}}. Spark permet de travailler par batchs (c.-à-d., par petits lots de données) dans un environnement distribué : les données et méta-données sont segmentées en sous-ensembles plus facilement manipulables, puis répartis sur plusieurs machines où elles subissent toutes les mêmes traitements en parallèle (filtres, jointure, groupement, etc.). Spark est un outil flexible dans lequel nous pouvons définir une suite d'instructions (ou \textit{pipeline}) ayant pour finalité la fusion des données et méta-données DAFF en une seule et même source de données d'archives. La Figure~\ref{fig:spark} décrit la manière dont s'enchainent ces diverses transformations. Les méta-données sont traitées en premier et peuvent suivant la configuration du système être filtrées par date de téléchargement ou nom de domaine (par site Web). Puis, en nous rappelant que les méta-données possèdent chacune un pointeur vers le bloc de données DAFF dont elles sont l'extension (champ \textit{content} en DAFF, Section~\ref{sec:3_constituer}), nous remplaçons l'identifiant des méta-données par l'identifiant du bloc de données correspondant. Cette manipulation nous permet ensuite de grouper les méta-données par identifiants communs, c'est-à-dire, toutes les méta-données d'une seule et même chaine de persistance (Section~\ref{sec:4_temporalite}). 

C'est à cette étape que nous identifions notamment les dates de dernière modification. De là, nous opérons une jointure entre les méta-données et données DAFF afin de rassembler enfin les informations issues du crawler et le contenu même des pages archivées. Pour terminer, nous préparons ces nouvelles données à être envoyées dans le moteur de recherche, sans oublier de les enrichir avec des informations tirées de l'Atlas e-Diasporas (type de sites, langue, etc.).  

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/spark}
  \caption{Pipeline de transformation des données et méta-données DAFF}
  \label{fig:spark}
\end{figure*}

\noindent Deux configurations différentes ont été testées pour Spark, l'une distribuée entre plusieurs machines d'un même \textit{cluster} (c.-à-d., un groupe de machines), l'autre distribuée sur l'ensemble des cœurs d'une seule machine puissante. Si la première configuration s'est révélée la plus rapide (traitement de l'ensemble du corpus marocain en 3 jours), il a fallut néanmoins s'en détourner. En effet, Spark étant particulièrement dur à piloter sur un réseau souvent instable, il était fréquent de voir le traitement des données s'arrêter après avoir perdu connexion avec une ou plusieurs machines. De fait, nous avons préféré nous contenter de la seconde configuration, plus lente (une dizaine de jours) mais garantissant la totalité du traitement\footnote{\RaggedOuter Notre système est téléchargeable ici-même \url{https://github.com/lobbeque/archive-miner}}. 

\subsection{Adapter un moteur de recherche}

\noindent Au cours de la Section~\ref{sec:3_constituer}, nous avons présenté l'ensemble des méthodes aujourd'hui utilisées pour consulter des corpus d'archives Web. La plupart d'entre elles, s'appuient sur l'utilisation de moteurs de recherches qui offrent la possibilité d'interroger une base de documents\footnote{\RaggedOuter Les données manipulées par des moteurs de recherche sont de manière générale appelées \textbf{documents}.} en plein texte. De notre côté, nous avons choisi d'adapter, à la nature particulière de nos archives Web, une solution open-source existante nommée Solr/Lucene. 

Solr\footnote{\RaggedOuter Voir \citep{grainger_solr_2014} et \url{http://lucene.apache.org/solr/}} est un serveur de \textit{search}, c'est-à-dire qu'il permet de faire le lien entre une requête utilisateur (un mot-clé, une dimension, etc.) et un ensemble de documents préalablement indexés. Solr est construit au-dessus de la librairie d'indexation Lucene\footnote{\RaggedOuter Voir \citep{hatcher_lucene_2004} et \url{http://lucene.apache.org/index.html}} dont le principe de base est de stocker un texte dans un \textbf{index inversé}.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/index}
  \vspace*{0.2cm}  
  \caption{Principe de base d'un index inversé}
  \label{fig:index}
\end{marginfigure} 


Le fonctionnement simple d'un index inversé est illustré par la Figure~\ref{fig:index}. Un premier tableau de données (a) renferme le contenu de deux documents $doc 1$ et $doc 2$ dont les identifiants (\textit{doc id}) sont respectivement $0$ et $1$. Un second tableau de données (b) contient ce que l'on appelle un dictionnaire de termes (\textit{term dict}). Dans ce dictionnaire, sont répartis l'ensemble des mots uniques (numérotés de $0$ à $4$) contenus dans les documents $0$ et $1$. Ces mots sont identifiés par des \textit{term ids} et sont, de plus, associés à une \textit{posting list} qui fait correspondre à chaque mot la liste des documents où il est présent. 

Ainsi, pour réaliser une recherche plein texte, il suffira de parcourir l'ensemble du dictionnaire jusqu'à trouver les mots correspondant à la requête de l'utilisateur et, par extension, les documents associés. Ces deux tableaux de données (a) et (b) forment ce que l'on appelle un \textbf{segment}, soit le bloc de base de tout index inversé. On nomme \textbf{indexation} l'action de stocker un texte dans un index inversé. Différentes stratégies peuvent être mises en place pour accélérer la recherche dans un index, en optimiser la taille, etc.\footnote{\RaggedOuter Pour de plus amples détails sur l'indexation via Lucene/Solr, voir mon cours sur le fonctionnement interne des moteurs de recherche (Lobbé, Q. 2016, Voyage au cœur d'un index Lucene, \url{http://qlobbe.net/ressources/search.pdf}).}. 

Un moteur de recherche se doit d'ordonner ses résultats avant de les retourner à l'utilisateur. On nomme cette étape le \textbf{classement} (\textit{ranking}). Pour cela, il fait appel à une \textbf{fonction de similarité} qui trie les documents résultants en leur attribuant à chacun un score. Parmi les nombreux critères de ranking, les systèmes de search favoriseront souvent les documents où les mots clés recherchés sont les plus fréquents. Cette mesure sera pondérée par l'ajout d'une prime aux termes rares, c'est-à-dire : peu présents dans l'ensemble des index. C'est tout le sens du fameux \textit{tf-idf}\footnote{\RaggedOuter \textit{Term frequency-inverse document frequency}, fonction de similarité qui évalue l'importance d'un terme dans un document au regard d'un corpus donné (\url{https://fr.wikipedia.org/wiki/TF-IDF}).} dont nous réutilisons ici une version légèrement modifiée : la \textit{defaultSimilarity} de Lucene\footnote{\RaggedOuter En plus du simple tf-df, cette fonction de similarité prend en compte la taille du document et la taille des champs vérifiant la requête (\url{https://frama.link/RsYNvx-6}).}. 

Nous n'avons pas eu l'occasion de tester une fonction de similarité propre aux archives Web, la nôtre est finalement très générique. C'est pourtant une question  intéressante, puisque comme le suggère \citep{weikum_longitudinal_2011} les moteurs d'exploration d'archives pourraient prendre en compte l'aspect temporel des documents collectés pour procéder au classement des résultats. 

\subsection{Le schéma d'indexation}

\noindent Tout document destiné à l'indexation doit d'abord passer au crible du \textbf{schéma} qui est considéré comme la pierre angulaire de tout moteur de recherche. 

Le schéma est un fichier décrivant dans le détail la façon dont tout document sera indexé, il forme l'ossature de l'indexation. En effet, un document n'est pas indexé d'un seul tenant. Pour maximiser les chances de le voir satisfaire une requête, il peut être nécessaire de le découper en plusieurs \textbf{champs} (\textit{fields}), ayant chacun des attributs particuliers. Par exemple, un article issu d'un site de news pourra être segmenté suivant son titre, sa date, l'auteur et finalement le cœur du texte. Ce dernier sera indexé de manière classique en vue d'une recherche plein texte, l'auteur en revanche pourra être destiné à une recherche par \textit{facet}, c'est-à-dire par \textbf{dimension } (par exemple : Quels sont les textes de tel ou tel auteur ?). Si tel est le cas, son indexation se fera via des \textit{docValues}\footnote{\RaggedOuter \url{https://lucene.apache.org/solr/guide/6_6/docvalues.html}}. Dans notre schéma, la plupart des informations issues du fichier de méta-données DAFF sont destinées à une recherche par dimension, telles que :\\


\begin{fullwidth}
\small
\begin{verbatim}
<!-- archive fields -->
<field name="id"                type="string"  indexed="true"    multiValued="false" required="true" />
<field name="archive_active"    type="boolean" indexed="true"    multiValued="false"/>
<field name="archive_corpus"    type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_ip"        type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_length"    type="double"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_level"     type="int"     indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_referer"   type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_mime"      type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="is_page"           type="boolean" indexed="true"    multiValued="false" default="false"/>    

<!-- client fields -->
<field name="client_country"    type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="client_ip"         type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="client_lang"       type="string"  indexed="true"    docValues="true" multiValued="true" />

<!-- crawl fields -->
<field name="crawl_id"          type="string"  indexed="true"    docValues="true" multiValued="true" />
<field name="crawl_id_f"        type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="crawl_id_l"        type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="crawl_date"        type="date"    indexed="true"    docValues="true" multiValued="true" />
<field name="crawl_date_f"      type="date"    indexed="true"    docValues="true" multiValued="fasle"/>
<field name="crawl_date_l"      type="date"    indexed="true"    docValues="true" multiValued="true" />
\end{verbatim} 
\end{fullwidth}

\newpage
\begin{figure*}
\begin{fullwidth}
\small
\begin{verbatim}
<!-- download fields -->
<field name="download_date"     type="date"    indexed="true"    docValues="true" multiValued="true" />
<field name="download_date_f"   type="date"    indexed="true"    docValues="true" multiValued="false"/>
<field name="download_date_l"   type="date"    indexed="true"    docValues="true" multiValued="false"/> 

<!-- page fields -->
<field name="page_site"         type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="page_url"          type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="page_url_id"       type="string"  indexed="true"    docValues="true" multiValued="false"/>      

<!-- extracted page fields -->
<field name="page_link"         type="string"  indexed="true"    docValues="true"  multiValued="true"/>     
<field name="page_meta_title"   type="string"  indexed="true"    docValues="false" multiValued="false"/>
<field name="page_meta_desc"    type="text"    indexed="true"    docValues="false" multiValued="false"/>
<field name="page_meta_img"     type="string"  indexed="true"    docValues="false" multiValued="false"/>
<field name="page_meta_date"    type="date"    indexed="true"    docValues="true"  multiValued="false"/>    
<field name="page_meta_author"  type="string"  indexed="true"    docValues="true"  multiValued="false"/>    
<field name="page_title"        type="text"    indexed="true"    docValues="false" multiValued="false"/>

<!-- searchable page fields -->
<field name="page_text"         type="text"    indexed="true"  stored="false" multiValued="true"/>
<field name="page_text_shingle" type="shingle" indexed="true"  stored="false" multiValued="true"/> 
\end{verbatim} 
\end{fullwidth}
\caption{Schéma d'indexation de notre moteur d'exploration d'archives Web}
\label{fig:schema_1}
\end{figure*}

\noindent Pour chaque champ, nous définissons un nom et un type : une date, un nombre (int), du texte (string et text)\ldots{} Tous les champs sont indexés (\texttt{indexed="true"}). Ceux destinés à une recherche par dimension sont associés à une docValue. Certain champs, comme les dates de téléchargement, sont multivalués (une page peut avoir été crawlée plusieurs fois à l'identique). Le champ de recherche plein text par défaut est le champ page\_text qui couvre l'ensemble du texte d'une page archivée\footnote{\RaggedOuter Ce champ subit un traitement particulier (un découpage en bi-gramme : page\_text\_shingle) dont nous reparlerons en Section~\ref{sec:retour_au_moteur}}. Dans Spark, lors de la transformation des DAFF en document Solr, nous extrayons les liens de citation hypertextes (\texttt{page\_link}) et les informations contenues dans l'en tête des pages\footnote{\RaggedOuter Tout ce qui est contenu dans les balises HTML \textit{<meta>} (\url{https://www.w3schools.com/Tags/tag_meta.asp})} (\texttt{page\_meta\_img}, \texttt{page\_meta\_date}, etc.). Les diverses dates associées à une page sont également présentes : allant de la date de lancement du crawl (\texttt{crawl\_\-date\_f}), à la date de téléchargement (\texttt{download\_date}) et en passant par la date de dernière modification (\texttt{download\_date\_f})\footnote{\RaggedOuter Nous avons, un temps, intégré à notre schéma les information de l'en-tête HTTP des pages archivées. Mais étant trop peu fiable, nous avons décidé de ne plus les prendre en compte.}.

Mais les documents à indexer ne sont pas les seuls à devoir passer par le schéma. En effet, un moteur de recherche est un système à double entrée (Figure~\ref{fig:architecture}), conjuguant des documents et des requêtes utilisateurs grâce à une fonction de similarité. Pour ce faire, documents et requêtes doivent parler la \textit{même langue}, c'est-à-dire qu'une requête utilisateur devra être traitée de la même manière que les documents à indexer, subir les mêmes transformations et interroger les bons champs. Cette suite de transformations est appelée \textbf{analyzer}\footnote{\RaggedOuter Pour plus d'informations sur les analyzers et tokenizers dans Solr: \url{https://wiki.apache.org/solr/LanguageAnalysis}}. Sur ce point, documents et requêtes suivent les traitements suivants : tout d'abord, les majuscules deviennent minuscules (Figure~\ref{fig:tokenizer}, (a)), puis le texte est découpé en termes distincts (Figure~\ref{fig:tokenizer}, (b)) et les \textit{stopwords}\footnote{\RaggedOuter Mots qui ne sont généralement pas intéressants pour l'analyse : et, il, elle\ldots{} (voir \url{https://fr.wikipedia.org/wiki/Mot_vide})} sont écartés (Figure~\ref{fig:tokenizer}, (c)), s'en suit une phase appelée \textbf{stemming} dans laquelle on ne garde finalement que la racine des termes restants (Figure~\ref{fig:tokenizer}, (d)) avant indexation (Figure~\ref{fig:tokenizer}, (e)).

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/tokenizer}
  \caption{Cycle de transformation d'un texte dans notre moteur de recherche}
  \label{fig:tokenizer}
\end{figure}

\noindent Dans le cas particulier des archives Web, l'exploration de pages collectées peut être focalisée autour d'un instant précis. Si l'utilisateur en fait la demande, notre moteur lui proposera différentes stratégies de recherche pour retrouver les pages les plus proches d'une date donnée: soit en amont (Figure~\ref{fig:date-picker}, (a)) , soit en aval (Figure~\ref{fig:date-picker}, (c)) ou soit autour de cette dernière (Figure~\ref{fig:date-picker}, (b)). Internet Archive par exemple utilise la première option dans la WayBack Machine.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/date-picker}
  \caption{Stratégies de choix d'un ensemble de pages par rapport à une date précise}
  \label{fig:date-picker}
\end{figure*}

\noindent Notre moteur de recherche est finalement déployé sur les serveurs. Les index sont distribués entre plusieurs machines pour améliorer les temps de réponse et d'indexation du système. On appelle \textbf{sharding} l'action de scinder un index en plusieurs sous-index avant de les distribuer. Nous suivons une configuration classique \textit{maître--esclave}\footnote{\RaggedOuter \url{https://lucene.apache.org/solr/guide/6_6/solrcloud.html}} où l'instance maître de notre moteur de recherche centralise les requêtes utilisateur avant de les dispatcher entre ses diverses instances esclaves qui, elles seules, sont habilitées à retourner des résultats\footnote{\RaggedOuter Notre moteur de recherche peut être téléchargé ici \url{https://github.com/lobbeque/archive-search}}. 

\subsection{Interface de visualisation}

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/gui}
  \caption{Capture d'écran de notre interface de visualisation}
  \label{fig:gui}
\end{figure*}

\noindent Une système de visualisation et d'interrogation des archives est dé\-veloppé\footnote{\RaggedOuter Nommé \textit{Peastee} en référence au narrateur de la nouvelle de H.P. Lovecraft \textit{The Shadow Out of Time} (1935), ce système est téléchargeable ici \url{https://github.com/lobbeque/peastee}} au-dessus de notre moteur. Il s'agit en fait d'une \textit{application Web} permettant à tout utilisateur d'écrire une requête et de se voir présenter les résultats sous diverses formes. Une application Web est composée de deux briques logicielles distinctes : un serveur en \textit{node.js}\footnote{\RaggedOuter \url{https://nodejs.org/en/about/}} se charge tout d'abord de faire la liaison avec le moteur de recherche, une interface Web permet ensuite de visualiser les documents archivés. Les éléments de visualisation sont développés en \textit{d3.js} et l'architecture de l'interface en tant que telle se base sur \textit{angularjs}\footnote{\RaggedOuter D3 est une librairie Javascript de visualisation de données \url{https://d3js.org/}, Angular est un framework Javascript pour les applications Web \url{https://angularjs.org/}}. Notre interface suit un modèle \textit{en liste} très classique : les résultats sont présentés les uns à la suite des autres et des facets, à la marge, permettent de les filtrer ou de les trier après coup. Divers histogrammes offrent à voir une répartition dans le temps des pages archivées ayant correspondu à la requête de l'utilisateur. La Figure~\ref{fig:gui} présente une capture d'écran de cette interface, une démonstration en vidéo permet de se faire une idée plus précise de son fonctionnement\footnote{\RaggedOuter \url{https://youtu.be/snW4O-usyTM}}

Notre application Web accueille les nombreux prototypes que nous avons pu expérimenter tout au long de ces trois années de travail. Nous ne reviendrons pas ici en détail sur leurs développements respectif, mais, bien qu'incomplets ou inaboutis, ces prototypes restent des jalons qui nous ont permis de cheminer vers les résultats présentés au Chapitre~\ref{chap:6}. Nous retiendrons, premièrement, une visualisation \textit{en oursin} de l'arborescence des URL d'un site archivé mois après mois (Figure~\ref{fig:prototypes-1}). La racine d'un site (sa page d'accueil) est située au centre de l'oursin, plus on s'en éloigne et plus on est censé découvrir les diverses pages constitutives de ce site. 

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/prototypes-1}
  \caption{Prototypes de visualisation de la structure des URL d'un site archivé}
  \label{fig:prototypes-1}
\end{figure}

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/prototypes-2}
  \caption{Prototypes de visualisation des liens hypertextes produits par un site archivé}
  \label{fig:prototypes-2}
\end{figure}

\noindent Pour terminer, un autre prototype propose de voir la distribution temporelle (en abscisse) des liens hypertextes (en ordonnée) sortant d'un site archivé (Figure~\ref{fig:prototypes-2}, différenciés par catégories : réseaux sociaux, sites migrants e-Diasporas et reste du Web), la production de liens de citation pouvant être un bonne indicateur d'activité dans le temps. 

\section{Les archives ne sont pas des traces directes du Web}
\label{sec:4_legacy}

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/yabiladi-map}
  \vspace*{0.2cm}  
  \caption{\textit{yabiladi.com} (rouge) dans l'e-Diaspora marocaine (Section \ref{sec:2_atlas})}
  \label{fig:yabiladi-map}
\end{marginfigure} 

\noindent Notre moteur d'exploration maintenant présenté, nous voilà enfin en mesure d'interroger les archives de l'Atlas e-Diasporas. Depuis le Chapitre~\ref{chap:2}, le site \textit{yabiladi.com} et plus particulièrement son forum de discussion attire notre attention. De part la place qu'il occupe dans le corpus marocain depuis le début des années 2000, le site a su jouer un rôle clé pour l'ensemble de la diaspora en ligne. Notre première requête cherche donc à nous faire découvrir la répartition temporelle de \textit{yabiladi.com} dans les archives. Nous voulons saisir et comprendre la dynamique des publications postées sur sa section forum afin d'identifier des moments-clés de l'histoire du site. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/legacy-1}
  \caption{Distribution du nombre de pages archivées par jours pour \textit{yabiladi.com}}
  \label{fig:yabiladi-download}
\end{figure*}

\noindent Mais les résultats que nous retourne notre moteur d'exploration semblent très curieux, la Figure~\ref{fig:yabiladi-download} présente ainsi la répartition par jour, du nombre de pages forum collectées pour \textit{yabiladi.com}, de Mars 2010 à Septembre 2014. Ainsi, il semble que le site ait littéralement cessé de produire du contenu de Janvier 2013 à début 2014. Or, si l'on passe maintenant par la Wayback Machine\footnote{\RaggedOuter Voir \url{https://frama.link/Jv7WpLCJ}}, on se rend rapidement compte que chez, Internet Archive, des ressources Web ont bel et bien été capturées à ces même dates. Où se situe donc notre erreur ?

Nous interprétons nos résultats de la mauvaise manière. Depuis le début de ce chapitre, nous cherchons à mettre en évidence les nombreux biais d'analyse possibles pour qui souhaite mener à bien une exploration d'ar\-chives Web. Nous avons notamment évoqué les cécités de crawl (Section~\ref{sec:4_temporalite}), mais sans nous attendre à trouver dans nos propres corpus une telle défaillance. Après enquête auprès des équipes de l'INA, il s'avère que le crawler de l'institution a stoppé sa collecte de \textit{yabiladi.com} pendant toute une année, avant qu'archivistes et chercheurs ne s'en rendent compte et relancent le robot. Ce que la Figure~\ref{fig:yabiladi-download} donne à voir est un \textbf{artéfact de crawl}, c'est-à-dire un effet mécanique du crawler qui aura influencé la forme même du collectage, au delà du simple décalage ou de l'imprécision inévitable pour ce type de campagne. 

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{graphics/legacy-2}
  \caption{"Boulevard du Temple", Louis Daguerre, 1838}
  \label{fig:boulevard}
\end{figure*}

\noindent Les archives Web ne sont pas les traces directes du Web, elle sont les traces directes des crawlers. Les outils de collecte façonnent l'image de ce qu'ils sont supposés préserver. Ils en modifient la forme, potentiellement le fond, et par là même, la nature des interprétations que nous faisons du corpus si l'on n'y prend pas garde. Ce que l'on voit dans les archives reste avant tout le geste de l'archiviste et des ses dispositifs de capture. 

\begin{center}
	\textbf{***}
\end{center}

\noindent En 1838, L. Daguerre réalise un daguerréotype\footnote{\RaggedOuter Procédé photographique basé sur l'exposition à la lumière d'une surface d'argent pure (\url{https://fr.wikipedia.org/wiki/Daguerréotype}).}, le \textit{Boulevard du Temple}, qui est aujourd'hui reconnu comme l'une des première photographie figurant un être humain : deux hommes seuls dans une rue vide (Figure~\ref{fig:boulevard}). En réalité, le boulevard était ce jour là bondé. Demandant un temps d'exposition particulièrement long, les seuls sujets (en plus des bâtiments et des arbres) que le dispositif a su capturer sont ceux qui étaient restés pratiquement immobiles : un cireur de chaussures et son client assis devant lui. Cet exemple illustre parfaitement ce que nous rencontrons dans les archives Web. Associées à des dates de téléchargement qui les arrachent à leur temporalité, les archives Web sont des objets discrétisés et figés. Sans lien direct avec la réalité dont elles sont pourtant censées être le reflet. 

Afin d'améliorer la pertinence historique de nos analyses à venir et pour nous affranchir des crawlers et de leurs artéfacts, nous proposerons, dans la suite de cette thèse, de descendre sous le niveau des pages Web capturées et de nous appuyer sur une nouvelle unité d'explo\-ration des corpus archivés : le \textbf{fragment Web}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 5 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Fragmenter les archives Web}
\label{chap:5}

\par\noindent Les artéfacts de crawl sont indissociables des archives Web telles que nous les connaissons (Section~\ref{sec:4_legacy}). Ils sont liés organiquement à la structure même des ressources collectées (Section~\ref{sec:3_constituer}), issus de l'as\-sociation d'une page Web et d'une date de téléchargement. Ces artéfacts et leurs effets induisent nombres de biais pour qui souhaite explorer le Web passé : collectages non réguliers, sur-représenta\-tion de certaines parties d'un site, incohérences entre les contenus préservés, etc. 

Nos travaux portant sur l'exploration de corpus d'archives Web déjà existants ou constitués de longue date, nous ne proposerons pas ici d'alternative aux formats WARC et DAFF. Nous chercherons plutôt à définir, partant d'une collecte terminée, une stratégie d'analyse capable de s'affranchir de l'héritage pesant des crawlers ou, tout au moins, d'en atténuer les effets. Par ailleurs, nous souhaitons mener une exploration large (en terme de pages à visiter) et profonde (en terme de durée à balayer) de nos corpus d'archives Web. Mais, nous voulons aussi garder la possibilité de nous appuyer, au besoin, sur une analyse plus fine de certains éléments. Cela implique le développement d'une méthodologie hybride capable de débrayer du quantitatif vers le qualitatif. Cette approche s'articulera autour d'une nouvelle entité qui pourra faire cohabiter traitements algorithmiques à grande échelle et campagnes de validation humaine.

Aussi, nous proposerons dans ce chapitre de changer d'unité d'exploration en introduisant les \textbf{fragments Web}. Nous pensons, en effet, qu'il peut être bénéfique de mener une analyse au-dessous du niveau des pages Web archivées. Pour valider cette intuition, le fragment Web offrira aux explorateurs une plus grande souplesse et de nouveaux outils pour interroger les archives. Il se voudra également object d'étude à part entière. À travers les fragments Web, nous questionnerons directement le geste des auteurs et des lecteurs des sites collectés, en suivant les indices de leur passage sur la toile. Revenir à l'humain dissimulé sous les archives. Pour ce faire, nous porterons notre réflexion sur la question de la datation des archives Web en associant à chaque fragment une date d'édition. Ainsi, nous nous approcherons, au mieux, du Web tel qu'il a été de son vivant. Enfin, nous reviendrons en miroir sur les modalités techniques et théoriques d'un moteur d'exploration basé, cette fois-ci, sur le fragment Web comme unité principale d'indexation. Un cas simple de détection d'événements dans les archives Web nous permettra d'en faire la démonstration.

\section{En dessous des pages Web}
\label{sec:5_dessous}

\noindent Comme le résume \citep{weikum_longitudinal_2011}, les archives Web sont de véritables mines d'or pour qui souhaite étudier l'histoire du Web passé\footnote{\RaggedOuter \og\textit{These archives host a wealth of information, providing a gold mine for sociological, political, business, and media analysts.}\fg{} \citep{weikum_longitudinal_2011}}. Mais tout trésor est difficile d'accès et nous avons déjà évoqué, au regard de l'état de l'art (Section~\ref{sec:3_20ans}), à quel point les corpus archivés restaient pour nous des territoires inexplorés, repliés et fortifiés. 

L'archive est pourtant une matière qui ne doit pas rester fermée \citep{ketelaar_de_2006}, mais toujours prête à être questionnée. C'est au travers des lectures, discussions et interprétations successives des archives que s'écrit l'histoire. Pour plonger au cœur des archives Web, essayons d'ouvrir une brèche dans nos corpus afin d'y extraire une nouvelle entité. Ce fragment Web, comme nous le nommons, est issue de la segmentation des pages Web collectées. Sa construction s'appuie sur plusieurs éléments, plusieurs inspirations. Tout d'abord, il s'agira pour nous d'adopter une attitude plus souple vis-à-vis des archives en cherchant à les décomposer pour mieux les explorer. Ensuite, nous inscrirons les fragments dans la droite lignée des strates du Web au sens où les décrit N. Brügger. Nous nous attarderons alors sur la question de la datation des ressources collectées en introduisant les dates d'édition à notre grammaire. Nous nous servirons de ces dates pour finalement descendre vers une plus grande précision historique et ramener les archives vers la temporalité du Web passé.

\subsection{Découper, déplacer, monter}

\noindent Funes vit dans l'indexation d'un présent perpétuel (Section~\ref{sec:4_derrida}). Condamné à ne plus jamais rien oublier, il lui devient impossible de penser, de raisonner et de s'inventer :

\begin{fullwidth}
\og\textit{[Funes], ne l’oublions pas, était presque incapable d’idées générales, platoniques. Son propre visage dans la glace, ses propres mains, le surprenaient chaque fois. [\ldots{}] Penser c'est oublier des différences, c'est généraliser, abstraire. Dans le monde surchargé de Funes il n'y avait que des détails, presque immédiats.}\fg{} --- \citep[p.117-118]{borges_fictions_1974}\\
\end{fullwidth} 

\noindent Pour mémoriser il faut oublier. Ré-arranger et faire du montage. Nos souvenirs sont des sélections qui, mises bout à bout, collées, accélérées ou ralenties forment le fil de nos histoires et de nos vies. Nous décrivions en Section~\ref{sec:3_constituer}, comment les conditions d'accès aux archives Web rendaient difficile leur exploration par les chercheurs\footnote{\RaggedOuter Notons  néanmoins l'existante du projet \url{https://archivesunleashed.org/} et des outils développés par l'Omilab \url{https://github.com/omilab/}.}. Chevillées aux niveaux des seules pages Web les outils d'analyse existants (la Wayback Machine tout autant que notre propre moteur d'exploration, Section~\ref{sec:4_moteur}) ne nous permettent pas de manipuler les résultats de nos requêtes. Les archives sont consultables, certes, mais restent enfermées dans des \textit{interfaces-vitrines} plutôt que de nous être restituées sur des tables de montage. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/marker}
  \caption{C. Marker, 1977, Le Fond de l'Air est Rouge, (\url{https://youtu.be/dO1E4GYjF1s})}
  \label{fig:marker}
\end{marginfigure}

En achevant \textit{Le Fond de l'Air est Rouge} en 1977, le cinéaste C. Marker revient amer sur l'avènement des mouvements contestataires et révolutionnaires dans années 60, événements dont il a été le témoin direct. Il remonte ainsi et assemble 15 années de ses propres archives filmiques qu'il aborde sous un angle inédit : \og\textit{on ne sait jamais ce que l'on film, on ne sait jamais ce qu'il y a derrière une image}\fg{} (\textit{Le Fond de l'Air est Rouge}, Partie II, 14mn 22s) nous dit-il en voix off. Détachées de lui et faisant désormais partie de l'histoire, ses archives peuvent enfin être confrontées et ré-interrogées. En cela la posture de l'historien face à un document archivé se rapproche de celle du monteur de cinéma face à une matière filmée. Leurs outils sont semblables. Lorsqu'il invente l'histoire, l'historien découpe, isole et rapproche des sources archivées potentiellement très éloignées. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/godard}
  \caption{J.L. Godard, 1993, Je~Vous Salue, Sarajevo, (\url{https://youtu.be/WKbfu8rRrho})}
  \label{fig:godard}
\end{marginfigure}

Dans son court métrage \textit{Je Vous Salue, Sarajevo}, réalisé en 1993 pendant la Guerre de Bosnie-Herzégovine, J-L. Godard déconstruit une photographie du reporteur de guerre R. Haviv. Il fragmente cette image pour faire se correspondre des inserts éclatés à la manière d'un collage-poème ou d'un cinétract\footnote{\RaggedOuter Mini-films non signés à caractère militant, réalisés en mai et juin 1968 (\url{https://fr.wikipedia.org/wiki/Cin\%C3\%A9tract}) et influencés notamment par C. Marker.}. Par le collage, les fondus et les découpes Godard rompt la continuité de l'archive qu'il utilise comme source première. Il peut ainsi rendre compte, image après image, de la cruauté qui frappe les rues Sarajevo. Le film finit par dévoiler entière, l'image dans toute son horreur, \textbf{décomposer} pour mieux \textbf{recomposer}.\\

\noindent Il y a dans les travaux de Godard et de Marker une souplesse d'action vis-à-vis des archives que nous pourrions appliquer à nos propres corpus. Chercher à avoir en main des éléments fragmentés de pages Web éloignées, que nous pourrions associer, à souhait, afin de traiter plus largement d'un moment particulier de l'histoire du Web. Comment se donner la possibilité de rapprocher automatiquement deux contenus archivés hors du carcan de leurs pages Web respectives ? Peut-on ralentir ou accélérer le cours de nos archives ? 

\subsection{Les strates du Web}

\noindent Le glissement d'un niveau d'analyse à un autre, vers un en-dessous de la page archivée, est formulé pour la première fois par l'historien du Web N. Brügger lorsque, cherchant à définir le site Web comme objet potentiel de recherches historiques \citep{brugger_website_2009}, ce dernier en vient à introduire la notion de \textbf{strates analytiques du Web}\footnote{\RaggedOuter En anglais : \textit{analytical Web strata}.}.

Brügger suggère de construire un système d'analyse dynamique pour réajuster, au besoin, le périmètre d'une recherche portant sur le Web. L'observateur doit ainsi pouvoir passer d'un ensemble de sites à une page unique, voire descendre jusqu'aux éléments constitutifs de cette dernière (un texte, une image, etc.)\footnote{\RaggedOuter \og\textit{One can distinguish the following five analytical strata: the web as a whole; the web sphere; the individual website; the individual webpage; and an individual textual web element on a webpage}\fg{}, \citep[p.10]{brugger_website_2009}}. 
Cette approche, notons-le, n'est pas confinée au Web archivé, elle peut très bien s'adapter au Web vivant. Brügger définit ainsi 5 niveaux d'analyses, allant du  plus englobant au plus élémentaire, comme l'illustre la Figure~\ref{fig:web_strata}.

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{graphics/strata}
  \caption{Les 5 strates analytiques du Web, d'après \citep{brugger_website_2009}}
  \label{fig:web_strata}
\end{figure*} 

\noindent Le premier niveau englobe l'entièreté des sites du Web vivant (Figure~\ref{fig:web_strata}, (1)). Il inclut également les éléments de back-end (base de données, code côté serveur, etc.) et plus généralement l'ensemble de l'infrastructure physique du Web (serveurs, câbles réseaux, supports numériques, etc.). Une sphère Web désigne un ensemble de sites Web sélectionnés par un chercheur (Figure~\ref{fig:web_strata}, (2)). C'est une construction ad hoc motivée par une question de recherche donnée, une thématique précise\footnote{\RaggedOuter La notion de sphère Web est inspirée des travaux de K. Foot sur le volet numérique des campagnes électorales états-uniennes du début des années 2000 \citep{foot_web_2006}.}. Les acteurs Web regroupés au sein de ces sélections n'ont pas forcément conscience d'appartenir à un tel groupe. Par exemple, les réseaux de sites e-Diasporas (Section~\ref{sec:2_atlas}) peuvent être considérés comme des sphères Web. Sites et pages Web (Figure~\ref{fig:web_strata}, (3-4)) sont ensuite définis de manière identique à ce que nous proposons en Section~\ref{sec:2_web}. L'élément Web, quant à lui, est considéré comme l'élément textuel minimal d'une page Web (Figure~\ref{fig:web_strata}, (5)). La définition de Brügger reste néanmoins assez floue sur ce dernier point, la nature d'un élément Web n'étant pas énoncée de manière non ambiguë : ce peut être un ensemble de caractères écrits sur une page, des images fixes ou mobiles, ainsi que des sons. Mais nous pouvons aussi penser que l'élément Web minimal puisse être une balise HTML vide (Section \ref{sec:5_scraping}). Brügger en revanche écarte de cette liste les menus, barres d'informations et autres éléments de navigations. \\

\noindent De notre côté, nous voulons penser le futur fragment Web comme un \textbf{sous-ensemble cohérent et auto-suffisant} d'une page Web. Il s'inscrira dans la continuité des strates du Web, en se situant quelque part entre l'élément Web et la page Web. Un fragment pourra, en fonction des cas, être un élément Web seul, un groupe de plusieurs éléments, voire la page Web dans son entièreté\footnote{\RaggedOuter Nous reviendrons dans le détail sur la question de l'étendue du fragment Web dans la Section~\ref{sec:5_scraping}.}. 

Dès à présent, pour tout site Web composé de \textit{n} pages Web $\{p_1$,...,$p_n\}$, nous supposons que chacune de ses pages $p_j$ consiste en \textit{m} fragments Web numérotés $\{f_{j1},...,f_{jm}\}$ (Figure~\ref{fig:fragment}).

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/fragment}
  \caption{Une page $p_1$ et ses fragments Web $f_{11}, f_{12}, f_{13}$}
  \label{fig:fragment}
\end{figure}

\subsection{Dater une page archivée}

\noindent La datation des pages archivées peut être réévaluée à l'aune du fragment Web. Depuis la fin du précédent chapitre une question demeure~: Comment tendre vers une plus grande précision historique ? Comment s'affranchir des seules dates de téléchargement ? Comment \textit{bien} dater une page Web et son contenu ?

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/yabiladi-wayback}
  \caption{Répartition des archives de \textit{yabiladi.com} dans la WayBack Machine (\url{https://web.archive.org/web/*/www.yabiladi.com})}
  \label{fig:yabiladi-wayback}
\end{marginfigure}

Les archives Web sont les traces directes des crawlers (Section~\ref{sec:4_derrida}). En DAFF ou en WARC, une page archivée sera toujours adressée par sa seule et unique date de téléchargement. Dans la plupart des moteurs d'exploration (par exemple la WayBack Machine, Figure~\ref{fig:yabiladi-wayback}), cette date est l'unique dimension temporelle interrogeable. Il est néanmoins possible d'établir une échelle de datation plus complète en introduisant la notion de date de dernière modification (Section~\ref{sec:4_temporalite} et Table~\ref{tab:datation_1}). Échelle dont nous pensons maintenant pouvoir à nouveau améliorer la précision, en associant aux futurs fragments Web une \textbf{date d'édition}. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/yabi-date-com}
  \caption{Date d'édition (rouge) d'un post de forum sur \textit{yabiladi.com}}
  \label{fig:yabi-date-com}
\end{marginfigure}  

En effet, une page Web évolue (Section~\ref{sec:3_constituer}) dès que son contenu est édité par un tiers : humain ou robot. Par édition, nous entendons ici la création, la modification ou la suppression d'un élément d'une page. Comme les actes de modification et de suppression demandent, pour être datés (même approximativement), de comparer deux versions archivées d'une même page \citep{rocco_page_2003, nunes_using_2007}, leur détection semble de prime abord compliquée à intégrer à notre moteur d'exploration. 

La création d'un message ou d'un commentaire peut en revanche être plus facilement datée. Des indices sont souvent dispersés à même la page (Figure~\ref{fig:yabi-date-com}), reste alors à les interpréter et à les formater avant indexation \citep{de_jong_temporal_2005,kanhabua_using_2009}. Si l'en-tête HTTP d'une page Web a été archivé, celui-ci peut nous renseigner sur une date de dernière modification qui ne dépende pas directement du crawler  \citep{amitay_trend_2004}. 

À défaut, la création d'un contenu donné sera rapportée à sa première apparition sur l'ensemble des versions archivées d'une même page \citep{jatowt_detecting_2007}, cette comparaison peut être affinée si des URI ont été par ailleurs collectées\footnote{\RaggedOuter Le système Memento propose de voir une page archivée comme la concaténation de toutes les URI qu'elle agrège. Cette vue est appelée TimeMaps  \citep{van_de_sompel_http_2013} et peut être exploitée pour comparer les dates de certaines URI d'images par exemple.} \citep{aturban_difficulties_2017}. Notons enfin qu'il existe des stratégies de datation adaptées à la nature interdépendante de certains contenus archivés, comme un réseau de citation d'articles de blogs par exemple \citep{toyoda_whats_2006,spitz_predicting_2018}. Quoi qu'il en soit, l'identification et l'extraction d'une telle date d'édition reste possible et nous nous y emploierons en Section~\ref{sec:5_scraping}. \\

\noindent Mais, dès à présent, faisons par avance l'hypothèse d'être en capacité de doter chaque fragment Web d'une date d'édition. Ainsi, à tout fragment $\{f_{j1},...,f_{jm}\}$ d'une page $p_j$ nous associons maintenant une date d'édition $\phi(f_{j1}),...,\phi(f_{jm})$. De plus, nous nommons \textbf{date de création} de tout la page $p_j$ la plus ancienne date d'édition de l'ensemble de ses fragments soit $\min\limits_{k} \phi(f_{jk})$. La Figure~\ref{fig:edition_creation} décrit l'imbrication de ces nouvelles datations. 

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{graphics/edition_creation}
  \caption{Dates d'édition des fragments Web $\{f_{11}, f_{12}\}$ (rouges) et date de création de la page $p_1$ (noir)}
  \label{fig:edition_creation}
\end{figure*} 

\noindent Par ailleurs, nous faisons ici l'hypothèse implicite que toute datation extraite du contenu d'une page Web n'est ni erronée ni falsifiée. Dans le cas contraire, il existerait une possibilité non nulle d'avoir une date de création antérieure à la date de dernière modification. Ce faisant, nous pouvons maintenant mettre à jour notre échelle de datation en y ajoutant dates de création et d'édition, telles que :

\newpage

\begin{table}
\hspace{2em}%
  \label{tab:datation_2}
  \begin{tabular}{lll}
    \toprule
    Niveau & Nature de la date &\\
    \midrule
    page&lancement du crawl & \tikzmark{start}\\    
    page&téléchargement &\\
    page&dernière modification &\\
    page&création & \\
    fragment&édition & \tikzmark{end}\\     
  \bottomrule
\end{tabular}
  \bigskip
  \caption{Échelle (actualisée) de datation d'une page Web archivée}
\end{table} 

\begin{tikzpicture}[overlay,remember picture]
\draw[->] let \p1=(start), \p2=(end) in ($(\x1,\y1)+(0.8,0.2)$) -- node[label={[xshift=2.0cm, yshift=-0.3cm]précision historique}] {} ($(\x1,\y2)+(0.8,0)$);
\end{tikzpicture}

\noindent En pratique, tout fragment Web devra être associé à une date d'édition. Mais si cela est impossible, sa datation sera rapportée à la date de création de la page Web à laquelle il appartient. Et si bien dater une page archivée participe de son émancipation vis-à-vis du crawler, cela donne, par la même occasion, corps aux acteurs qui l'ont fait vivre. 

Un article de blog ne s'écrit pas de lui même, il est le fruit du geste d'un auteur (unique ou collectif, humain ou robot) qui l'a mis en ligne. Derrière les dates d'édition des fragments Web, peuvent transparaitre les gestes de divers auteurs : blogueurs, commentateurs ou contributeurs qui deviennent dès lors objets ou dimensions possibles d'une exploration d'archives Web\footnote{\RaggedOuter Pour le philosophe V. Flusser les gestes sont des séries de mouvements significatifs dont le but est déchiffrable, ils \og\textit{montrent la façon dont nous sommes au monde}\fg{}, \citep[p.319]{flusser_les_2014}.}. Serait-il alors possible, comme le suggère l'historien J. Morsel, d'écrire une histoire \textit{symptomale}\footnote{\RaggedOuter Alors que la trace, telle que nous la décrivions jusqu'ici (Section~\ref{sec:4_derrida}), suggère l'absence de l'agent qui l'a produite (elle s'en est détachée), le symptome, selon Morsel, suppose la présence latente de l'agent, coprésent à ce dont il est le signe \citep{morsel_traces?_2016}.} \citep{morsel_traces?_2016} à partir de nos corpus d'archives Web ? Cela reviendrait à considérer que certains fragments Web se trouvent chargés de la présence latente d'un auteur, dissimulée sous la surface des pages archivées et prête à être questionnée. 

Cette nouvelle perspective d'exploration nous mènera à considérer, depuis les archives Web, le devenir de communautés d'utilisateurs ou de collectifs d'auteurs tel que nous l'illustrerons dans le Chapitre~\ref{chap:6}. Avec le fragment Web, une nouvelle dimension d'analyse des archives s'offre donc à nous : l'exploration par acteur (auteur, contributeur, commentateur, etc.), plutôt que la simple exploration par page ou par site.

\subsection{Désagréger pour changer de temporalité}

\noindent Le Web est un flux grandissant d'information tout autant qu'un territoire en perpétuelle expansion. Par l'action des crawlers, les archives Web sont arrachées à la temporalité continue du Web vivant pour rejoindre celle figée et discrétisée des corpus collectés (Section~\ref{sec:4_derrida}). Les archives, malheureusement, ne peuvent revenir au temps du Web vivant, mais, grâce au fragment Web, nous pouvons les faire basculer dans la temporalité du Web tel qu'il a été. Temporalité que nous allons essayer de caractériser ci-dessous.  

\noindent Commençons par une expérience. Au cours de la Section~\ref{sec:4_legacy}, nous avions visualisé, dans le temps, la répartition des pages archivées de la section forum du site \textit{yabiladi.com}, et ce, par rapport à leurs seules dates de téléchargement (Figure \ref{fig:yabiladi-download}). Maintenant, essayons plutôt de nous focaliser sur les dates d'édition des fragments Web de chacune de ces pages et tentons une comparaison. 

Faute de ne pas avoir encore définit clairement la nature d'un fragment Web, nous nous contenterons ici de l'approximation suivante : chaque \textit{post} (un message individuel) publié sur le forum de \textit{yabiladi.com} sera considéré comme fragment de la page dont il dépend. Un post est écrit par un unique auteur (identifié comme tel) et associé à une date d'édition (Figure~\ref{fig:yabi-date-com}). \\

\noindent D'un point de vue pratique, nous procédons à une extraction focalisée\footnote{\RaggedOuter Cette extraction de données n'est donc pas générique, voir la Section~\ref{sec:5_scraping} pour une approche plus générale.} dans nos archives, afin de ne conserver que les dates d'édition des posts collectés. Ces dernières peuvent être facilement identifiées dans le code des pages Web par un nœud HTML unique, par exemple :
\[
\small
\texttt{<div class="com-date">17 Novembre 2009</div>}
\]
\noindent Aussi, nous modifions notre moteur d'exploration au niveau de la jointure entre données et méta-données DAFF (Figure \ref{fig:spark}) et ajoutons un traitement permettant d'extraire les dates d'édition.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/fragment-date}
  \caption{Distribution, pour \textit{yabiladi.com}, du nombre de pages et de fragments archivés par jours et suivant leurs dates de téléchargement (bleu) et d'édition (rouge) respectives}
  \label{fig:edition_vs_download}
\end{figure*}

\noindent Nous construisons ensuite un index dédié dans Solr. Ne reste plus alors qu'à visualiser les deux distributions côte à côte : d'une part la répartition des pages par date de téléchargement (Figure~\ref{fig:edition_vs_download}, bleu) et d'autre part la répartition des fragments correspondants par date d'édition (Figure~\ref{fig:edition_vs_download}, rouge). Cette dernière (rouge) semble \textit{gommer} l'artéfact de crawl précédemment observé sur l'année 2013 (bleu). La distribution des fragments est homogène et ne souffre d'aucune cécité remarquable. Détachée de l'influence du crawler, elle n'en subit plus les effets. 

Par ailleurs, nos archives Web semblent chargées d'une mémoire plus étendue que celle initialement prévue. Ainsi, partant d'une collecte débutée en Mars 2010, nous voilà maintenant capable de considérer et d'analyser des fragments Web édités 7 années plus tôt, jusqu'en 2003 pour les plus anciens. Les pages archivées contiennent, en elles-mêmes, les traces sédimentaires de publications antérieures.\\

\noindent Par l'extraction et l'étude des fragments Web, nous nous donnons les moyens d'un saut dans le passé considérable. Ces fragments sont potentiellement porteurs d'une mémoire préexistante à chaque collecte et dont nous pouvons dater avec précision l'apparition. En désagrégeant les archives Web, en les fragmentant, nous changeons une nouvelle fois de temporalité pour entrer dans \textbf{le temps du Web tel qu'il a été}. Là ou le temps des archives était figé et fait de séries de captures discrètes d'une même page, le temps du Web tel qu'il a été est un temps fragmenté, c'est-à-dire un temps éclaté, où chaque fragment se voit définit relativement par rapport à lui même.

Nos expérimentations pratiques ne portent que sur les seules dates d'édition. Mais, dans le temps du Web tel qu'il a été, chaque fragment Web suit sa propre temporalité, détachée de celle des autres. Une ligne allant de son apparition sur le Web (date d'édition) jusqu'à sa possible disparition de la toile. Isolées les unes des autres, c'est à l'explorateur d'archives que revient le rôle de naviguer entre ces lignes de temps éclatées. L'explorateur sélectionne, découpe et assemble des fragments pour construire ce que l'anthropologue T. Ingold nomme un \textbf{trajet}, support de nos explorations à venir : \\ 

\begin{fullwidth}
\og\textit{Dans le cas du trajet, en revanche, on s'engage dans une voie qu'on a déjà explorée avec d’autres, ou qui a été explorée par d'autres, en reconstruisant l'itinéraire au fur et à mesure de sa progression.}\fg{} --- \citep[p.26]{ingold_breve_2013}\\
\end{fullwidth} 

\noindent Un trajet est fait de détours, de contours et de bifurcations. À mesure qu'il se conçoit, le trajet se développe et s'inscrit dans le temps. Suivant le cours de son analyse, c'est par le montage que le chercheur chemine d'un fragment Web à l'autre, dans le sens et l'ordre qu'il juge pertinent. En conjuguant les multiples lignes de temps il s'affranchit ainsi des formes classiques et linéaires d'accès aux archives Web. Ouvrant la voie à de nouveaux degrés de liberté, les fragments pourront être associés sur la base d'un lien hypertexte partagé, d'une présence sur la même page à un instant donné, d'une filiation commune, etc. Ces trajets entre fragments deviennent sous la plume de J. Bashet des \textbf{lignes processuelles} \citep[p.227]{baschet_defaire_2018}. L'historien cherche, ce faisant, à rompre avec une vision linéaire de l'histoire dont il faudrait faire éclater la continuité : \\

\begin{fullwidth}
\og\textit{En effet, il ne s'agit en aucun cas de penser l'Histoire tout entière comme un seul processus unifié, mais de saisir, dans l'histoire, un entrelacement complexe de multiples processus.}\fg{} --- \citep[p.227]{baschet_defaire_2018}\\
\end{fullwidth} 

\noindent En suivant le devenir historique de multiples lignes processuelles, l'écri\-ture de l'histoire revient à raisonner autour de \textbf{moments} singuliers où convergent et se croisent temporalités et processus hétérogènes :\\

\begin{fullwidth}
\og\textit{Et on proposera plutôt d'explorer diverses manière de penser l'événement - le surgissement, le nouveau, la rupture mais aussi l'imprévu, l'imprévisible, l'improbable - à partir d'une pensée des processus. Ainsi, outre qu'elle peut naître ou disparaître, une ligne processuelle connaît par elle-même  des variations de rythme et des moments singuliers de concentration ou d'expansion des forces à l'œuvre : l'événement tient alors à une étape particulière de maturation ou correspond, peut-être à un seuil d'ébullition ou de cristallisation.}\fg{} --- \citep[p.227-228]{baschet_defaire_2018}\\
\end{fullwidth} 

\noindent Avec le passage de la page au fragment, nous basculons d'une unité d'exploration à l'autre. Le fragment Web nous invite à un changement d'échelle temporelle et spatiale dans le rapport que nous entretenons aux archives Web. Situé entre la page et l'élément Web, le fragment peut contenir en lui la trace du Web tel qu'il a été : une mémoire jusqu'ici retenue dans les fichiers archivés. Le chercheur associe alors un à un les fragments qu'il juge pertinents et conduit, chemin faisant, son exploration pour saisir l'histoire du Web et ses cristallisations autour de moments singuliers. 

Dans notre méthodologie, la place du chercheur est donc centrale. C'est lui qui, par ses choix de montage (basés sur sa propre expertise ou sur des indices qu'il aura recueilli en amont) définit les fragments Web à explorer et la manière de les parcourir. Il peut, dans cette tâche, se faire aider de scripts informatiques pour automatiser certains traitements. Le fragment Web doit ainsi être interprétable par une machine : un programme pourra l'analyser, le manipuler, le stocker, etc. Mais le fragment doit aussi rester compréhensible, en lui même, afin d'être étudié par un chercheur (sociologue, historien\ldots{}). Nous discuterons, en Section~\ref{sec:5_scraping}, de l'implication ou non du chercheur dans le choix même de la forme des fragments Web. Nous donnerons, enfin, dans le Chapitre~\ref{chap:6}, deux exemples d'explorations désagrégées de nos corpus et basées sur le fragment Web.

\section{Le fragment Web : définition}
\label{sec:5_fragment}

\noindent La définition suivante est intentionnellement générique. Nous souhai\-tons par là que d'autres chercheurs puissent se saisir après nous du fragment Web\footnote{\RaggedOuter Notons que le fragment Web ne doit pas être confondu avec la notion de fragments d'URL (\url{https://en.wikipedia.org/wiki/Fragment_identifier}).}. Par ailleurs, la nature des fragments dépendant beaucoup du contexte de l'analyse et de la sensibilité propre à chaque chercheur, soit qu'il voudra une fragmentation plus ou moins englobante, soit qu'il se satisfera d'éléments abstrait, nous ne donnerons pas ici de définition technique précise du fragment. Nous proposerons, dans la Section~\ref{sec:5_scraping}, notre propre système d'extraction des fragments Web depuis une page archivée, d'autres approches et stratégies peuvent naturellement exister.\\

\begin{itshape}
\noindent Considérant la page web comme unité de consultation de base du World Wide Web, bâtie sur des modalités d'écriture propre au support numérique et constatant que du point de vue de la perception humaine \citep{bernard_criteria_2003, michailidou_visual_2008} une page web est le résultat de l'agencement logique d'éléments sémantiques distincts, nous nommons \textbf{fragment Web} un sous-ensemble sémantique et syntaxique d'une page Web donnée et vérifiant les propriétés suivantes :

\begin{enumerate}[leftmargin=*]  
\item Il y a une relation d'échelle entre une page Web et ses fragments Web. Ceux-ci peuvent couvrir l'entièreté de la page ou n'être qu'un élément unitaire de cette dernière.
\item Un fragment Web est un assemblage cohérent d'éléments textuels, visuels, sonores ou logiciels extraits d'une page Web. Le fragment Web doit ainsi être compréhensible par lui même.
\item Au sein d'une même page Web, deux fragments Web ne peuvent pas se superposer, même partiellement.
\item Certains éléments d'un fragment Web peuvent faire l'objet d'une catégorisation lors de l'extraction. Un fragment Web peut ainsi être associé à un titre, à un auteur, à une date d'édition, etc.
\item Le fragment Web capture l'ensemble des dispositifs d'écriture (nœuds HTML, widgets de CMS, éditeurs de texte\ldots{}) et de partage (liens hypertextes, liens de syndication, liens de publications\ldots{}) utilisés pour publier son contenu sur le Web.
\end{enumerate}
\end{itshape}

\section{Scraping et méthodologie d'extraction}
\label{sec:5_scraping}

\subsection{Extraire de l'information issue d'une page Web}

\noindent On appelle \textbf{scraping} l'ensemble des techniques et méthodes employées pour extraire de l'information depuis une page Web. Un \textbf{scraper} est, de fait, un robot chargé de faire du scraping\footnote{\RaggedOuter Par abus de langage et faute d'une meilleure traduction, on dira d'un scraper qu'il \textbf{scrape} une page Web.}. En pratique, un scraper ne travaille jamais au hasard, il est focalisé, c'est-à-dire qu'il est paramétré pour ne conserver que certaines parties ou éléments distincts d'une page : des noms, des adresses, des images, des mots clés, etc. La recherche de nos fragments Web passera obligatoirement par une étape d'extraction, il faudra alors scraper l'ensemble des pages archivées.

De prime abord, les scrapers ne considèrent pas les pages Web telles que nous les voyons depuis nos écrans, interprétées par les navigateurs Web. Lors d'une extraction, les scrapers parcourent, d'abord et avant tout, des portions de code issues des fichiers HTML et CSS qui forment l'ossature de ces pages. 

Le \textbf{HTML}\footnote{\RaggedOuter \textit{HyperText Markup Language}} est un langage de programmation décrivant, à la fois, la structure et le contenu d'une page Web. Le HTML est la grammaire de l'hypertexte. Écrites en HTML, les pages sont alors \textit{rendues} par le navigateur Web qui transcrit visuellement les instructions codées.  

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/html}
  \caption{Ajout successif d'éléments HTML, CSS et JavaScript à une page Web et transcription sur l'écran d'un internaute}
  \label{fig:html}
\end{figure}

\noindent Le HTML est un langage à \textbf{balise}, c'est-à-dire que chaque élément d'une page Web est délimité par une balise ouvrante à une extrémité (ex: \texttt{<p>}) et fermante à l'autre bout (ex: \texttt{</p>}). La nature de ces balises, leur syntaxe et leur agencement permettent d'enrichir le contenu textuel de l'élément qu'elles définissent (Figure~\ref{fig:html}, (a)). Une balise HTML est identifiée par un nom (\textit{tag}) qui donne une indication sur le type de l'élément caractérisé (du texte \texttt{<p>}, un lien \texttt{<link>}\ldots{}). Elle peut être complétée (entre autres) par un \textit{id} (un identifiant unique) et une ou plusieurs \textit{class} (attribut qualifiant un ou plusieurs éléments). Classes et identifiants peuvent servir à associer un comportement spécifique à un ou plusieurs éléments cibles.

Une page Web est un document structuré (Figure~\ref{fig:html}, (b)). Les éléments HTML s'agencent entre eux suivant la forme particulière d'un arbre : l'\textbf{arbre DOM}\footnote{\RaggedOuter \textit{Document Object Model tree}, en anglais. En informatique un arbre est une structure de données où chaque élément (nœud) est codé hiérarchiquement par rapport aux autres (\url{https://fr.wikipedia.org/wiki/Arbre_binaire})}. Par convention, on appelle \textbf{nœud} HTML tout élément d'un arbre DOM. Il existe ainsi un seul et unique nœud racine, plusieurs nœuds parents, enfants, etc. Un scraper peut accéder à un nœud HTML donné soit en l'adressant directement via son id ou sa classe, soit en parcourant l'arbre DOM.  

Le \textbf{CSS}\footnote{\RaggedOuter \textit{Cascading Style Sheets}, en anglais} est un langage pensé pour décrire l'aspect visuel (rendu et animation) d'un nœud HTML à l'écran. Le CSS transcrit ainsi des règles de style directement depuis le HTML de la page Web ou dans un fichier dédié. Une correspondance est alors faite entre l'identifiant (et/ou la classe) d'un nœud et la règle à lui appliquer (Figure~\ref{fig:html}, (c)). On jouera ainsi sur la couleur, la police d'écriture, la marge, les bordures, etc. de chaque élément.  

Les éléments dynamiques d'une page Web sont générés, majoritairement, par du code \textbf{JavaScript} (Figure~\ref{fig:html}, (d)). Le JavaScript peut s'écrire dans un ou plusieurs fichiers séparés ou être directement ajouté au HTML, au sein de balises dédiées. Il est alors possible de manipuler des nœuds HTML et de leur attribuer à chacun comportement. En réaction au geste d'un internaute, par exemple : un clic, un défilement, etc. D'autres technologies comme Adobe Flash\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Adobe_Flash}} ont, par le passé, également su gérer ces aspects dynamiques. Au final, HTML, CSS et JavaScript forment le triptyque le plus courant face auquel doivent se débattre les scrapers.\\

\noindent En effet, un scraper doit savoir s'adapter à la complexité des pages qu'il parcourt. Par exemple, une page contenant du JavaScript devra parfois être préalablement interprétée par le scraper (et non juste parcourue), afin de prendre en compte les éléments dynamiques qui ne se chargeraient qu'à l'affichage écran\footnote{\RaggedOuter Voir les bibliothèques Phantomjs (\url{http://phantomjs.org/}) et After-load (\url{https://www.npmjs.com/package/after-load}).}. Une campagne de scraping se prépare donc en amont, il s'agira alors de définir une stratégie adaptée au contexte de notre extraction. Le scraper peut, ainsi, s'attarder sur les éléments visuels d'une page Web \citep{cai_vips:_2003}, ou se contenter de la seule information sémantique présente dans le HTML \citep{jatowt_detecting_2007}. Là où la première solution sera en quête d'une vision humaine des pages Web, la seconde privilégiera la recherche d'un temps de réponse réponse acceptable. 

La vitesse des traitements est, de fait, une composante essentielle de tout scraping, notamment dans ses applications industrielles. Peut-on se permettre d'utiliser des méthodes coûteuses pour rendre certaines images ou interpréter du code ? Ce faisant, les travaux portants sur l'extraction d'information depuis une page Web sont souvent pensés pour s'intégrer, d'abord et avant tout, à de vastes campagnes d'a\-nalyses \citep{weninger_text_2008, adar_web_2009, oita_forest:_2015}. La validation humaine n'est pas la finalité de ces recherches. De notre côté, nous préférons nous rapprocher de méthodes plus qualitatives, conçues sciemment pour être utilisées, en premier lieu, par des êtres humains. 

L'extension Readability\footnote{\RaggedOuter Voir \url{https://github.com/mozilla/readability}, Mercury Reader pour Chrome ou encore l'application Pocket.} du navigateur Web Firefox propose, par exemple, aux internautes d'expérimenter une forme de lecture \textit{zen} sur la toile. Le système cherche ainsi à identifier le contenu principal de chaque page (le corps d'un article), à l'extraire et à le présenter dépouillé des publicités, menus et autres suggestions qui pourraient nuire à la lecture. Bien que Readability se limite seulement à certains types de sites  (les sites de news notamment), une partie de son fonctionnement pourra être adaptée à notre propre moteur. 

\subsection{Des pages bruitées à nettoyer}

\noindent Notre tâche consiste ici à fragmenter une page Web donnée, c'est-à-dire (suivant les termes nouvellement introduits), à extraire de nos fichiers archivé, des sous-ensembles cohérents de nœuds HTML. Pour ce faire nous prendrons chaque page une par une, nous la nettoierons, puis nous définirons une mesure censée traduire la cohérence entre des nœuds HTML deux à deux, avant de les grouper en un ensemble de fragments Web distincts. Soit une page Web $p$ composée de $m$ nœuds HTML $\{n_1,...,n_m\}$, organisés en un arbre DOM $t$ et associés à des règles CSS.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/bruit}
  \caption{Processus de nettoyage, nœud par nœud, d'une page Web}
  \label{fig:bruit}
\end{figure*}

\noindent Nous commençons par \textit{nettoyer}\footnote{\RaggedOuter Voir la section suivante pour une discussion sur le nettoyage des pages} $p$ de tous les nœuds qui ne nous semblent pas pertinents : publicités, menus de navigation, scripts\ldots{} D'expérience, nous faisons l'hypothèse que le Web est une source de données très bruitée, tout l'enjeu est ici de trouver un juste milieu entre nettoyage et conservation des données pertinentes. Des méthodes très efficace, par apprentissage supervisé, existent \citep{kohlschutter_boilerplate_2010}, cherchant à définir des masques de nettoyage pour chaque site.  Or, ce genre de technique demande la création en amont d'un ensemble d'apprentissage annoté. Opération qui pourrait s'avérer rapidement fastidieuse si nous l'appliquions aux différentes versions de pages collectées par nos archives.


comme nous ne connaissons pas, à priori, les évolutions structurelles et stylistiques subies par un site Web au cours de son histoire, la définition d'un ensemble d'apprentissage nous semble ici compromise. 

De notre côté, nous préférons favoriser une approche par heuristiques \citep{jatowt_detecting_2007}. Ainsi, nous définissons pour chaque nœud de $p$ un label, résultat de la concaténation de son tag, de son id et de sa classe : 
\[
label = tag + id + classe
\]
\noindent L'idée est ici de vérifier la valeur informative d'un nœud via un ensemble d'expressions régulières appliquées à son label (Figure \ref{fig:bruit}). Pour ce faire, nous parcourons l'arbre DOM $t$ et si l'un des labels contient les termes \textit{menu} ou \textit{navbar}, par exemple\footnote{\RaggedOuter Voir la liste complète dans le code source (\url{https://github.com/lobbeque/rivelaine/blob/master/scala/src/main/scala/qlobbe/Rivelaine.scala}, l.~72-73).}, alors celui-ci ne sera pas conservé dans la suite du processus d'extraction. À la fin de cette étape nous ne retenons, à titre illustratif, que 30\% des nœuds des pages forums de \textit{yabiladi.com}, ce taux descend autour de 15\% pour les pages \textit{actualités}, plus bruitée donc. 

\subsection{Classification de nœuds HTML}

\noindent Transposé au champ d'action de la recherche d'information, un fragment Web peut être vu comme un groupe cohérent de nœuds HTML. Toute la difficulté revient à traduire informatique cette notion de cohérence entre nœuds. Sur ce point, la librairie open-source Fathom\footnote{\RaggedOuter \url{https://github.com/mozilla/fathom}} a été conçue pour identifier des \textit{clusters} (groupes) de nœuds HTML au sein d'une page Web donnée. L'idée de Fathom est simple : deux nœuds proches l'un de l'autre sont placés dans un même groupe, un nœud proche d'un groupe déjà formé le rejoindra alors, et ainsi de suite. L'algorithme réalise un clustering par agglomérations successives de l'ensemble des nœuds de l'arbre DOM~$t$. 

Dans la Figure~\ref{fig:fathom}, la page $p$ contient cinq nœuds HTML identifiés par les tags de leurs balises : $A, B, C, D, E$. Deux nœuds $n_1, n_2$ sont considérés proches l'un de l'autre si la distance $d(n_1,n_2)$ les séparant est inférieure strictement à une variable $minDist$ : la distance minimale autorisant le rapprochement de deux nœuds (ici valant arbitrairement~4). 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/fathom}
  \caption{Processus de classification des nœuds d'une page Web}
  \label{fig:fathom}
\end{figure*}

\noindent Dans cet exemple\footnote{\RaggedOuter Les distances sont ici données à titre illustratif, voir la section suivante pour une discussion sur les fonctions de distance}, la distance $d(A,D)$ vaut $4$, $A$ et $D$ ne sont donc pas considérés comme proches. L'ensemble des $m$ nœuds de $p_1$ sont codés, dans Fathom, sous la forme d'une matrice d'adjacence $m \times m$ nommée $M$ (ici de taille 5). À chaque ligne (\textit{row}) de $M$ correspond un nœud et sa distance respective vis-à-vis des autres nœuds de $p$. À chaque itération de Fathom, une fonction \textit{closestRows} détermine les deux nœuds ou groupes de nœuds les plus proches. Dans notre exemple, au premier passage ce sont $A$ et $B$ qui sont considérés les plus proches avec $d(A,B)=1$, puis vient le tour de $C$ et $E$ situés à une distance $2$ l'un de l'autre. À la troisième itération plus aucun groupe ne peut être aggloméré, Fathom a donc identifié trois clusters distincts de nœuds. Le pseudo-code, ci dessous, décrit avec plus de détail le fonctionnement de Fathom\footnote{\RaggedOuter Implémentation originale disponible ici : \url{https://github.com/mozilla/fathom/blob/master/clusters.mjs\#L161}} :  

\begin{algorithm}
 \While{rows(M) > 1 and dist(closestRows(M)) < minDist }{
  $\{r_i,r_j\} = closestRows(M)$\\  
  $newRow = \{ \}$\\
  \For{$r\in rows(M)$}{
   \If{$r \neq r_i \textrm{ and } r \neq r_j$}{
	$newRow[r] = \min(d(r_i,r),d(r_j,r))$   
   }
  }
  remove($M[r_i]$)\\ 
  remove($M[r_j]$)\\
  remove($M[*][r_i]$)\\
  remove($M[*][r_j]$)\\
  append($M,newRow$)
 }
\end{algorithm}

\noindent Fathom a besoin d'être paramétré pour fonctionner correctement. Il faut ainsi établir en amont la valeur de $minDist$ et définir une fonction de distance qui fasse sens. Dans notre cas nous voulons que cette dernière traduise la cohérence sémantique, syntaxique et visuelle d'un fragment Web. 

\subsection{Définir une fonction de distance}

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/depth}
  \vspace*{0.2cm}  
  \caption{Différence de profondeur entre deux nœuds HTML au sein d'un même arbre DOM. $d(n_1,n_2)=0$ s'ils sont frères. $d(n_1,n_2)=1$ si l'un est le parent de l'autre}
  \label{fig:depth}
\end{marginfigure}

\noindent Une \textbf{fonction de distance} est un objet mathématique qui traduit et calcule l'éloignement entre deux entités, données en variable. Dans notre cas, deux nœuds HTML $n_1,n_2$ seront considérés comme \textit{proches} si le résultat de la fonction de distance $d(n_1,n_2)$ est strictement inférieure à la valeur de $minDist$. Ces nœuds pourront alors être groupés par Fathom et formeront un seul et même fragment Web. 

Par défaut, Fathom réutilise la fonction de distance implémentée dans Readability et designée pour grouper ensemble les nœuds appartenant au contenu principale d'une page Web. Cette fonction s'appuie, d'une part, sur la différence de profondeur entre deux nœuds de l'arbre~$t$ (Figure~\ref{fig:depth}, $depth(n_i,n_j)$) et, d'autre part, sur le nombre d'éléments les séparant une fois l'arbre $t$ mis à plat ($length(n_i,n_j)$). Un malus est ensuite ajouté si les nœuds ne possèdent pas les mêmes balises HTML ($tag(n_i) \neq tag(n_j)$). Le pseudo code suivant décrit l'intégration de cette fonction de distance\footnote{\RaggedOuter Voir l'implémentation originale : \url{https://github.com/mozilla/readability/blob/master/Readability.js\#L760}} à Fathom, lors de la création de la matrice d'adjacence $M$ :  

\begin{algorithm} 
 \For{$n_i \in nodes$}{
  \For{$n_j \in nodes$}{
    $d(n_i,n_j) = 0$\\
    $d(n_i,n_j) = d(n_i,n_j) + depth(n_i,n_j)$\\
	$d(n_i,n_j) = d(n_i,n_j) + length(n_i,n_j)$\\    
    \If{$tag(n_i) \neq tag(n_j)$}{
		$d(n_i,n_j) = d(n_i,n_j) + malus$    
    }
    return $d(n_i,n_j)$      
  } 
 }
\end{algorithm}

\noindent En l'état, cette fonction ne traduit qu'une forme de cohérence structurelle (\textit{depth}, \textit{length}), voire sémantique si l'on considère la différence de balises telle quelle. Notre définition du fragment Web se veut plus complète. Nous allons donc enrichir cette fonction de distance en partant d'un principe simple : par défaut deux nœuds sont considérés comme proche, tout motif d'éloignement sera sanctionné d'un malus.

Tout d'abord, la cohérence visuelle jouant un rôle important dans la segmentation d'une page Web donnée\footnote{\RaggedOuter \og\textit{[\ldots{}] constatant que du point de vue de la perception humaine \citep{bernard_criteria_2003, michailidou_visual_2008} une page web est le résultat de l'agencement logique d'éléments sémantiques distincts}\fg{},  Section~\ref{sec:5_fragment}}, nous éloignerons les nœuds dont la couleur d'arrière plan ($color(n_i) \neq color(n_j)$, issue du CSS) n'est pas la même.

Puis, nous ajouterons un malus aux éléments séparés par des \textit{breaking lines} ($vips(n_i,n_j)$). Dans l'algorithme de segmentation Vips \citep{cai_vips:_2003}, les breaking lines sont des nœuds HTML identifiés comme potentiels séparateurs de contenu sur le Web. Ce sont des sauts visuels entre deux portions de texte d'une même page. Les balises \textit{<hr>}, \textit{<br>}, etc. sont des breaking lines.   

Enfin, nous savons grâce aux travaux de J. Goody \citep{goody_raison_1979}, que la liste, comme forme d'organisation graphique de l'écriture, est fortement utilisée par l'Homme depuis qu'il a ressenti le besoin de stocker et d'organiser ses données\footnote{\RaggedOuter Des listes de comptes des tablettes sumériennes aux listes de résultats de Google.}. La liste abstrait par un jeu de discontinuités (retour à la ligne) et de continuités (récurrences) les données ainsi présentées, permettant un classement de ces dernière suivant de multiples critères. 

Les pages Web, dans leur organisation à l'écran, n'échappent pas à cette règle : listes d'articles, de commentaires, de suggestions, de liens\ldots{} Une manière de traduire la cohérence d'un fragment Web serait d'identifier chaque fragment à un élément d'une de ces listes, quelque soit sa taille. Pour ce faire, nous définissons, par l'observation, des \textbf{masques de continuité} entre nœuds HTML. La Figure~\ref{fig:masques} illustre cette intuition. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/masques}
  \caption{Ségmentation d'une page Web suivant des masques de continuité}
  \label{fig:masques}
\end{figure*}

\noindent La page $p$ peut se voir comme une liste de nouvelles écrites par Borges, chacune présentée par un titre et un phrase faisant office de texte. Nos masques de continuité prennent en compte, d'une part, la nature des nœuds HTML (par une catégorisation de ces derniers\footnote{\RaggedOuter Voir la section suivante pour une discussion sur la catégorisation des nœuds HTML}) et, d'autre part, une relation de hiérarchie entre ces mêmes nœuds~: Le second est il plus profond que le premier ? Sont-ils au même niveau~? Nous faisons l'hypothèse, que dans l'arbre DOM $t$ un nœud de profondeur moindre (le titre) subordonnera la réception d'un nœud plus éloigné de la racine (le texte). Ainsi, dans cette exemple nous définissons comme masque l'énoncé suivant~: un nœud titre suivi d'un nœud texte plus profond. Si deux nœuds ne valident pas ce masque (ici un texte suivi d'un titre moins profond), un malus leur sera attribué dans la fonction de distance. Cela nous permet, au final, de fragmenter la page $p$ comme une liste de deux nouvelles, de deux fragments Web. 

Nous définissons ainsi plusieurs masques (Figure~\ref{fig:coherente-nodes}), supposés englober la majorité des cas de figure rencontrés sur le Web. Une condition ($incoherent(n_i,n_j)$) est ajoutée à notre fonction de distance, qui traduit maintenant une forme de cohérence structurelle, visuelle et syntactique entre deux nœuds HTML. Fathom est maintenant capable de fragmenter les pages Web archivées. Le pseudo-code\footnote{\RaggedOuter Voir l'implémentation détaillée : \url{https://github.com/lobbeque/rivelaine/blob/master/nodejs/cluster.js\#L41}} suivant présente l'agencement de l'ensemble de nos malus au sein de la fonction~$d$~:

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/coherente-nodes}
  \vspace*{0.2cm}  
  \caption{Masques de continuité entre deux types de nœuds HTML de profondeur variable}
  \label{fig:coherente-nodes}
\end{marginfigure}

\begin{algorithm} 
 \For{$n_i \in nodes$}{
  \For{$n_j \in nodes$}{
    $d(n_i,n_j) = 0$\\
    $d(n_i,n_j) = d(n_i,n_j) + depth(n_i,n_j)$\\
	$d(n_i,n_j) = d(n_i,n_j) + length(n_i,n_j)$\\      
    \If{$tag(n_i) \neq tag(n_j)$}{
		$d(n_i,n_j) = d(n_i,n_j) + malus$    
    }
    \If{$color(n_i) \neq color(n_j)$}{
		$d(n_i,n_j) = d(n_i,n_j) + malus$    
    } 
    \If{$vips(n_i,n_j)$}{
		$d(n_i,n_j) = d(n_i,n_j) + malus$    
    }
    \If{$incoherent(n_i,n_j)$}{
		$d(n_i,n_j) = d(n_i,n_j) + malus$    
    }
    return $d(n_i,n_j)$                        
  } 
 }
\end{algorithm}

\subsection{Catégorisation}

\noindent Pour définir nos masques de cohérence, il nous catégoriser certains nœuds HTML par rapport à la nature de leur contenu. La catégorisation se fait ici au niveau des nœuds et non à l'intérieur du texte de l'élément HTML observé. Ces catégories interviennent, donc, au moment de la segmentation d'une page Web en fragments, mais elles deviendront aussi, à terme, dimension d'interrogation à part entière des archives Web. Pour trouver l'ensemble des fragments Web écrits par un seul et même auteur, il faut, en amont, avoir déterminé les nœuds HTML susceptibles de nous renseigner sur l'identité de cette personne. Nous définissons ainsi six catégories de nœuds :

\begin{enumerate}[leftmargin=*]  
\item Les nœuds titres : titre d'une page, d'un article\ldots{}
\item Les nœuds auteurs : auteur d'un post de blog, de forum\ldots{}
\item Les nœuds dates : toute information temporelle 
\item Les nœuds textes : tout élément textuel qui ne soit ni un auteur, ni une date, ni un titre
\item Les nœuds d'expression : nœuds permettant de partager, promouvoir, éditer du contenu en ligne (liens hypertextes, éditeur intégrés, bouton partager\ldots{})
\item Les nœuds autres : ceux qui n'ont pas pu être catégorisés 
\end{enumerate}

\noindent La catégorisation en elle même se fait sur la base d'expressions régulières et d'heuristiques ad hoc. Nous cherchons, ainsi, à faire correspondre le label de chaque nœud à un ensemble de termes (balises, classe, etc.) caractéristiques d'une catégorie donnée. Par exemple, trouver le terme \textit{title} associé à une balise \texttt{<h1>}\footnote{\RaggedOuter Balise HTML définissant un titre} dans le label d'un nœud, nous permettra de le placer dans la famille des titres. Chaque label passe alors au crible de nos expressions régulières\footnote{\RaggedOuter Voir le détail des patterns recherchés \url{https://github.com/lobbeque/rivelaine/blob/master/nodejs/utils.js}}, allant de la plus discriminante à la plus englobante, comme l'illustre la Figure~\ref{fig:categorie-nodes} : 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/categorie-nodes}
  \caption{Chaine d'expressions régulières permettant la catégorisation d'un nœud HTML sur la base de son label}
  \label{fig:categorie-nodes}
\end{figure*}

\noindent Au sortir de cette étape, nous souhaitons normaliser les nœuds dates. En effet, ces nœuds renferment les dates d'édition que nous cherchons à extraire depuis le début de ce manuscrit. Mais il y a ici une différence importante à faire entre une date encapsulée dans un nœud date et une date trouvée dans le corps d'un nœud texte ou titre. 

La première peut être vue comme une information directement relative à la page et à son contenu. Elle caractérise par exemple une date de publication, d'écriture d'un commentaire ou de réponse à un article\footnote{\RaggedOuter Ces nœuds dates sont souvent crées automatiquement par les CMS et autres éditeurs de sites}. La seconde, en revanche, peut faire référence à n'importe quel aspect du contenu textuel des pages analysées : la date d'un événement narré dans un article, la date d'une référence bibliographique, etc. La structure même du HTML ne nous renseigne pas sur le contexte de ces dates. Pour nous, elles ne sont pas directement liées à un geste d'édition en ligne. Ces dates pourront, par contre, faire l'objet d'une analyse ultérieure.

Ainsi, nos nœuds dates passent finalement au travers d'une fonction de normalisation, qui, sur la base d'un dernier jeu d'expressions régulières\footnote{\RaggedOuter Voir le détail des patterns : \url{https://github.com/lobbeque/rivelaine/blob/master/scala/src/main/scala/qlobbe/Patterns.scala}}, transforme une date écrite en langage naturel en une date formatée\footnote{\RaggedOuter Suivant le standard ISO 8601} et compréhensible par notre moteur de recherche Solr. Les dates générées sans horaires sont, par défaut, remmenées à minuit du jour indiqué. Les dates peut précises du type \textit{hier, 08:30} ou \textit{il y a 15 minutes}, ne sont pas prises en compte\footnote{\RaggedOuter Une amélioration serait ici de se référer à la date de création ou à la date de téléchargement de la page.}.

\subsection{Discussions}

\noindent Depuis le début de cette section, nous suivons le parcours d'une page Web $p$ d'une étape à l'autre de son processus de segmentation. La page est d'abord nettoyée, pour ne conserver que les nœuds à haute valeur informative. Les éléments HTML restants sont ensuite catégorisés suivant leur nature propre. Grâce à l'algorithme de classification Fathom, associé à une fonction de distance enrichie, nous groupons les nœuds entre eux et segmentons alors $p$ en une suite de fragments Web distincts. 

Nous appelons \textbf{Rivelaine}\footnote{\RaggedOuter Open-source et téléchargeable ici-même : \url{https://github.com/lobbeque/rivelaine}} notre librairie d'extraction des fragments Web. Une première implémentation est développée en Scala et retourne les fragments suivant le format\footnote{\RaggedOuter \textit{JavaScript Object Notation}, format de données textuelles permettant de représenter des informations structurées (\url{https://fr.wikipedia.org/wiki/JavaScript\_Object\_Notation})} JSON. À titre d'exemple, nous demandons à rivelaine de fragmenter une page issue du forum de \textit{yabidali.com}. Parmi l'ensemble des fragments identifiés, nous nous attardons sur ceux semblant se rapprocher de messages postés par des membres du site, tels que :

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/semoule}
  \vspace*{0.2cm}  
  \caption{Exemple de message posté sur \url{https://www.yabiladi.com/forum/semoule-fine-pour-couscous-54-9290786.html}}
  \label{fig:semoule}
\end{figure}

\newpage

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/rivelaine}
  \caption{Fragment Web de la page \url{https://www.yabiladi.com/forum/semoule-fine-pour-couscous} \url{-54-9290786.html}}
  \label{fig:rivelaine}
\end{figure*}

\noindent Tel que retourné par Rivelaine, le fragment Web correspondant se présente à nous comme un ensemble de champs JSON interrogeables (Figure \ref{fig:rivelaine}). Ainsi, le champ \texttt{node} renferme l'ensemble des nœuds HTML du fragment. Son contenu textuel complet est, quant à lui, présenté dans le champ \texttt{text}. Dans le détail, le fragment est constitué d'un auteur, d'une date, d'un texte et de deux nœuds d'expression (champ \texttt{category}), identifiés grâce à leurs labels (champ \texttt{label}). Quand plusieurs nœuds sont imbriqués les uns dans les autres, seul le label du nœud de plus haut niveau est retourné. Plusieurs liens hypertextes ont été extraits (champ \texttt{href}) et nous savons que ce fragment est le 4\ieme{} a avoir été identifié sur cette page (champ \texttt{offset}). Mais il ne représente que $0.008\%$ de l'ensemble du HTML de la page (champ \texttt{ratio}).  Enfin, notons que l'extraction n'est malheureusement pas parfaite. Certains liens hypertextes pourraient ne pas être conservés (par exemple : \texttt{javascript:///}) et nous n'avons pas su identifier le bouton \texttt{[MP]} comme un nœud d'expression permettant de répondre directement à l'auteur du message.\\


\noindent À mesure que se construisait Rivelaine, un changement de stratégie s'est opéré. Il s'agissait au début de définir une méthode de fragmentation universelle, capable de s'adapter à tous types de pages et à tous les âges du Web. Mais force est de constater que les heuristiques, non génériques, ont pris une place grandissante dans l'architecture de Rivelaine. L'automatisme, premièrement visé, s'est effacé au profit d'un agencement compliqué de \textit{bricolages} par heuristiques et d'ajustements manuels. En effet, Fathom (pour ne citer que cet élément) est une méthode infiniment paramétrable. La forme d'un fragment Web, dé\-pend ainsi de la valeur de $minDist$ ou du rapport de grandeur entre les divers malus de la fonction de distance. Doit-on favoriser la cohérence visuelle ? Structurelle ? Sémantique ? Au détriment d'une autre ? 

Le Web est ainsi fait qu'il reste, pour tout chercheur, pour tout explorateur d'archives, un terrain d'étude non trivial. Le Web est vaste et sauvage. Les sites ne se ressembleront jamais, certains seront \textit{mieux} construits que d'autres et aucune méthode de fragmentation ne pourra satisfaire l'ensemble des chercheurs. Ainsi, lors d'une présentation de Rivelaine\footnote{\RaggedOuter Lobbé Q., 2017, \textit{Workshop : Introducing Web Fragments, Computational tools for the social study of Web archives}, Open University Of Israel, Tel Aviv}, l'historien Y. Scioldo-Zürcher suggéra d'ajouter plus de contexte aux fragments Web, d'élargir la segmentation des pages. La forme d'un fragment est, au final, dépendante de la question de recherche qui nous motive et de ce que l'on aimerait trouver dans les archives Web.

Sur les conseils de T. Drugeon, il a été décidé de replacer les cher\-cheurs au cœur de la définition des fragments Web. Pour ce faire, une seconde implémentation de Rivelaine a été développée, cette fois en nodeJs\footnote{\RaggedOuter Voir \url{https://github.com/lobbeque/rivelaine/tree/master/nodejs}}, afin de la rendre autonome et interrogeable en tant que Web service. Nous construisons, par dessus cette application, un \textit{addon}\footnote{\RaggedOuter Voir \url{https://github.com/lobbeque/rivelaine/tree/master/addon},\\ les addon ne sont malheureusement plus compatibles avec les version récentes de Firefox} (c.-à-d., une extension) au navigateur Firefox permettant de tester, sur le Web vivant, la fragmentation d'une page affichée à l'écran. Il est ainsi possible de jouer directement sur les réglages de Fathom et de sa fonction de distance pour apprécier la forme des futurs fragments Web. Une fois le chercheur satisfait, le paramétrage de Rivelaine est ajouté à la configuration du moteur d'exploration des archives et l'extraction peut débuter.     

La fragmentation des archives Web, nous invite à une forme de souplesse et d'agilité vis-à-vis des données qui ne doit pas être le seul fait des outils que nous développons. Toute notre méthodologie d'exploration doit pouvoir débrayer, au besoin, d'un traitement large et automatisé des archives vers une analyse plus focalisée où une grande part du travail se fera à la main. Au cas par cas. Il en va ainsi de toute étude sur le Web, soit une alliance à dimensions variables, entre le chercheur, l'algorithme, l'heuristique, le moteur\ldots{}  

Ainsi, Rivelaine et la stratégie d'extraction qu'elle renferme, ne doi\-vent pas être vues comme la seule et unique manière de construire des fragments Web. Rivelaine n'est qu'une possibilité, parmi d'autres qui, nous l'espérons, arriveront bientôt. Ce que nous défendons, dans ce manuscrit, est la fragmentation des archives Web comme principe d'exploration et non la forme particulière de tel ou tel fragment. Il nous faudra, en revanche, être très clair, dans le Chapitre~\ref{chap:6}, sur la définition de nos espaces d'explorations à venir.    

\section{Penser une exploration désagrégée}
\label{sec:desagreger}

\noindent Voyons, maintenant, comment les fragments Web peuvent nous aider à améliorer certains biais d'analyse identifiés en Section~\ref{sec:4_temporalite}. Nous nous plaçons dans l'hypothèse d'une exploration désagrégée d'un corpus d'archives Web. Nous rappelons qu'un site Web archivé se compose de \textit{n} pages Web numérotées $\{p_1$,...,$p_n\}$. Mais, désormais, une page $p_j$ consiste elle même en \textit{m} fragments Web numérotés $\{f_{j1},...,f_{jm}\}$. Nous supposons connaitre et avoir identifié la date d'édition de chacun de ces fragments $\phi(f_{j1}),...,\phi(f_{jm})$.

\subsection{Atténuer les cécités de crawl}

\noindent En désagrégeant les archives Web, nous faisons l'hypothèse qu'une date d'édition sera toujours antérieure ou égale à une date de téléchargement. C'est une hypothèse plus ou moins forte et qui tient essentiellement à la nature des sites explorés. Une date d'édition peut, en effet, être falsifiée si elle est directement écrite par un humain. Mais, pour un site comme \textit{yabiladi.com}, les dates d'édition, extraites de la partie forum, sont à la base automatiquement générées par le CMS Phorum. Sur l'ensemble de l'e-Diasporas marocaine, nous décomptons plus de $55\%$ de sites associés à un CMS. Nous pouvons donc avoir raisonnablement confiance en la véracité des dates d'éditions manipulées, ainsi :

\[
	\forall p_j,f_{jk} \exists \phi(f_{jk}) : \phi(f_{jk}) \leq \mu_i(p_j) \leq t_i(p_j)
\] 
\[
	\textrm{où } c_i \textrm{ est un crawl dans lequel } f_{jk} \textrm{ existe   }
\]

\noindent Dans la Section~\ref{sec:5_dessous}, nous révélions que, par la désagrégation des archives, il était possible d'accéder à une mémoire antérieure à toute collecte, comme le rappelle la Figure~\ref{fig:frag_blindness}. 

\newpage

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/frag_blindness}
  \caption{La fragmentation de la page $p_1$ permet d'accéder à des éléments antérieurs à la date de collecte $t_1(p_1)$}
  \label{fig:frag_blindness}
\end{figure*}

\noindent Mais essayons maintenant de quantifier ce potentiel gain de mémoire. Quelle peut être la différence, en jours, entre une date de téléchargement et une date d'édition ? 

Pour ce faire, reprenons le cours de l'expérience,  débutée en Section~\ref{sec:5_dessous}, où nous comparions la distribution (pour \textit{yabiladi.com}) du nombre de pages et de fragments archivés suivant leurs dates de téléchargement et d'édition respectives. Nous sélectionnons les 109~534 pages archivées de la section forum de \textit{yabiladi.com} que nous segmentons\footnote{\RaggedOuter Malus maximal sur la cohérence visuelle et les masques de continuité, pour qu'à tout post du forum corresponde un fragment Web}, via notre moteur, en 422~906 fragments Web associés à une date d'édition. Nous considérons, ensuite, la plus ancienne date d'édition de chaque page $\min\limits_{k} \phi(f_{jk})$ pour s'approcher au plus près de leurs dates de création (Section~\ref{sec:5_dessous}). 

Nous calculons alors la différence $\min\limits_{i} t_i(p_j) - \min\limits_{k} \phi(f_{jk})$  entre dates de création et dates de première collecte. La Figure~\ref{fig:timeDiffFull} donne à voir le gain en jours pour chaque page archivée. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/fragment-gain}
  \caption{Distribution de la différence $\min\limits_{i} t_i(p_j) - \min\limits_{k} \phi(f_{jk})$ en jours}
  \label{fig:timeDiffFull}
\end{figure*}

\newpage

\noindent Les quartiles correspondants sont donnés par la Table~\ref{tab:quartiles_1}. Pour $50\%$ des pages archivées de \textit{yabiladi.com} (Table~\ref{tab:quartiles_1}, Q2) le gain est estimé à plus de deux années, la maximum étant de 3131 jours.

\begin{table}
\centering
\hspace{2em}%
  \label{tab:quartiles_1}
  \begin{tabular}{ccl}
    \toprule
    quartiles&différence en jours\\
    \midrule
    Q1 & 256\\
    Q2 & 777\\
    Q3 & 1340\\    
    max & 3131\\  
  \bottomrule
\end{tabular}
  \bigskip
  \caption{Quartiles de la différence $\min\limits_{i} t_i(p_j) - \min\limits_{k} \phi(f_{jk})$ en jours}
\end{table} 

\noindent Mais les bénéfices que nous constatons ici, peuvent être simplement liés à la date de commencement du crawl. En effet, la collecte menée par l'INA a débuté bien après la création de \textit{yabiladi.com}. L'écart entre date de création et date de première collecte ne doit donc pas nous surprendre outre mesure.

Aussi, concentrons-nous plutôt sur des moments singuliers de cette campagne de crawl. D'une part, les six premiers mois de crawl qui correspondent à l'initialisation du corpus, où l'on cherche à capter des pages potentiellement antérieures de 7 ou 8 ans\footnote{\RaggedOuter \textit{yabiladi.com} est crée fin 2002 et la campagne de crawl débute, elle, en 2010}. D'autre part, une année dite de routine (2012-2013), où le crawl n'a plus rien à rattraper et doit simplement se contenter d'archiver les pages nouvellement créées. Nous calculons alors, pour chaque moment, la même différence $\min\limits_{i} t_i(p_j) - \min\limits_{k} \phi(f_{jk})$, les résultats sont donnés par la Table~\ref{tab:quartiles_2}.

\begin{table}
\centering
\hspace{2em}%
  \label{tab:quartiles_2}
  \begin{tabular}{ccc}
    \toprule
    quartiles&différence cas n°1&différence cas n°2\\
    \midrule
    Q1 & 428 & 39\\
    Q2 & 875 & 49\\
    Q3 & 1340 & 1229\\
    max & 2628 & 2389\\      
  \bottomrule
\end{tabular}
  \bigskip
  \caption{Quartiles de la différence $\min\limits_{i} t_i(p_j) - \min\limits_{k} \phi(f_{jk})$ en jours, pour les 6 premiers mois de crawl (cas n°1) et les années 2012-2013 (cas n°2)}
\end{table} 

\noindent Dans le premier cas, la différence de dates est, comme prévue, plus importante : celle-ci passant à 2 ans et 4 mois pour $50\%$ des pages archivées (Table~\ref{tab:quartiles_2}, cas n°1, Q2). Pour le second cas, les gains sont bien moins importants et oscillent majoritairement entre un et deux mois (Table~\ref{tab:quartiles_2}, cas n°2, Q1 et Q2). En revanche, il est intéressant de noter que, même dans un contexte de crawls routiniers, des pages très anciennes continuent à être collectées (Table~\ref{tab:quartiles_2}, cas n°2, Q3), et ce, alors que l'on se serait plutôt attendu à ne découvrir que des pages nouvellement mises en ligne.

Fragmenter les archives Web permet ainsi d'atténuer les diverses cécités de crawl. Mais ces bénéfices seront plus marqués dans le cadre d'une collecte déclenchée après la création du site ciblé (notre cas), que lors d'un crawl routinier (le cas d'Internet Archive).    

\subsection{Cohérence relative entre pages}

\noindent Lorsque nous explorions les archives Web au niveau des seules pages (Section~\ref{sec:4_temporalite}), nous avions défini la cohérence par observation comme l'existence d'un unique instant $t_{\mathrm{coherence}}$ où se croisent les intervalles d'invariance respectifs des pages considérées \citep{spaniol_data_2009}, et ce, dans le cadre d'un crawl unique. \\

\noindent Avec le fragment Web, nous pouvons dépasser cette définition et introduire la notion de \textbf{cohérence relative par observation}. Entre deux pages, la cohérence telle que nous la connaissons est absolue (Figure \ref{fig:coherence}), l'entièreté des pages est considérée. Or, nous nous plaçons maintenant dans le cadre d'une analyse focalisée sur un élément particulier par page archivée. 

Par exemple, si un chercheur souhaite vérifier la cohérence entre deux articles collectés, il pourrait vouloir connaitre la nature précise de l'in\-tervalle d'invariance correspondant. À ses yeux, la cohérence serait hors sujet ou abusive, si le seul élément d'invariance entre les deux pages se révèlait être une barre de navigation plutôt que le corps des articles. Comment, dès lors, considérer la cohérence relativement à une question de recherche donnée ? 

Sur ce point, nous définissons un sous-ensemble discret de fragments d'intérêt $\{f^*_{j1},...,f^*_{jl}\}$ (avec $l \leq m$). Le chercheur sélectionne, dans chaque page, un fragment Web qui lui semble pertinent pour son analyse. Puis il vérifie la cohérence $t^*_{\mathrm{coherence}}$ entre toutes ces pages relativement aux fragments considérés, ainsi :

\[
	\forall p_j, \forall f^*_{jk} \in \{f_{j1},...,f_{jm}\}, \exists t^*_{\mathrm{coherence}}:
\] 
\[
	t^*_{\mathrm{coherence}} \in \bigcap_{j}[\phi(f^*_{jk}),t_i(p_j)] \neq \emptyset
\] 

\noindent En désagrégeant les archives Web, le chercheur peut reprendre la main sur les analyses qu'il entend mener au cœur des archives. Il peut focaliser, à souhait, son expérience d'explo\-ration et déplacer son point d'observation relativement à son sujet. La Figure~\ref{fig:frag_coherence} décrit, de manière graphique, la différence entre cohérence par observation et cohérence relative par observation, pour deux pages $p_1, p_2$ et deux fragments Web choisis $f^*_{11}, f^*_{21}$. 

\newpage

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/frag_coherence}
  \caption{Cohérence par observation et cohérence relative par observation}
  \label{fig:frag_coherence}
\end{figure*}

\noindent Il serait intéressant d'étendre cette notion de cohérence relative par observation à la prise en compte de plusieurs fragments Web par pages archivées ou de plusieurs crawls. Enfin, nous n'avons pas eu ici l'occasion de proposer une expérimentation pratique de la cohérence relative par observation. Mais nous pensons qu'il est tout-à-fait faisable de l'intégrer à un système d'exploration d'archives Web et encourageons la mise en place future de travaux voulant traiter ce sujet.  

\subsection{Dédupliquer les corpus}

\noindent En Section~\ref{sec:4_temporalite}, nous nous sommes inquiétés de la possibilité de voir plusieurs fois le même contenu archivé dans un corpus. Cela peut provoquer des biais d'analyse, notamment si l'exploration est basée sur une recherche plein texte. Mais par la désagrégation des archives, il est possible de dédupliquer des éléments qui auraient été re-collectés d'un crawl à l'autre. En utilisant le fragment Web comme unité d'exploration, nous pouvons définir une \textbf{fonction d'identité} nommée $id$. Cette fonction compare l'invariance dans le temps, d'un fragment $f_{jk}$ extrait d'une page $p_j$, au cours de deux crawls consécutifs $c_1$ et $c_2$ à $t_1(p_j)$ et $t_2(p_j)$ tel que :    
\[
	id(c_1(f_{jk})) = c_2(f_{jk})
\]
\noindent La Figure~\ref{fig:frag_doublon} illustre cette idée. D'un point de vue technique, la fonction d'identité ne peut être mise en place qu'au moment de retourner les résultats d'une requête depuis le moteur de recherche (Section~\ref{sec:4_moteur}). En effet, l'extraction des fichiers DAFF étant parallélisée, il serait trop couteux de maintenir un index dynamique des fragments Web déjà identifiés. Nous laissons donc, à dessein, des doublons dans les index. C'est lors de la restitution de ces résultats par Solr que nous les grouperons via la fonction d'identité.  

\newpage

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/frag_doublon}
  \caption{Dédupliquer les archives Web entre deux crawls $c_1$ et $c_2$ grâce à une fonction d'identité}
  \label{fig:frag_doublon}
\end{figure*}

\noindent Pour ce faire, nous associons à chaque fragment Web un champ unique appelé \texttt{frag\_text\_id}. Ce champ est le résultat du passage de l'ensemble du contenu textuel du fragment Web dans une fonction de hachage\footnote{\RaggedOuter Fonction déjà évoquée en Section~\ref{sec:3_constituer} pour les identifiants des fichiers DAFF.} SHA-256. Nous utilisons la fonction \textit{group by}\footnote{\RaggedOuter Voir \url{https://lucene.apache.org/solr/guide/6_6/result-grouping.htmlf}} de Solr pour grouper les fragments potentiellement dupliqués par \texttt{frag\_text\_id} unique. \\

\noindent Dans notre modèle d'exploration désagrégé, une page Web archivée et observée à un instant $t$ donné, ne sera plus que le résultat de l'assem\-blage de fragments Web précédemment publiés. La page Web, en tant que telle, disparait de notre modèle de données. 

\section{Intégration au moteur d'exploration}
\label{sec:retour_au_moteur}

\noindent Notre moteur d'exploration d'archives Web, tel que nous l'avions décrit en Section~\ref{sec:4_moteur}, prend la page Web comme unité principale d'exploration. Mais, depuis, nous avons opéré un changement analytique de la page vers le fragment Web. Expliquons maintenant comment intégrer le fragment à notre moteur et proposons un premier cas d'usage, basé sur la détection d'événements dans les archives.

\subsection{D'un schéma à l'autre}

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/rivelaine_moteur}
  \vspace*{0.2cm}  
  \caption{Intégration de la fragmentation au pipeline de transformation des archives (Voir Figure~\ref{fig:spark})}
  \label{fig:rivelaine_moteur}
\end{marginfigure}

\noindent D'un point de vue pratique, l'extraction des fragments s'intègre à l'ensemble des traitements supervisés par Spark (Section~\ref{sec:5_scraping}). Une fois la jointure effectuée entre méta-données et données, notre moteur demande à Rivelaine de segmenter les pages archivées avant de les envoyer dans Solr pour indexation (Figure~\ref{fig:rivelaine_moteur}).

Un nouvel index doit alors être créé pour accueillir les fragments, le premier étant pensé pour les pages Web uniquement. Deux stratégies s'offrent ici à nous. Tout d'abord, conserver la page comme élément de référence, à laquelle nous subordonnons les fragments (Figure~\ref{fig:schema_vs}, (a)). Ou éliminer la notion même de page et n'indexer que les fragments (Figure~\ref{fig:schema_vs}, (b)). 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/schema_vs}
  \caption{Différentes stratégies d'indexation du fragment Web dans un moteur de recherche et complexité de la recherche (bleu)}
  \label{fig:schema_vs}
\end{figure*} 

\noindent La première option, plus intuitive, conserve le lien ontologique entre la page et ses fragments Web. Elle nécessite la mise en place dans Solr, d'une structure dite de \textit{nested documents}\footnote{\RaggedOuter Documents imbriqués, \url{http://yonik.com/solr-nested-objects/}}. Dans un même index, deux types de documents cohabiteraient, un document page et des documents fragments. Malheureusement, cette stratégie est couteuse, notamment lorsqu'il s'agit d'identifier et de retourner des résultats. En effet, dans les moteurs de recherche, il est toujours conseillé (surtout lorsque le nombre de documents est important) de dupliquer au besoin les documents indexés. L'espace disque occupé par l'index sera plus important, mais les performance du \textit{search}, en tant que tel, seront améliorées, la complexité d'une recherche par documents à plat étant moindre que celle par documents imbriqués pour laquelle toute la structure doit être retournée (Figure  \ref{fig:schema_vs}, tracés bleus). 

Nous nous orientons donc vers la seconde option, qui a pour effet de dupliquer les informations associées à une page à l'intérieur de chaque fragment. Si l'utilisateur veut, au besoin retrouver l'ensemble des fragments d'une même page, il pourra s'orienter vers une requête \textit{group by} sur le champ \texttt{page\_id} dans Solr. 

Soit le schéma d'indexation des fragments Web présenté par la Figure~\ref{fig:schema_2}. Dans ce schéma, l'\texttt{id} de chaque document correspond à l'identifiant unique d'un fragment. Les champs issus de Rivelaine (\texttt{frag\_type}, \texttt{frag\_offset}\ldots{}) sont intégrés à l'index et la recherche plein texte est maintenant réalisée sur le seul champ \texttt{frag\_text}. Pour retrouver l'ensemble des fragments d'une même page, on se servira du champ \texttt{page\_url\_id} et pour dédupliquer les fragments (Section~\ref{sec:desagreger}), on s'appuiera sur la valeur de \texttt{frag\_text\_id}\footnote{\RaggedOuter Clé SHA-256 unique}. Les différents niveaux de notre échelle de datation (Table~\ref{tab:datation_2}) sont indexés, le champ \texttt{page\_date} correspondant à la date de création d'une page (Section~\ref{sec:5_dessous}). Le champ \texttt{frag\_date} est, lui, supposé contenir les dates d'édition de chaque fragment. Néanmoins, si nous sommes dans l'impossibilité d'associer une date d'édition à un fragment, le champ \texttt{frag\_date} se verra attribuer la valeur de \texttt{page\_date}, voire de la date de téléchargement \texttt{download\_date} dans le pire des cas. Sur ce point, le type \texttt{dateLvl} nous renseigne sur le niveau de précision alloué au champ \texttt{frag\_date}.

\begin{figure*}
\small
\begin{verbatim}
<field name="id"                type="string"  indexed="true"    multiValued="false" required="true" />

<!-- archive fields -->
<field name="archive_active"    type="boolean" indexed="true"    multiValued="false"/>
<field name="archive_corpus"    type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_country"   type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_lang"      type="double"  indexed="true"    docValues="true" multiValued="false"/>
<field name="archive_mime"      type="string"  indexed="true"    docValues="true" multiValued="false"/>  

<!-- crawl fields -->
<field name="crawl_id"          type="string"  indexed="true"    docValues="true" multiValued="true" />
<field name="crawl_id_f"        type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="crawl_id_l"        type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="crawl_date"        type="date"    indexed="true"    docValues="true" multiValued="true" />
<field name="crawl_date_f"      type="date"    indexed="true"    docValues="true" multiValued="fasle"/>
<field name="crawl_date_l"      type="date"    indexed="true"    docValues="true" multiValued="true" />

<!-- download fields -->
<field name="download_date"     type="date"    indexed="true"    docValues="true" multiValued="true" />
<field name="download_date_f"   type="date"    indexed="true"    docValues="true" multiValued="false"/>
<field name="download_date_l"   type="date"    indexed="true"    docValues="true" multiValued="false"/> 

<!-- page fields -->
<field name="page_domain"       type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="page_url"          type="string"  indexed="true"    docValues="true" multiValued="false"/>
<field name="page_url_id"       type="string"  indexed="true"    docValues="true" multiValued="false"/>      
<field name="page_link"         type="string"  indexed="true"    docValues="true"  multiValued="true"/>      
<field name="page_title"        type="text"    indexed="true"    docValues="false" multiValued="false"/>
<field name="page_date"         type="date"    indexed="true"    docValues="true"  multiValued="true" />

<!-- fragment fields -->
<field name="frag_type"         type="string"  indexed="true"    docValues="true"  multiValued="true" />    
<field name="frag_author"       type="string"  indexed="true"    docValues="false" multiValued="true" />
<field name="frag_date"         type="date"    indexed="true"    docValues="true"  multiValued="true" />
<field name="frag_date_level"   type="dateLvl" indexed="true"    docValues="true"  multiValued="false"/> 
<field name="frag_href"         type="string"  indexed="true"    docValues="false" multiValued="true" />
<field name="frag_label"        type="string"  indexed="true"    docValues="true"  multiValued="true" />
<field name="frag_ratio"        type="int"     indexed="true"    docValues="true"  multiValued="true" />
\end{verbatim} 
\end{figure*}

\newpage

\begin{figure*}
\small
\begin{verbatim}
<field name="frag_node"         type="text"    indexed="false"   docValues="false" multiValued="true" />  
<field name="frag_offset"       type="int"     indexed="true"    docValues="true"  multiValued="true" />
<field name="frag_text_id"      type="string"  indexed="true"    docValues="true"  multiValued="false"/>

<!-- searchable fragment fields -->
<field name="frag_text"         type="text"    indexed="true"    stored="false"  multiValued="true" />
<field name="frag_text_shingle" type="shingle" indexed="true"    stored="false"  multiValued="true" />   
\end{verbatim} 
\caption{Schéma d'indexation des fragments Web}
\label{fig:schema_2}
\end{figure*}

\subsection{Détection d'événements}

\noindent Comme cas d'usage pratique du fragment Web, nous souhaitons maintenant ajouter à notre moteur d'exploration un système de détection d'événements dans les archives. Cette proposition a fait l'objet d'une publication démonstration\footnote{\RaggedOuter Lobbé, Q. (2018), \textit{Revealing Historical Events out of Web Archives}, TPDL 2018} dont l'application est, jusqu'à présent, limitée aux seules archives du site \textit{yabiladi.com}. 

La recherche par événements est une alternative aux méthodes d'ex\-ploration classiques qui se font principalement par URL (Section~\ref{sec:3_constituer}). Des travaux récents tentent également de s'en affranchir en proposant des analyses par catégories \citep{holzmann_tempas:_2016}, par entités nommées \citep{spaniol_tracking_2012} ou basées sur des tendances issues des réseaux sociaux \citep{risse_arcomem_2014}. Dans l'ensemble, tout indique que, face à des corpus d'archives Web si vastes, une exploration dirigée ou guidée (par exemple sur la base d'événements) peut être bénéfique. 

Nous pensons que tout explorateur d'archives (Web ou autre) poursuit à un moment donné la recherche d'événements singuliers qu'il puisse mettre au regard de l'histoire \citep{chaney_who_2015}. Ainsi, pour J. Baschet (Section~\ref{sec:5_dessous}) l'étude historique de lignes processuelles passe par une pensée de l'évé\-nement comme \og\textit{surgissement}\fg{} ou \og\textit{rupture}\fg{} \citep[p.227]{baschet_defaire_2018}.\\ 

\noindent Au sein d'une distribution temporelle d'éléments donnés, un événement peut être caractérisé de trois manières différentes comme le propose \citep[p.106]{viard_link_2016} : par sa détection, par son identification et par son explication. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/event}
  \vspace*{0.2cm}  
  \caption{Détection d'événements à partir d'un seuil}
  \label{fig:event}
\end{marginfigure}

Un événement \textbf{détecté} est une anomalie présente dans une distribution. Il peut s'agir d'un instant singulier ou d'une période entière durant laquelle le niveau de messages postés sur un blog est supérieure à une valeur de référence (une moyenne par exemple). Un événement \textbf{identifié} est un événement pour lequel un élément de causalité aura été trouvé dans les données sources. Un pic d'activité dans un forum en ligne est, par exemple, causé par un nombre important de messages postés. Enfin, un événement \textbf{expliqué} est un événement pour lequel une explication aura été trouvée et validée à l'extérieur des données sources. Ici, une expertise et une analyse humaine est nécessaire. Un pic de messages dans un forum peut, ainsi, être expliqué par un contexte social ou politique particulier qui aura fait réagir certains membres de la communauté.  

Continuant sur notre logique exploratoire, nous ne voulons pas ici cibler une forme particulière d'événements, nous éviterons donc les méthodes de détection par motif \citep{chaney_detecting_2016} ou classification  \citep{dodds_temporal_2011}. Nous nous orientons plutôt vers une méthode de détection par \textbf{seuil} \citep{fung_parameter_2005} à l'intérieur d'une fenêtre glissante d'une semaine\footnote{\RaggedOuter Sur \textit{yabiladi.com}, la durée de vie moyenne d'un thread de messages est d'un peu plus d'un jour, le choix de prendre la semaine comme granularité nous a donc semblé judicieux}. Nous définissons ici un événement comme une valeur aberrante détectée au sein d'une distribution de fragments Web (Figure~\ref{fig:event}).

Pour ce faire, le contenu textuel de chaque fragment Web indexé est divisé en \textbf{bigrammes}\footnote{\RaggedOuter Le champ \texttt{frag\_text\_shingle} de notre schéma d'indexation (Figure~\ref{fig:schema_2})}. Un bigramme est une séquence de deux mots consécutifs extraite d'un même ensemble textuel (Figure~\ref{fig:bigram}). 

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/bigram}
  \caption{Division d'une phrase en bigrams}
  \label{fig:bigram}
\end{figure} 

\noindent Dans le cadre de cette démonstration, la recherche plein texte porte sur le contenu textuel des bigrammes. Le moteur ne retourne donc plus que les fragments Web dont certains bigrammes auraient correspondus à des mots clés proposés par un chercheur. Dans notre cas, identifier un événement revient, en réalité, à détecter un pic soudain de bigrammes dans le temps. Les bigrammes sont souvent utilisés pour observer des tendances ou des évolutions lexicales au sein de grands corpus de textes. On citera par exemple, le système \textit{ngrams viewer}, conçu par les équipes de Google books, qui permet de suivre l'évolution temporelle de l'utilisation de certains mots dans leur base de données de livres numérisés \citep{michel_quantitative_2011}.\\

\noindent Pour terminer, nous essayons d'expliquer nos événements en trouvant des corrélations avec certains titres d'articles de news, extraits des archives de la section actualités du site \textit{yabildai.com}. En effet, nous faisant l'hypothèse que les utilisateurs du forum sont susceptibles de réagir, par le biais de messages, à un événement précis de l'actualité (avant ou après que celui-ci ait été rapporté dans la presse). 

Nous construisons ainsi, à la volée, un nouvel index d'événements potentiels en utilisant le titre et la date d'édition de ces articles archivés. Lorsqu'un pic de messages est détecté, une requête secondaire est automatiquement adressée à notre index d'événements possibles. Si l'un des titres correspond également à la recherche du chercheur et que sa date d'édition se trouve à moins d'une semaine de la date du pic détecté, alors nous proposons ce titre comme potentielle explication de cette soudaine recrudescence de messages.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/ben-ali}
  \caption{Ajout de la détection d'événements à notre interface d'exploration}
  \label{fig:ben-ali}
\end{figure*} 

\noindent Notre interface de visualisation est modifiée en conséquence et permet maintenant au chercheur de choisir la granularité d'explo\-ration qui l'intéresse le plus, entre la page et le fragment (Figure~\ref{fig:ben-ali}). Dans la partie fragment Web, apparait un nouvel histogramme affichant la distribution dans le temps des bigrammes ayant correspondus à la requête du chercheur. C'est sur cet histogramme que sont affichés les événements détectés et leur possible explication. Dans une vidéo de démonstration\footnote{\RaggedOuter Consultable ici : \url{https://youtu.be/snW4O-usyTM}}, nous décrivons différents cas d'usages de ce système et, plus généralement, nous y présentons le fonctionnement du moteur d'exploration. 

Nous donnons ainsi à voir, comme exemple d'événements détectés dans les archives, des pics de discussion autour de diverses actualités liées au roi du Maroc Mohammed VI et des réactions à la destitution de l'ancien dirigeant tunisien Z. Ben-Ali, au début de l'année 2011 (Figure~\ref{fig:ben-ali}, tracé vert). Dans le Chapitre~\ref{chap:6}, nous reviendrons en détail sur la manière avec laquelle le forum de \textit{yabiladi.com} a réagi à ce moment historique particulier qu'a été le Printemps arabe.

\newpage

\begin{center}
	\textbf{***}
\end{center}

\noindent Malgré notre idée première, l'extraction des fragments Web n'a pas pu se faire sans une forte dose d'heuristiques non génériques. Le Web est ainsi fait qu'il nous oblige, sans cesse, à ré-adapter l'échelle de nos analyses. Passant de vastes traitements automatisés à des moments de pur travail manuel. Au cas par cas. Nos explorations à venir ne contrediront pas cet état de fait : notre méthode d'exploration chemine dans un entre-deux constant entre approche quantitative et validation qualitative. Il nous faut ainsi mettre les mains dans les archives, les ouvrir et y plonger.

C'est, au final, toute l'ambition du fragment Web, tel que nous l'avons introduit dans ce chapitre. Redonner au chercheur les moyens théoriques et techniques d'une plus grande maniabilité des archives. Le terrain théorique ayant été préparé, dans le courant des années 2000, par les travaux pionniers de N. Brügger, il existait un espace analytique à explorer entre l'élément Web et la page Web. Nous définissons ainsi le fragment Web comme un sous-ensemble sémantique et syntaxique d'une page Web.

Avec le fragment Web et la grammaire qu'il introduit, le chercheur quitte les interfaces d'exploration vitrines et s'assoit à la table de montage où il peut découper, déplacer et mettre en relation des éléments épars du Web passé. Nous avons ainsi montré comment, en s'appuyant sur les dates d'édition plutôt que sur les seules dates de téléchargement, les archives en arrivent à basculer d'une temporalité à l'autre. Elles quittent le temps des crawlers pour retrouver le temps du Web tel qu'il a été. Le chercheur accède alors à une mémoire antérieur aux collectes des archivistes, mémoire jusqu'ici retenue derrière le verrou des fichiers sauvegardés. Le fragment témoigne ainsi directement du geste des auteurs, lecteurs et bloggers du Web passé et replace, de fait, l'humain au cœurs de l'étude des archives Web.

Intégrés à notre moteur d'exploration, nous nous appuierons sur les fragments Web pour mener, dans le chapitre suivant, deux explorations à travers notre corpus de sites marocains. Nous étudierons l'histoire de collectifs migrants en ligne, depuis longtemps éteints et dont la trace ne subsiste aujourd'hui plus que dans les archives.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 6 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\begin{minipage}[t,leftmargin=5em]{1.5\linewidth}%
\begin{adjustwidth}{-0.5cm}{}
\chapter{Exploration de collectifs migrants éteints} 
\label{chap:6}
\end{adjustwidth}
\end{minipage}
\hfill

\noindent Le processus de cartographie de l'e-Diaspora marocaine s'est étalé sur près de deux ans, de 2008 à 2010. L'archivage de ces sites s'est alors présenté comme une nécessité, leurs traces commençant déjà à disparaitre de la toile. Dix ans plus tard, en 2018, sur les 153 sites observés à l'époque, seuls 53 peuvent encore être qualifiés de vivants, c'est-à-dire : toujours en ligne et ayant été mis à jour au moins une fois au cours de la dernière année passée. Les deux autres tiers sont pour la plupart hors ligne, tombés à l'abandon ou récupérés par des cybersquatteurs\footnote{\RaggedOuter Technique de hacking consistant à prendre possession d'un nom de domaine existant et de publier à sa place un contenu autre (e-commerce, publicités, arnaques, pornographie\ldots{})}.      

Le Web est un environnement éphémère (Section~\ref{sec:3_constituer}) et les e-Diaspo\-ras ne sont, au final, que des images instantanées d'un espace qui, une fois la capture effectuée, n'est déjà n'est plus tout a fait le même. Il a continué à évoluer et s'est transformé. 

Parmi les nombreux sites du corpus marocain, les plateformes institutionnelles (Section~\ref{sec:2_atlas}) sont celles qui ont le mieux résisté au passage du temps. En effet, $50\%$ d'entre elles sont toujours vivantes et leur ancrage durable en ligne semble résulter d'une stratégie planifiée. La petite dizaine de sites consulaires identifiés en 2008 s'est ainsi muée en un seul et même portail Web \textit{consulat.ma}\footnote{\RaggedOuter Voir \url{http://www.consulat.ma/fr/aide.cfm}, site lancé en 2011 dans le cadre du Plan Maroc Numeric 2013 (\url{http://www.egov.ma/sites/default/files/Maroc\%20Numeric\%202013.pdf})} sous l'impulsion du gouvernement marocain. Puis, derrière elles, viennent les sites des associations et ONG dont $30\%$ sont encore accessibles. Mais c'est le cas de la blogosphère qui, en ce début de chapitre, nous interpelle le plus : sur les 48 blogs cartographiés, seuls 5 sont aujourd'hui vivants (soit à peine $10\%$).

Au sein de l'e-Diaspora marocaine, la blogopshère avait été caractérisée\footnote{\RaggedOuter Voir l'intervention de M. Renault (\url{https://www.youtube.com/watch?v=1sE5PZVG6iM})} comme une communauté densément liée entre chacun de ses membres. Soit un espace d'expression et de représentation où circulaient, tout autant, commentaires politiques que témoignages de la vie quotidienne des marocains de l'étranger. Pourquoi ce groupe de blogs s'est-il à ce point réduit, perdant au cours du temps son influence et son dynamisme ? Les blogueurs ont-ils simplement disparu et quitté la toile ? Ou ont-ils migré vers d'autres territoires du Web ? Peut-on remonter le fil des potentielles traces archivées de cette cybermigration et en déterminer la destination ?

Au cours de ce chapitre, nous mènerons deux explorations successives, proposant chacune une utilisation différente des fragments Web. La première nous permettra de comprendre la mutation progressive des blogs marocains vers les plateformes de réseaux sociaux à la fin des années 2010. Cette transformation, nous le découvrirons, est autant le fait d'une évolution technologique inhérente au Web, que le résultat de l'influence d'événements socio-politiques extérieurs à la toile. Parmi ces événements, le Printemps arabe et, plus particulièrement, la manifestation marocaine du 20 février 2011 semblent avoir été des moments déterminants de l'histoire de la blogosphère. 

En suivant cette nouvelle piste, nous questionnerons la réception de ce même événement par les membres d'un autre collectif en ligne, central dans la vie de l'e-Diaspora marocaine : le forum de \textit{yabiladi.com}. Nous comprendrons la manière avec laquelle les membres de ce site se sont momentanément organisés et retrouvés emportés par la vague révolutionnaire qui déferlait alors sur le Maghreb et le Moyen Orient. 

Comme un bilan de ces deux explorations nous introduirons, pour terminer, la notion de \textbf{moments pivots du Web} : des instants particuliers de l'histoire de la toile où celle-ci change soudainement de direction par la rencontre d'une avancée technologique et d'un groupe d'utilisateurs capables de s'en saisir\footnote{\RaggedOuter Ce chapitre a fait l'objet d'une publication : Q. Lobbé, (2018), \textit{Where the dead blogs are}, BDA, 2018}.

Mais, avant de débuter notre analyse, nous souhaitons revenir sur les aspects théoriques de ce que nous nommons \textbf{exploration} depuis le début de ce manuscrit. Il s'agit pour nous de présenter comment, ce courant des statistiques qu'est l'analyse exploratoire de données (AED), peut aujourd'hui servir de cadre méthodologique à une recherche portant sur le Web passé.\\

\section{À la recherche de l'étonnement}
\label{sec:6_eda}

\noindent Dans le courant du 19e siècle, la théorie statistique prend un tournant rigoriste majeur en préférant, à la longue tradition exploratoire\footnote{\RaggedOuter Les statisticien ont longtemps été des explorateurs de données, palliant certaines lacune théorique, par l'utilisation d'outils de recueil des données simples et visuels, comme le comptage par Quipu chez les civilisations précolombiennes (\url{https://fr.wikipedia.org/wiki/Quipu}).}, des analyses et des inférences toutes tournées vers la seule quête de l'optimalité, de la moyenne et de la loi normale \citep{ladiray_laed_1997}. Les statisticiens tombent alors dans une logique \textbf{confirmatoire}, faisant des hypothèses fortes sur la nature même des données étudiées qui, dès lors, ne sont plus sources de calculs statistiques, mais un moyen vers la validation d'un modèle. La donnée est subordonnée au modèle et le réel doit venir confirmer la théorie. La domination des statistiques confirmatoires s'établit ainsi au détriment des statistiques exploratoires, souvent décriées par l'appellation péjorative de statistiques \textbf{descriptives}.

\subsection{L'analyse exploratoire de données}

\noindent L'\textbf{analyse exploratoire de données} (AED) est un courant de la statistique moderne introduit, au cours des années 60 et 70, par le statisticien J.W. Tukey \citep{tukey_exploratory_1977}. Voulant réintroduire le réel au cœur des statistiques, Tukey préfère la résolution (même approximative) d'un problème véritable à la recherche d'un indicateur optimal sur une question de peu d'intérêt~:\\

\begin{fullwidth}
\og\textit{The most important maxim for data analysis to heed, and one which many statisticians seem to have shunned, is this: Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise. Data analysis must progress by approximate answers, at best, since its knowledge of what the problem really is will at best be approximate. It would be a mistake not to face up to this fact, for by denying it, we would deny ourselves the use of a great body of approximate knowledge, as well as failing to maintain alertness to the possible importance in each particular instance of particular ways in which our knowledge is incomplete.}\fg{} --- \citep[p.13-14]{tukey_future_1962}\\
\end{fullwidth}

\noindent Pour Tukey, les statistiques doivent ainsi retrouver le gout de l'in\-certitude et traiter à nouveau de la réalité. Ainsi tout modèle ou toute analyse doit, selon lui, partir d'une réflexion empirique, sensible. Les données doivent guider le choix des méthodes utilisées pour les étudier, et non l'inverse. C'est par la connaissance intime des données, que l'explorateur peut faire émerger des pistes de recherche et des hypothèses de travail. Il faut éprouver (qualitativement) les données dans la durée et retrouver une forme de rapport artisanal vis-à-vis d'elles. En cela, l'AED est un processus fondamentalement itératif, basé des boucles d'explorations successives, où l'analyste est amené à conjuguer intuition, capacités visuelles et expérience des données.

Là où les statistiques confirmatoires s'inscrivent dans l'administra\-tion de la preuve, l'analyse exploratoire, elle, s'articule autour d'une logique d'observation et de découverte.  

\subsection{Suivre et s'attacher aux indices}

\noindent L'AED avance par investigation, guidée par la découverte de l'inattendu. L'explorateur multiplie les facets et les vues lui permettant de décrire les données dans leur ensemble et se place ainsi dans une position d'étonnement. Il s'agit de s'attacher autant aux tendances générales qu'aux détails, pour progresser pas à pas, par hypothèses successives en suivant la piste des indices précédemment révélés (Figure~\ref{fig:aed-1}). Mais, dans le l'esprit de Tukey, l'AED ne doit pas remplacer l'analyse confirmatoire, il convient plutôt de conjuguer les deux : les boucles d'exploration (Figure~\ref{fig:aed-1}, a) préfigurent et induisent toute modélisation (Figure~\ref{fig:aed-1},~b). 

\newpage

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/aed-1}
  \caption{L'analyse exploratoire et les diverses phases de l'exploration préfigurent toute analyse confirmatoire}
  \label{fig:aed-1}
\end{figure*} 

\noindent L'AED rencontre rapidement un écho grandissant, porté par le dé\-veloppement des techniques de calculs et de visualisations informatiques. Plusieurs années après, enrichissant sa réflexion par la lecture des travaux de J. Bertin\footnote{\RaggedOuter Inspirateur de la sémiologie graphique ou science de la représentation graphique des données (\url{https://visionscarto.net/la-semiologie-graphique-a-50-ans})} \citep{bertin_semiologie_1973}, B. Fry propose de définir ce qu'il nomme \textbf{conception computationnelle d'information}\footnote{\RaggedOuter \textit{Computational information design} en anglais} \citep{fry_computational_2004}, comme une version moderne de l'AED, explicitement orientée vers la visualisation de données et la programmation informatique. Tout autant processus d'exploration itératif (Figure~\ref{fig:aed-2}) qu'art de la représentation de la donnée, la méthode de Fry accompagne et motive le dé\-veloppement d'outils neufs, tels que l'environnement de programmation Processing\footnote{\RaggedOuter \url{https://processing.org/}} ou encore la librairie Javascript D3 créée par M.~Bostock\footnote{\RaggedOuter https://d3js.org/}.

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/aed-2}
  \caption{Étapes de la conception computationnelle d'information et ensemble des boucles d'analyses possibles selon \citep{fry_computational_2004}}
  \label{fig:aed-2}
\end{figure*} 

\noindent Ce mode d'analyse par explorations offre un cadre méthodologique adapté à l'étude que nous souhaitons ici mener sur les archives Web. Concernant le devenir des blogs marocains après 2008, nous ne disposons au début de notre étude que d'un faisceau assez faible d'indices susceptibles d'expliquer la disparition de la blogosphère. De plus, la taille de l'espace d'exploration (48 blogs segmentés en un multitude de fragments Web) et son étendue (4 années d'archives) nous pousse à cheminer par à-coups et à inférer de nos trouvailles de nouvelles hypothèses de travail. En cela, l'AED est souvent comparée (par Tukey lui même\footnote{\RaggedOuter \og\textit{(EDA) is detective work – numerical detective work – or counting detective work – or graphical detective work\ldots{} unless exploratory data analysis uncovers indications, usually quantitative ones, there is likely to be nothing for confirmatory data analysis to consider}\fg{} --- \citep[p.1-3]{tukey_exploratory_1977}}) au travail du détective qui tisse la trame de ses recherches à travers un réseau d'indices. 

Ce raisonnement par inférence, qui émerge de notre description de l'AED, peut être rapproché d'un autre mode de pensée découvert par C. Ginzburg en 1979 : le \textbf{paradigme indiciaire} \citep{ginzburg_signes_1980}. En effet, l'historien révèle que, dans nombre de disciplines liées aux sciences humaines (psychanalyse, histoire de l'art, médecine\ldots{}), s'est installé au fil du temps, un paradigme permettant de révéler à partir d'effets ou d'éléments singuliers des événements plus généraux\footnote{\RaggedOuter \og\textit{Si la réalité est opaque, des zones privilégiées existent (traces, indices) qui permettent de la déchiffrer.}\fg{} --- \citep[p.290]{ginzburg_mythes_2012}}. Le psychanalyste progresse par l'étude des symptômes du patient et l'historien de l'art étudie les traces du geste du maître derrière le pinceau.

Née à la suite des travaux de Ginzburg, la \textbf{micro-histoire} s'attache à analyser historiquement des objets de tailles limitées. Les chercheurs cheminent d'indices en indices, à la manière d'un Sherlock Holmes, pour compléter l'étude de trajectoires et de motivations individuelles. La micro-histoire se veut, ainsi, le contre-poids focalisé d'une pratique plus quantitative du travail de l'historien. 

Comme pour l'AED face aux statistiques confirmatoires, on reproche à la micro-histoire la non représentativité de ses travaux, trop précis et détachés de l'étude des tendances historiques normales et des grandes structures de masse. Mais, sur ce point, et c'est l'élément qui nous intéresse ici tout particulièrement, selon Ginzburg l'anomalie ou l'objet singulier peut se révéler porteur d'une résonance plus globale :\\

\begin{fullwidth}
\og\textit{La possibilité de passer du cas isolé à la généralisation part d'une hypothèse qui a gagné en clarté à travers le temps. Aujourd'hui, je proposerai de considérer un individu comme le point d'intersection d'une série d'ensembles différents qui ont chacun une dimension variable. [\ldots{}] L'historien doit partir de l'hypothèse que chez tout individu quel qu'il soit, coexistent des éléments partagés par un nombre variable (entre plusieurs milliards et zéro) d'individus. L'anomalie sera le résultats des réactions réciproques entre tous ces éléments.}\fg{} --- \citep[p.359-360]{ginzburg_mythes_2012}\\
\end{fullwidth} 

\noindent Dans les explorations à venir nous nous attarderons autant sur les tendances générales que sur les détails singuliers, suivant la tradition de l'AED. Mais l'incomplétude des archives Web, leur caractère partiel et détaché (sous certains aspects) de la réalité du Web vivant, nous conduiront à affiner petit à petit notre échelle d'analyse, à nous concentrer sur de plus petits objets dont certains détails nous auront révélé l'importance. 

Ce faisant, il peut alors être vertigineux de penser que, partant d'une archive de 70 téra-octets, on en vienne à explorer, \textit{seulement}, le devenir en ligne d'une poignée d'internautes. Mais, en nous inspirant des travaux de Ginzburg, nous chercherons à repositionner ces éléments singuliers par rapport aux grandes vagues historiques dont ils ont été témoins ou vecteurs privilégiés. 

\section{Les traces d'une mutation numérique}
\label{sec:6_blogs}

\noindent Concentrons nous maintenant sur le devenir de la blogosphère marocaine, entre 2008 et 2018. Essayons de comprendre, à travers les archives Web, le ou les processus qui ont amené à sa disparition quasi-complète. Sommes-nous témoins d'une extinction ? Ou d'une migration d'un territoire du Web vers un autre ? Peut-on encore trouver, dans nos collectages, les traces archivées d'une possible mutation des blogs vers les plateformes de réseaux sociaux ? 

\subsection{D'une communauté de blogs\ldots{}}

\noindent Entre 2008 et 2010, D. Diminescu et M. Renault cartographient et recensent 47 blogs\footnote{\RaggedOuter Voir la carte \url{http://www.e-diasporas.fr/wp/moroccan.html}} qu'ils intègrent à l'e-Diaspora Marocaine, alors en construction. Cette blogosphère est l'une des trois communautés\footnote{\RaggedOuter En théorie des graphes, une communauté de nœuds est un groupe fortement lié en son sein et faiblement lié avec le reste du réseau \citep{wasserman_social_1994, scott_social_2017}.} majeures du réseau de sites marocains tel que nous l'avons introduit en Section~\ref{sec:2_atlas}. \\

\noindent Le terme \textbf{blogosphère} est un néologisme forgé, au début des années 2000, pour désigner les communautés de blogs alors florissantes sur la toile. À cette époque, d'anciens concepts, comme logosphère ou graphosphère\footnote{\RaggedOuter Communautés humaines basées sur le langage oral d'une part, et l'écrit d'autre part.}, ne suffisent plus à traduire la nature hypertextuelle des liens établis entre ces sites. La connexion par liens de citation étant l'une des mécaniques de base des blogs et de leurs environnements. En effet, les auteurs en ligne s'agrègent en listes et communautés de blogs amis, qu'ils affichent de manière ostensiblement visibles sur leurs sites, comme marque consciente d'appartenance à un groupe délimité \citep{keren_blogosphere:_2006}. On n'entre pas dans une blogosphère, on s'y intègre. On cherche à la rejoindre en se connectant à ses membres qui, en retour, nous reconnaissent comme l'un des leurs.   

Type particulier de site Web, un blog est une plateforme de publication, en ligne, de billets ou d'articles courts. Les blogs sont alimentés en contenu de manière régulière et se rapprochent en cela du journal intime : chaque billet est daté et signé par un auteur (le créateur du blog ou une personne partageant les droits d'édition), l'ensemble des articles se lit ensuite du plus récent au plus ancien. Ces textes (incluant aussi images, liens, vidéos\ldots{}) peuvent être vus et commentés par d'autres blogueurs ou par de simples visiteurs. 

En cela, un blog est, avant tout, un médium destiné à une population d'ama\-teurs de la toile. Sa facilité de création et de maintenance a fortement joué en faveur de la diffusion de ce support d'écriture auprès d'un large public. Il était ainsi possible, en quelques clics, de créer via des plateformes dédiées et souvent gratuites\footnote{\RaggedOuter On peut citer Overblog, Blogger, Skyblog\ldots{}} son premier blog, et ce, sans être un professionnel de l'informatique. De fait, les blogs ont permis une forme de démocratisation de la prise de parole sur le Web, atteignant leur apogée\footnote{\RaggedOuter Les statistiques varient d'une source à l'autre, mais on estime généralement qu'entre 150 et 200 millions de blogs avaient été crées en 2011 \url{https://www.statista.com/statistics/278527/number-of-blogs-worldwide/}.} à la fin des années 2000. Les sujets de publication y sont divers et fonction du goût de chacun : on y parle de son quotidien, on écrit des billets d'humeur, voire des commentaires et des analyses politiques. Le tout partagé et diffusé au sein de sa ou de ses communautés d'appartenance.  

Sur ce point, de premières études ont rapidement montré le rôle grandissant des blogs quant à la diffusion et à la cristallisation d'opi\-nions politiques sur le Web, souvent en rupture avec les discours tenus par les médias classiques (télévision, radio\ldots{}). Par exemple, \citep{adamic_political_2005, adar_implicit_2004} caractérisent les divergences de pensées démocrates et républicaines en ligne, lors de la campagne présidentielle de 2004 aux États-Unis. En France, l'étude du collectif RTGI\footnote{\RaggedOuter \textit{Réseaux, Territoires et Géographie de l'Information}, collectif fondé à l'Université de Technologie de Compiègne (UTC) par F. Ghitalla (\url{https://web.archive.org/web/20060702021013/http://www.utc.fr:80/rtgi/}).} révèle la forte structuration et l'influence, sur la toile, des partisans du \textit{non} avant la tenue du référendum sur la Constitution Européenne de 2005 \citep{fouetillou_web_2008}. 

Passé le tournant des années 2010, les blogs perdent peu à peu de leur influence, \citep{weltevrede_where_2012} constate ainsi, en 2012, la lente disparition de la blogosphère néerlandaise. Cette perte de vitesse se fait au profit des plateformes de réseaux sociaux (Facebook, MySpace, Instagram\ldots{}) et de micro-blogging (Twitter, Tumblr, Sina Weibo\ldots{}). Ces dernières reprennent à leur compte, et améliorent, les mécaniques de publication introduites par les blogs, accélérant toujours la diffusion et le partage de contenu sur le Web.\\  

\begin{table*}
  \label{tab:blogs}
  \begin{tabular}{llll}
    \toprule
    préfixe d'URL&catégorie&langue principale&pays du blog\\
    \midrule
    7didane.org&intimiste&Français&USA\\
    9afia.blogspot.com&littérature&Français&USA\\
    adilski.blogspot.com&mixe&Anglais&USA\\ 
    al9adiya7amda.blogspot.com&social – politique&Français&USA\\
    anasalaoui.com&social – politique&Français&France\\ 
    badrryadi.centerblog.net&littérature&Français&France\\ 
    blogreda.blogspot.com&mixe&Français&USA\\ 
    boubouh.over-blog.com&social – politique&Français&France\\
    cabalamuse.wordpress.com&mixe&Anglais&USA\\ 
    eatbees.com/blog&intimiste&Anglais&USA\\ 
    emigrant.canalblog.com&intimiste&Français&France\\ 
    enmarruecos.blogspot.com&intimiste&Espagnol&USA\\ 
    fatima-salma.over-blog.com&cuisine&Français&France\\ 
    kalima.hautetfort.com&littérature&Français&France\\ 
    karlamassini.blogspot.com&littérature&Français&USA\\ 
    kennza.wordpress.com&mixe&Français&USA\\ 
    kingstoune.com&mixe&Français&France\\ 
    klamia.canalblog.com&mixe&Français&France\\ 
    kugelschreiber.canalblog.com&humeur&Français&France\\
    labelash.blogspot.com&mixe&Anglais&USA\\ 
    lailalalami.com&littérature&Anglais&USA\\ 
    lallamenana.free.fr&humeur&Français&France\\ 
    larbi.org&social – politique&Français&France\\ 
    lemythe.com&intimiste&Français&Maroc\\ 
    lesamismarocains.blogspot.com&humeur&Français&USA\\ 
    louladekhmissbatata.wordpress.com&mixe&Français&USA\\ 
    magiaenmarruecos.blogspot.com&intimiste&Espagnol&Espagne\\ 
    makhoudjit.blogspot.com&social – politique&Arabe&USA\\ 
    marocainsdalgerie.sosblog.com&social – politique&Français&Algérie\\ 
    marouki.joeuser.com&social – politique&Français&USA\\ 
    mlouizi.unblog.fr&littérature&Français&France\\ 
    mohblog.blogspot.com&littérature&Français&USA\\ 
    monagora.fr&humeur&Français&France\\ 
    murmures.net&intimiste&Français&USA\\ 
    myrtus.typepad.com&humeur&Anglais&USA\\ 
    nowbi.over-blog.com&intimiste&Français&France\\ 
    oef75.blogspot.com&littérature&Français&USA\\ 
    poliquonautemarocain.blogspot.com&social – politique&Français&USA\\ 
    purplemind-candysha.blogspot.com&intimiste&Français&USA\\ 
    saad.amrani.free.fr/blog&intimiste&Français&France\\ 
    sahara-libre.blogspot.com&social – politique&Français&USA\\ 
    sebti.fr&mixe&Français&France\\ 
    slimane.canalblog.com&humeur&Français&France\\ 
    sonofwords.blogspot.com&intimiste&Français&USA\\ 
    soumiaz.blogspot.com&intimiste&Anglais&USA\\ 
    supertimba.skynetblogs.be&intimiste&Français&Belgique\\ 
    taha.fr/blog&mixe&Français&France\\ 
  \bottomrule
  \end{tabular}
  \bigskip
  \caption{Liste des 47 blogs de la blogosphère marocaine tels que référencés dans l'Atlas e-Diasporas}
\end{table*}  

\begin{figure}%
  \includegraphics[width=\linewidth]{graphics/blogs-year}  
  \caption{Répartition des blogs de la blogosphère marocaine par année de création}
  \label{fig:blogs-years}
\end{figure}

\noindent En 2008, la \textbf{blogosphère marocaine}\footnote{\RaggedOuter Par abus de langage, nous appelons ici blogosphère marocaine le groupe de blogs de l'e-Diaspora marocaine. Il existe et a existé, bien évidement, d'autres blogosphères au Maroc, ce pays comptant près de 30 000 blogs en 2008 (\url{https://mg.co.za/article/2008-01-08-moroccos-blogosphere-takes-off}).} est une communauté fortement connectée de 47 sites Web crées ou maintenus par des citoyens marocains de l'étranger. Ce collectif est relativement jeune, la majorité des blogs ayant moins de trois années d'existante (Figure~\ref{fig:blogs-years}) au moment de sa cartographie pour l'Atlas.

La Table~\ref{tab:blogs} recense les blogs par préfixe d'URL, type de publication, langue et localisation. Mais situer géographiquement un site Web, quel qu'il soit, est toujours une étape sujette à discussion. Durant la création de l'Atlas, les chercheurs se sont servis, à la fois, d'indications présentes sur les sites eux même, et d'une méthode de localisation par adresse IP\footnote{\RaggedOuter La recherche par IP renvoie le pays d'hébergement du site (là où sont situés les serveurs), pas le pays de résidence de son auteur.}. Ainsi, beaucoup de blogs sont hébergés aux USA, du fait principalement des plateformes choisies pour créer ces sites. Mais la combinaison de cette information, associée à la langue principale de chaque site (Table~\ref{tab:blogs}), nous donne tout de même une idée générale de la répartition géographique du réseau : partagé entre la France et les États Unis.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-1}
  \caption{La blogosphère marocaine en 2008}
  \label{fig:blogs-1}
\end{figure*}

\noindent La Figure~\ref{fig:blogs-1} présente la blogosphère sous la forme d'un graphe, telle qu'elle fut cartographiée en 2008. La taille des nœuds y est fonction du degré de chaque blog. 

\begin{marginfigure}%
  \vspace*{2cm} 
  \includegraphics[width=\linewidth]{graphics/larbi-map}
  \vspace*{0.2cm}  
  \caption{\textit{larbi.org} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:larbi-map}
\end{marginfigure} 

Au cœur de la blogosphère, le blog politique \textit{larbi.org} fait autorité (Figure~\ref{fig:larbi-map}) : sa position est centrale et son degré est le plus élevé du réseau. En 2008, il est élu blog marocain et politique de l'année par un jury d'internautes et inaugure, de fait, un cycle de marques de reconnaissance des blogueurs entre eux. Cette forme de mise en avant des siens, pour promouvoir par extension l'ensemble du collectif, est monnaie courante dans la blogosphère\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Maroc\_Web\_Awards\#Maroc\_Blog\_Awards\_2008}}. On y cite volontiers les blogs qui nous semblent influents\footnote{\RaggedOuter L'auteur de \textit{manal.over-blog.com} se réfère explicitement à \textit{larbi.org} comme source d'inspiration (\url{http://manal.over-blog.com/article-517669.html}).}, ou  ceux que l'on souhaite promouvoir\footnote{\RaggedOuter Les lecteurs de \textit{larbi.org} citant \textit{makhoudjit.blogspot.com} parmi d'autres blogs crées par des femmes  (\url{https://web.archive.org/web/20130319234735/http://www.larbi.org/post/2006/03/05/183-hommage-aux-femmes}).}.

La présence de certains membres sur le Web est parfois antérieure à la formation de la blogosphère, \textit{7didane.org} par exemple en est déjà à son second site\footnote{\RaggedOuter \url{https://web.archive.org/web/20110810230023/http://7didane.blogspot.com/}}. Et si \textit{larbi.org} se propose, principalement, de commenter la vie politique marocaine à travers son regard de marocain émigré, les billets publiés sur les autres blogs sont divers et variés : allant de recettes de cuisines (\textit{fatima-salma.over-blog.com}), à des récits de vie quotidienne (\textit{murmures.net}), et en passant par des chroniques littéraires (\textit{lailalalami.com}).  Ainsi, la blogosphère se vie et se pense comme un environnement vibrant et dynamique où circulent des auteurs, des lecteurs et des visiteurs.

\subsection{\ldots{}à un collectif éteint}

\noindent En 2015,après une première enquête, \citep{khouzaimi_e-diasporas_2015} constate la disparition de 47 des 153 sites de l'e-Diaspora marocaine. La blogosphère est alors réduite à 17 membres actifs\footnote{\RaggedOuter Pour comprendre le décompte de J.~Khouzaimi, un blog actif est (selon sa méthodologie) un blog toujours en ligne.}. Par ailleurs, une série d'entretiens, enrichissant ce travail, nous apprend que les blogueurs toujours \textit{actifs} ne sont pas tous de jeunes étudiants comme le pensait en premier lieu l'auteure. Nombre d'entre eux sont des quarantenaires ou des cinquantenaires qui ont choisi, malgré les évolutions du Web, de maintenir ouverts leurs sites sur la toile. 

Mais une frontière entre étudiants de 2015 et anciens blogueurs se dessine : chez les étudiants, l'attachement en ligne à un passé vécu au Maroc se traduit au mieux par l'appartenance à certains groupes communautaires sur Facebook et Whatsapp\footnote{\RaggedOuter Tout comme Telegram, l'application de messagerie Whatsapp permet de créer des salon de discussions virtuels à plusieurs, voir \url{https://frama.link/JnjBqw8u}}, plus que par la consultation des anciens blogs d'émigrés, dont ils ne connaissent pas toujours l'existence d'ailleurs. \\

\noindent \textbf{Début 2018}, nous choisissons, à notre tour, de revenir en détail sur le cas des blogs de l'e-Diaspora marocaine. Pour ce faire, nous visitons chacune des 47 URL associées et classons les sites selon trois catégories :

\begin{enumerate}[leftmargin=*]  
\item vivant : le blog est en ligne et a été mis à jour au moins une fois au cours de l'année passée (courant 2017 donc)
\item abandonné : le blog est en ligne mais n'a pas été mis à jour récemment 
\item mort : le blog n'est plus en ligne ou a été victime de cybersquatting (le blog n'est plus celui qu'il a été au moment de sa cartographie, il a été volé ou squatté)
\end{enumerate}

\noindent La Figure~\ref{fig:blogs-2} présente l'état\footnote{\RaggedOuter La position des nœuds est conservée par rapport à la Figure~\ref{fig:blogs-1}} de la blogosphère, telle que nous la trouvons en 2018. Nous ne recensons plus que 5 blogs vivants (Figure~\ref{fig:blogs-2}, (a)), 23 ont été abandonnés (Figure~\ref{fig:blogs-2}, (b)) et les 19 autres sont morts. Parmi les blogs toujours en vie, deux sont, en fait, des transformations de blogs cartographiés en 2008 mais déplacés depuis par leurs auteurs : \textit{louladekhmissbatata.wordpress.com} devient \textit{louladekhmissbatataprise2.com} en 2009 et \textit{cabalamuse.wordpress.com} devient \textit{amoroccandrifter.wordpress.com} en 2012. Le collectif en ligne de 2008 s'est éteint.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-2}
  \caption{La blogosphère en 2018, (a) blogs vivants, (b) blogs vivants et abandonnés, la position est conservée}
  \label{fig:blogs-2}
\end{figure*}   

\subsection{Définir l'espace d'exploration}

\noindent Partant de cet état de fait, nous pouvons, en rassemblant les informations collectées, commencer a formuler quelques hypothèses. Nous savons qu'en 2015 certains étudiants marocains préféraient les groupes Facebook aux blogs d'émigrés pour maintenir le lien avec leur vie passée au Maroc \citep{khouzaimi_e-diasporas_2015}. Ces groupes Facebook étaient, par ailleurs, déjà contemporains de la blogosphère au moment de sa cartographie. En effet, S. Marchandise a réalisé, dans le cadre de l'Atlas, une e-Diaspora \citep{marchandise_facebook_2014} entièrement centrée sur la présence\footnote{\RaggedOuter \url{http://www.e-diasporas.fr/wp/marchandise.html}} des étudiants émigrés marocains au sein de groupes Facebook. De plus, les mécanismes des réseaux sociaux (Facebook, Twitter\ldots{}) ne sont pas si éloignés que ça des fonctionnalités démocratisées par les blogs en leur temps \citep{kwak_what_2010} : ils en reprennent certaines fonctionnalités (publication, création de liens, création de communautés\ldots{}), en améliorent d'autres (vitesse de diffusion, intégration mobile\ldots{}) et introduisent leurs propres règles (partage, retweet, flux d'informations et timeline\ldots{}).\\

\noindent Arrivés à ce niveau de notre exploration, nous nommons maintenant \textbf{auteur} la personne ou l'ensemble de personnes ayant créé ou maintenu l'un des 47 blogs de la blogosphère marocaine. De même, nous nommons \textbf{lecteur} une personne qui visite, réagit ou laisse un commentaire sur l'un de ces sites.

Notre tâche d'exploration a ici pour but de comprendre, autant que faire ce pourra, le devenir d'un \textbf{collectif en ligne éteint}, c'est-à-dire une communauté pour laquelle peu ou plus aucune trace ne subsiste encore sur le Web vivant. Deux grandes hypothèses peuvent être formulées : \textbf{1)}~les blogs ont purement et simplement disparu de la surface du Web, les auteurs qui les ont créés n'ont pas voulu ou pu donner suite à cette présence sur la toile \textbf{2)} les blogs se sont mués en une autre entité, migrant d'un territoire du Web (la blogosphère) à un autre (ici, les plateformes de réseaux sociaux). Nous chercherons donc, dans un premier temps, à identifier les indices archivés de cette possible mutation. \\

\noindent L'espace d'exploration est donc le suivant : un nombre connu et limité de sites Web observés pendant 10 ans, de 2008 à 2018. Grâce aux archives de l'atlas e-Diasporas, nous disposons de 4 années de collectes (2010-2014), que nous allons étendre à 6 années grâce aux dates d'éditions des fragments Web (2008-2014), la période 2014-2018 sera, elle, couverte par les collectages d'Internet Archive. 

Pour commencer, nous partons de la liste des 47 sites de la blogosphère que nous fragmentons (Section~\ref{sec:5_scraping}) et envoyons dans notre moteur d'exploration (Section~\ref{sec:3_constituer}). L'idée est ici de réaliser une même requête plein texte sur deux champs différents de nos fragments Web. Cette requête, nous la construisons à partir de mots clés que nous pensons être en rapport avec les réseaux sociaux, tels que :\\

\begin{fullwidth}
$\small\texttt{facebook, twitter, instagram, pinterest, youtube, flicker, medium, myspace, google+, googleplus, tumblr,}$\\
$\small\texttt{share, like, retweet, tweet, partager, aimer, social\ldots{}}$\\
\end{fullwidth}

\noindent Ces mots clés sont, ensuite, testés par rapport au contenu des champs \textit{frag\_text} et \textit{frag\_label} de chaque fragments. Les requêtes à \textit{frag\_text} permettent de détecter d'éventuelles références aux réseaux sociaux dans le corps d'un texte : par exemple, un blogueur parlant de Twitter dans l'un de ses billets. Les requêtes à \textit{frag\_label} sont supposées capturer et retourner les nœuds HTML dont les labels\footnote{\RaggedOuter Pour rappel, le label d'un nœud HTML est la concaténation de son tag, de son id et de sa classe} matchent l'un des mots clés : par exemple, un bouton \textit{partager sur facebook} présent sur une page Web. Nous cherchons donc, à la fois, du contenu textuel et des éléments de mise en forme.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-fragments-1}
  \caption{Exemples de fragments Web associés à divers réseaux sociaux}
  \label{fig:blogs-fragments-1}
\end{figure*} 

\subsection{Migrer d'un territoire du Web à un autre}

\noindent Trois types de fragments Web répondent à nos requêtes : \textbf{1)} des fragments de textes extraits d'articles ou de billets \textbf{2)} des boutons et \textit{widgets} like, share, follow me\ldots{} près construits et mis à disposition des blogueurs par les réseaux sociaux \textbf{3)} un mélange de nœuds HTML non conventionnels, confectionnés par les auteurs eux même, comme système de redirection Twitter ou Facebook. 

Le premier type sera examiné à la fin de cette section. En effet, nous préférons d'abord présenter les deux dernières sortes de fragments Web qui témoignent d'un age du Web balbutiant (2008-2010), où les auteurs de blogs devaient eux même \textit{bricoler}, avec un peu de HTML et de CSS, des connexions vers leurs nouveaux comptes sociaux. Avec le temps, cette pratique s'est faite oublier, supplantée par l'arrivée d'éléments hypertextes standardisés et prêts à l'emploi. La Figure~\ref{fig:blogs-fragments-1} donne à voir quelques exemples de ces fragments Web avec, en rouge, les parties ayant matchées nos requêtes. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/eatbees-map}
  \vspace*{0.2cm}  
  \caption{\textit{eatbess.com} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:eatbees-map}
\end{marginfigure} 

Mais en y regardant de plus prêt, ces fragments ont d'autres informations à nous offrir : il est possible de trouver, au cœur du HTML (Figure~\ref{fig:blogs-fragments-1}, bleu), des noms de comptes sociaux liés aux blogs. En effet, lorsque l'on souhaite s'inscrire sur une plateforme de réseaux sociaux, il faut d'abord et avant tout se créer un avatar : le \textit{@user} de Twitter ou le \textit{pseudo} de Facebook par exemple. Ces avatars deviennent alors l'incarnation de notre identité sur les réseaux. Ce faisant, nous constituons rapidement une liste d'association entre blogs passés et noms de comptes sociaux. À la fin de cette étape, nous identifions 20 blogs, parmi nos 47 de départ, liés à un ou plusieurs réseaux sociaux.

Afin d'élargir nos résultats, nous faisons ici l'hypothèse que les avatars, pseudos et autres noms d'utilisateurs peuvent être réutilisés par un même auteur, d'une plateforme à l'autre, moyennant une légère modification. À titre d'exemple, le blogueur \textit{eatbees.com} (Figure~\ref{fig:eatbees-map}) se nomme \textit{@eatbees} sur Twitter et \textit{eatbees} sur Medium. Aussi, nous normalisons les 20 avatars déjà extraits avec un petite opération de stemming\footnote{\RaggedOuter Les majuscules deviennent minuscules et l'on ne conserve que la racine des pseudonymes (l'avatar moins les deux derniers caractères)}. L'objectif de cette nouvelle phase est maintenant d'explorer le Web vivant à la recherche de comptes sociaux (Youtube, Flickr, Medium\ldots{}) liés, de prêt ou de loin, à l'un de ces 20 pseudonymes.   

Cette tâche ne peut malheureusement pas être automatisée. Si la recherche par fragment Web, dans notre moteur, nous a permis d'iden\-tifier rapidement quelques indices, c'est maintenant au chercheur d'en\-trer en scène. La fouille (via des moteurs de recherche : Google, Bing\ldots{}) et la vérification des informations tirées du Web vivant se font à la main. Ainsi, nous récoltons un total de 33 comptes sociaux actifs différents, liés par leurs avatars aux 20 blogs ayant matché les requêtes par mots clés initiales. 

La Figure~\ref{fig:blogs-social} présente la répartition de ces 33 comptes, entre anciens blogs (gauche) et nouveaux réseaux sociaux (droite). Twitter et Facebook dominent cette liste, ils agrègent à eux seuls 23 comptes. L'usage de Youtube, Pinterest, etc. reste plus confidentiel. Bien sûr, ce classement ne peut  se prévaloir d'une quelconque exhaustivité, par construction cela lui est impossible. En effet, Si l'un des auteurs des blogs a préféré utiliser un pseudonyme entièrement nouveau, sans en faire mention dans les pages de son ancien site, alors nous ne sommes pas ici en mesure de le retrouver.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-social}
  \caption{Liste des blogs de 2008 liés à des réseaux sociaux en 2018}
  \label{fig:blogs-social}
\end{figure*} 

\noindent Si l'on s'en tient aux seuls blogs subsistants (Figure~\ref{fig:blogs-2}), la blogosphère est bel et bien un collectif éteint. Crées entre 2005 et 2008, la quasi totalité de ces sites ont progressivement été fermés ou laissé à l'abandon par leurs auteurs. La blogosphère en tant qu'espace de communication n'a pas réussi à durer, du fait même, de ceux qui la constituaient. Mais en lieu et place d'une disparition, c'est en fait à une transformation que nous avons ici affaire. Les blogs se sont mués en une multitudes de comptes sur les réseaux sociaux et au cours de cette migration, les anciens blogueurs ont choisi de conserver leurs identités en ligne. En gardant leurs avatars, ils leur a été plus facile de se retrouver et de se reconnecter après coup.

En effet, en procédant à un rapide scraping des pages Facebook et Twitter, nous pouvons récolter l'ensemble des liens d'amitié et d'intérêt\footnote{\RaggedOuter Lien entre \textit{fellowers} sur Twitter} qui sont aujourd'hui tissés entre ces différents comptes. La Figure~\ref{fig:blogs-3} se veut, ainsi, une vue de la blogosphère, après sa mutation et telle que nous la redécouvrons en 2018. Nous plaçons les comptes sociaux là où se situaient leurs anciens blogs respectifs (Figure~\ref{fig:blogs-2}) et nous traçons entre eux les nouveaux liens de citations (liens rouges).

\newpage

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-3}
  \caption{La blogosphère en 2018, les emplacements des blogs sont conservés}
  \label{fig:blogs-3}
\end{figure*} 

\noindent Sur la nouvelle blogosphère, l'expression en ligne se fragmente et se spécialise par type de réseau et de médium. Certains, comme \textit{7didane.org}, choisissent d'avoir un compte Facebook en parallèle d'un compte Twitter. D'autres utilisent Youtube ou Flickr pour publier des photos ou des vidéos comme \textit{larbi.org}. On peut également observer l'utilisation conjointe de Twitter et de Medium\footnote{\RaggedOuter Plateforme de partage de billets se voulant longs et argumentés} (ou d'un blog Médiapart) sur lequel l'auteur va choisir d'écrire un texte réfléchis et structurés avant de le promouvoir à sa communauté via Twitter, comme \textit{eatbees.com}. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/density}
  \vspace*{0.2cm}  
  \caption{Densité d'un graphe}
  \label{fig:density}
\end{marginfigure}

Mais, la migration vers les réseaux sociaux n'est pas, pour autant, synonyme d'éclatement ou d'isolation des anciens membres de la blogosphère. Prenons, ainsi, le cas des 16 auteurs ayant désormais un compte Twitter. Il est possible de comparer la densité du sous graphe qu'ils formaient en 2008, avec celle de leur graphe d'intérêt, tel qu'il se trouve sur Twitter en 2018. 

En théorie des graphes, un graphe est dit \textbf{dense} si le nombre de ses liens est proche du nombre de liens maximum possibles. Si les nœuds ne sont pas du tout connectés entre eux, alors la densité vaudra $0$, mais s'ils sont tous liés celle-ci vaudra $1$ (Figure~\ref{fig:density}). Entre 2008 et 2018, la densité du sous graphe des utilisateurs de Twitter, anciennement blogueurs, passe  ainsi$0.16$ à $0.24$. L'aspect \textit{communauté} de l'ancienne blogosphère est conservée et même renforcée par le passage sur Twitter.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/lailalalami-map}
  \vspace*{0.2cm}  
  \caption{\textit{lailalalami.com} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:lailalalami-map}
\end{marginfigure} 

\subsection{Communauté de lecteurs et identité}

\noindent Sur la Figure~\ref{fig:blogs-3}, la taille de chaque nœud social est fonction de l'étendue de sa communauté de followers (pour Twitter) ou d'amis (pour Facebook). À titre d'exemple, \textit{7didane.org} est suivi par 43,512 sur Twitter et a 141,947 amis sur Facebook. De son côté, \textit{lailalalalmi.com} (Figure~\ref{fig:lailalalami-map}) dépasse les 35,000 followers sur Twitter.

À l'ère des réseaux sociaux, l'influence d'un auteur est souvent liée au nombre de lecteurs ou de visiteurs auxquels il est capable de s'adresser. La communauté devient une audience. De fait, la dynamique interne à la blogosphère évolues\footnote{\RaggedOuter Basé sur un crawl de Twitter de Janvier 2018} : \textit{larbi.org} n'est plus hégémonique, \textit{7didane.org} et \textit{lailalalalmi.com} le dépassent désormais.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-community}
  \caption{Répartition géographique des followers Twitter (a) et des amis Facebook (b)}
  \label{fig:blogs-community}
\end{figure*} 

\noindent L'origine des followers Twitter et des amis Facebook peut nous renseigner sur le caractère diasporique de la communauté des lecteurs et des visiteurs de 2018. D'où lisent celles et ceux qui suivent les anciens blogueurs sur les réseaux sociaux ?

\noindent Pour répondre à cette question nous suivons une double approche. La première est adaptée à Facebook, la seconde à Twitter : \textbf{1)} nous utilisons l'application Netvizz qui associe à chaque personne, ayant aimé une page facebook donnée, une situation géographique\footnote{\RaggedOuter Cette information est issue des méta-données renseignées lors de l'inscription à Facebook ou de la modification de sa page personnelle (\url{https://apps.facebook.com/netvizz/})} \textbf{2)} nous scrapons les pages de l'ensemble des followers des comptes Twitter. En effet, le champs \textit{location}\footnote{\RaggedOuter \url{https://help.twitter.com/fr/using-twitter/tweet-location}} de ces pages peut, s'il est renseigné, renfermer une information géolocalisée, dont nous faisons ici l'hypothèse qu'elle correspond au lieu, depuis lequel, une personne utilise Twitter. Nous croisons, ensuite, la valeur de ce champ avec la base de données d'entités géographiques Geonames\footnote{\RaggedOuter \url{http://www.geonames.org/}} afin de désambiguïser l'information extraite. 

Ces deux méthodes ne sont pas exhaustives, mais elles nous donnent à voir une coloration et une tendance générale. Nous essayons, néanmoins, de limiter au maximum les faux positifs dans nos résultats. Ainsi, la Figure~\ref{fig:blogs-community} présente pour chaque compte, la répartition géographique (si elle est connue) de ses followers Twitter ou amis Facebook. En pratique, \textit{7didane.org} est principalement suivi par des personnes situées au Maroc ($82\%$) mais aussi par quelques Français ($2\%$) et des Égyptiens ($2\%$). De son coté, \textit{lailalalami.com} continue de s'adresser à des Marocains ($24\%$), à des Américains ($15\%$) et à des Pakistanais ($8\%$). Au moins 19 pays\footnote{\RaggedOuter Algérie, Maroc, Égypte, Tunisie, Libye, France, Chine, Espagne, Pays-Bas, USA, Pakistan, Indonésie, Bangladesh, Nigeria, Inde, Belgique, Grande Bretagne, Canada et Corée du Sud} sont ainsi représentés, témoignant du caractère géographiquement dispersé de cette communauté de lecteurs. \\

\noindent Comme nous l'expliquions plus tôt, les auteurs ont su conserver leur identité en ligne en réutilisant les même pseudonymes, d'une plateforme à l'autre, et ce, depuis le temps de leurs premiers blogs. Nous faisons maintenant l'hypothèse de retrouver le même comportement chez leurs lecteurs. En effet, un blog est un médium tourné vers l'intéressement d'un public donné. Aussi, il nous semble raisonnable d'avancer que lorsqu'un lien fort se crée entre un auteur et ses lecteurs, ces derniers peuvent chercher à conserver à tous prix cette connexion. Nous supposons donc que les lecteurs ont réutilisé, eux aussi, leurs anciens avatars sur Twitter, pour suivre les auteurs qu'ils supportaient au temps des blogs.

Pour tester cette hypothèse, nous nous focalisons sur le site \textit{larbi.org} et sur le lien qu'il entretenait avec les personnes commentant ses articles, lorsqu'il faisait encore autorité (Figure~\ref{fig:blogs-1}). Nous définissons alors un modèle de requête capable de nous retourner l'ensemble de ces commentaires archivés. Il s'agit ainsi de cibler des fragments Web ayant la forme suivante (champ \textit{frag\_type}) : un nom d'auteur, une date et un contenu textuel publié dessous l'article principale d'une page. Ce faisant, nous obtenons 4177 résultats dont ne conservons que les noms d'utilisateurs.

Nous croisons cette liste à celle des followers actuels de \textit{larbir.org} sur Twitter\footnote{\RaggedOuter \url{https://twitter.com/larbi_org/followers}} via une égalité stricte pour ne pas multiplier les faux positifs. Au final, nous obtenons une borne inférieure de 647 lecteurs ayant, à priori, choisi de suivre \textit{larbi.org} sur Twitter, soit prêt de $15\%$ de son audience passée. Rapportés à leur nombre de commentaires publiés, ces lecteurs représentent au final $26\%$ des réactions postées sur le site. Les auteurs des blogs ont été accompagnés dans leur migration vers les réseaux sociaux. En conservant leur identité en ligne, ils ont emporté, à leur suite, la part la plus fidèle de leurs lecteurs et de leurs communautés.

\subsection{Le Printemps Arabe comme un moment clé ?}

\noindent Avant de clôturer leurs blogs, seuls 6 auteurs ont déposé sur leur site un message d'adieu, ou d'explication\footnote{\RaggedOuter Pour \textit{7didane.org} \url{https://web.archive.org/web/20120415100250/http://www.7didane.org:80/ 
}, pour \textit{larbi.org} \url{https://web.archive.org/web/20140119233126/http://www.larbi.org/post/2013/12/A-nos-apprentis-dictateurs} \url{-redacteurs-du-Code-du-Numerique}}. Passé un certain temps, les blogs ne sont plus mis à jours et finissent alors par disparaitre sans crier gare. Le blogueur \textit{7didane.org} est de ceux qui ont souhaité indiquer à leur communauté qu'il partait. En avril 2012 la front page de son blog vire au noir (Figure~\ref{fig:blogs-adieu}, a), une adresse mail est laissée pour ceux qui souhaiteraient garder le contact. Si \textit{7didane.org} n'a pas donné plus d'explication, \textit{larbi.org}, au contraire, argumente sa volonté de clôturer son blog par dernier article (Figure~\ref{fig:blogs-adieu}, b).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-adieu}
  \caption{Annonce de la fermeture de \textit{7didane.org} (a) et article précédant la clôture de \textit{larbi.org} (b)}
  \label{fig:blogs-adieu}
\end{figure*} 

\noindent Fin 2013, il y met en garde ses lecteurs contre l'application à venir, au Maroc, du \textit{projet de loi formant Code numérique}. Ce texte, selon lui, porte une atteinte grave au droit de citation hypertexte et, de manière plus générale, vise à limiter la liberté d'expression sur le Web\footnote{\RaggedOuter Voir \url{https://www.esi.ac.ma/Dossiers/20131217031227.pdf}}. Quelques semaines après, sans rien ajouter de plus, l'auteur décide de fermer son blog. Il ne s'exprime aujourd'hui plus que par son compte Twitter\footnote{\RaggedOuter \url{https://twitter.com/Larbi_org}}. Ce dernier billet témoigne d'un fort attachement aux libertés fondamentales et d'une crainte de voir le Web, comme espace d'expression, être de plus en plus censuré. Mais le contenu de ce texte, peut être désormais mis au regard d'un autre article. 

En effet, nous n'avons pas encore parlé des fragments de billets ayant, plus tôt, matché notre première liste de mots clés. Parmi ces résultats, les premiers fragments Web archivés faisant mention de Twitter chez \textit{larbi.org} et \textit{7didane.org} attirent particulièrement notre attention, la Figure~\ref{fig:blogs-fragments-2} transcrit ces morceaux de textes. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/blogs-fragments-2}
  \caption{Premiers fragments Web archivés faisant mention de Twitter chez \textit{larbi.org} \textit{7didane.org}}
  \label{fig:blogs-fragments-2}
\end{figure*}

\noindent En 2009, le blogueur \textit{7didane.org} dit suivre\footnote{\RaggedOuter \url{https://web.archive.org/web/20090627012354/http://www.7didane.org:80/2009/06/16/1453/
}}, via Twitter, le déroulé des manifestations\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Soulèvement\_postélectoral\_de\_2009\_en\_Iran}} qui secouent alors l'Iran. Cette année là, la contestation des élections du mois de Juin provoque de nombreux mouvements de protestations à Téhéran et dans le reste du pays. Mais surtout, les manifestations trouvent une résonance inédite sur le Web. L'information étant contrôlée par les médias gouvernementaux, les ci\-toyens s'emparent de Twitter pour diffuser leurs témoignages, leurs photos et leurs vidéos. Cette vague de manifestations porte encore aujourd'hui le nom de \textit{Révolution Twitter}. 

Chez \textit{larbi.org}, Twitter fait pour la première fois son apparition dans un billet\footnote{\RaggedOuter \url{https://web.archive.org/web/20110319191709/http://www.larbi.org:80/post/2011/02/Morocco-Feb20-Maroc-20Fev
}}, au moment où le Printemps Arabe\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Printemps_arabe}} commence à se pro\-pager au Maroc, début 2011. Dans cet article \textit{larbi.org} propose de suivre puis de revivre, via un hashtag dédié (Figure~\ref{fig:blogs-fragments-2}, bleu), la manifestation marocaine du 20 Février 2011.

Pour ces deux auteurs, Twitter n'a pas véritablement été découvert dans le contexte très précis de ces deux moments révolutionnaires, \textit{larbi.org} et \textit{7didane.org} (Figure~\ref{fig:7didane-map}) ayant tous deux ouverts leurs comptes Twitter en 2008. Mais, les manifestations Iraniennes et le Printemps Arabe ont pu jouer un rôle de révélateur, quant à un nouvel usage possible de Twitter, chez des personnes sensibles aux questions de libertés et de démocraties. À leurs yeux, Twitter est peut être, à ce moment là, devenu un nouvel espace d'expression libre sur la toile. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/7didane-map}
  \vspace*{0.2cm}  
  \caption{\textit{7didane.org} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:7didane-map}
\end{marginfigure} 

Nous pouvons ici émettre l'hypothèse que le Printemps Arabe, dans le cas particulier du Maroc, s'est inscrit dans un faisceau complexe d'événements qui ont, à un moment donné, influencé le devenir de la blogosphère, voire du reste de l'e-Diaspora marocaine. Bien sur, à l'échelle de nos archives, ces deux textes sont des détails statistiques, mais ils sont suffisamment intéressants pour nous mettre maintenant sur la piste de la manifestation du 20 février 2011 et de ce hashtag \textit{\#20Fev}. Cet événement a-il-pu avoir un impacte visible sur d'autres espaces de notre corpus ?

\section{Un soulèvement en ligne éphémère}
\label{sec:6_printemps}

\noindent En Section~\ref{sec:retour_au_moteur}, partant d'une démonstration technique, nous avions commencé à entrevoir le contenu des archives du forum \textit{yabiladi.com}. Notre système de détection d'événements nous révélait un pic de conversations portant sur la démission de l'ancien dirigeant tunisien Z. Ben Ali, comme un trait d'union entre un fait du Web et un bouleversement du réel. En effet, cette démission marque l'un des moments forts de la vague de contestations populaires qui a déferlé, fin 2010, sur l'ensemble du monde Arabe.

Dans ce manuscrit, nous tenons à insister sur la nécessité d'identifier des points d'entrée et de trouver des indices pour orienter nos explorations des archives Web. Le corpus marocain à lui seul étant tellement vaste, qu'il convient selon nous de s'attacher d'abord à l'étude de moments singuliers, bien définis et cadrés, sur lesquels nous sommes capable, à notre échelle et avec nos outils, de porter un regard autant quantitatif que qualitatif. 

En cela, la manifestation du 20 février 2011 révélée dans la section précédente, nous semble être un bon fil conducteur, pour tenter de comprendre la manière dont les utilisateurs de \textit{yabiladi.com} ont pu réagir au Printemps Arabe. Peut-on remonter les traces archivées d'un potentiel soulèvement du forum en amont ou en aval de cette manifestation ? ses membres se sont-ils organisés d'une quelconque manière, ou ont-ils regardé passer les protestassions sans y prendre part ? 

\subsection{Yabiladi.com : porte d'entrée sur la diaspora}

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/yabiladi-map}
  \vspace*{0.2cm}  
  \caption{\textit{yabiladi.com} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:yabiladi-map}
\end{marginfigure} 

\noindent Le site Web \textit{yabiladi.com} se présente donc comme le candidat idéal pour cette nouvelle exploration de notre corpus d'archives.  Son rôle est central dans l'organisation de l'e-Diaspora marocaine, puisqu'il fait le lien entre les trois grands clusters du réseau. C'est un hub, un pont entre des constellations de sites qui ne se parlent pas (Figure~\ref{fig:yabiladi-map}).

Site hybride, mélangeant forum de discussion en ligne, actualités, petites annonces et rencontres amoureuses, \textit{yabiladi.com} fait figure de dinosaure à l'échelle du Web. Crée à la toute fin de l'année 2001, par un jeune ingénieur marocain travaillant en France\footnote{\RaggedOuter voir \url{http://lavieeco.com/news/portraits/mohamed-ezzouak-le-} \url{mre-qui-a-lance-
yabiladi-com-6596.html}}, le site s'inscrit dans la longue tradition des portails diasporiques en ligne. Dans son analyse de l'e-Diaspora Indienne\footnote{\RaggedOuter \url{http://e-diasporas.fr/wp/leclerc.html}}, E. Leclerc décrit avec précision le rôle de ces vastes sites protéiformes. La génèse de \textit{yabiladi.com} est similaire à celle de ces sites indiens apparus au début des années 2000 sous l'impulsion d'une diaspora influencée par le succès de certains de ses membres, nouveaux entrepreneurs de l'informatique faisant carrière aux USA \citep{leclerc_cyberespace_2012}. 

Un portail Web peut se voir comme une porte d'entrée ou un relai focalisé sur une thématique, une zone géographique ou régionale, une ethnie, une caste, un culte\ldots{} et incarnant un double rôle : celui de l'intermédiaire entre une masse d'internautes et des grappes de sites inféodés à son autorité et celui du focalisateur d'une ou plusieurs communautés dont il se considère comme le représentant. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/portail}
  \caption{Dynamique de création d'un portail Web autour d'une communauté de sites}
  \label{fig:portail}
\end{figure*}

\noindent Un portail Web est donc dans la recherche constante d'une position d'autorité. Il commence par se mettre au service de sites existants en leur servant d'annuaire, en les pointant (Figure~\ref{fig:portail}, a). Puis, une fois que les internautes l'ont identifié comme porte d'entrée unifiée, le portail peut prospérer sur le Web, fort du monopole acquis et bascule alors dans la seconde phase de son existence : la conservation de sa position et de son audience (Figure~\ref{fig:portail}, b). Tout l'enjeu est alors de ne plus être seulement un site par lequel on passe, mais un espace où l'on reste. Pour ce faire, les portails s'adaptent aux exigences des internautes et proposent de nouveaux services (forum, petites annonces, radio, tv\ldots{}), voire deviennent éditeur ou hébergeur de contenu. Un portail diasporique peut ainsi chercher à créer, en son sein, un véritable environnement dédié aux rencontres et aux discutions entre émigrés, un lieu de partage et d'entre-aide.  

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/timeline}
  \caption{Timeline des évolutions successives de \textit{yabiladi.com}}
  \label{fig:timeline}
\end{figure*}

\noindent Mais le lien qui nait entre l'internaute émigré et son portail Web devenu espace, ne suffit pas à comprendre la longévité de ces sites. Eux qui, contrairement aux blogs, ont su résister et s'adapter à l'arrivée des réseaux sociaux. Pour continuer à être la vitrine culturelle de sa communauté, le portail doit y insuffler du dynamisme en testant toutes sortes de nouvelles technologie créatrices de lien. De fait, un portail Web, peut être vu comme un parfait témoin de l'évolution du Web et de ses outils. En cela, la genèse de \textit{yabiladi.com} est tout à fait exemplaire. En interrogeant nos archives et en les associant aux collectages d'Internet Archive, nous créons la timeline de la Figure~\ref{fig:timeline} qui présente les transformations successives de \textit{yabiladi.com} au cours de son histoire : 

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/catego-verti}
  \caption{Évolution des catégories du forum de \textit{yabiladi.com}, par date d'apparition}
  \label{fig:categories}
\end{figure*}


Yabiladi signifie littéralement \textit{Oh mon pays} (Ya biladi). Mis en ligne fin 2001, le portail inaugure, en 2002, une toute nouvelle section, un forum\footnote{\RaggedOuter \url{https://web.archive.org/web/20020615201721/http://www.yabiladi.com:80/forum/list.php?f=4}} contenant quatre espaces de discussions \textit{Général}, \textit{Femmes marocaines}, \textit{Investir au Maroc} et \textit{La corruption}. Il se présente alors comme le \og\textit{Le premier portail destiné aux Marocains Résidant à l'Etranger (RME)!}\fg{} mettant en avant un annuaire complet et éditorialisé (classement par catégories) d'adresses Web marocaines\footnote{\RaggedOuter \url{https://web.archive.org/web/20020531015840/http://www.yabiladi.com:80/}}, ainsi que quelque rubriques mélangeant informations et divertissements. 

Suivre le fil des évolutions de \textit{yabiladi.com}, c'est remonter l'histoire du Web dans son intégralité. Avant 2005, le site est maintenu par sa propre équipe de développeurs PHP, puis dès 2006, un premier CMS est utilisé pour moderniser le forum\footnote{\RaggedOuter \url{https://web.archive.org/web/20070406192841/http://www.phorum.org:80}} et des éléments dynamiques de Javascript sont progressivement intégrés à partir de 2010. Les flux RSS\footnote{\RaggedOuter \url{https://web.archive.org/web/20051217073725/http://www.yabiladi.com:80/rubrik/rss.php}} sont ajoutés dès 2005 mais disparaissent 5 années plus tard; le search hiérarchique (à la Yahoo) est lui remplacé en 2007 par un search plein texte (à la Google). Et il faut attendre 2012 pour voir une redirection se faire vers les comptes Twitter et Facebook de \textit{yabiladi.com}, puis patienter jusqu'en 2014 pour pouvoir partager du contenu sur les réseaux sociaux. Des technologies maisons sont testées puis abandonnées au profit de solutions extérieurs : un service de chat \textit{Yabuzz}, un player radio intégré\footnote{\RaggedOuter \url{https://web.archive.org/web/20060717190039/http://www.yabiladi.com:80/radio/download.php}} et une plateforme de partage vidéo \textit{Babrio}\footnote{\RaggedOuter \url{http://babrio.com/}}.

À plusieurs reprises, le portail tente de proposer du contenu éditorialisé en complément de ses seuls articles Web. Une Web radio, une Web télé et une Web série\footnote{\RaggedOuter \url{https://web.archive.org/web/20081220014828/http://www.yabiladi.com:80/webserie/}, \url{https://web.archive.org/web/20101202113409/http://yabiladi.com/tv/}, \url{https://web.archive.org/web/20050411011853/http://www.yabiladi.com:80/radio/}} sont lancées. Deux magazines sont publiés~: le premier, un journal satirique et politique \textit{La Gachette du Maroc}\footnote{\RaggedOuter \url{https://web.archive.org/web/20050831073003/http://www.yabiladi.com:80/magazine/}} ne durera que 2 ans; le second \textit{Yabiladi Mag} plus orienté business et tourisme\footnote{\RaggedOuter \url{https://web.archive.org/web/20101118010916/http://www.yabiladi.com:80/mag}} sera édité pendant 4 années. 

Espace de rencontre en ligne\footnote{\RaggedOuter \url{https://web.archive.org/web/20030626013657/http://www.yabiladi.com:80/rencontres/}}, \textit{yabliadi.com} propose à ses membres de se croiser en dehors du site, via des cafés débats\footnote{\RaggedOuter \url{https://web.archive.org/web/20060209041225/http://www.yabiladi.com:80/cafe-debat.php}}. Mais ces moments d'échanges ne durent pas et les espaces d'analyses et d'opinions\footnote{\RaggedOuter \url{https://web.archive.org/web/20050711003647/http://www.yabiladi.com:80/sommaire-debat.html}}, présents depuis les débuts du portail, sont peu à peu fermés, remplacés par des sections plus généralistes : \textit{Divertissement}, \textit{Vie pratique}, \textit{Famille}\ldots{} 

Le site évolue et se transforme, 6 changements visuels et structurels majeurs sont opérés successivement (Figure~\ref{fig:timeline}, \textit{nouveau CSS}), impactant notamment le forum. Si l'organisation locale de cette section reste la même (les messages postés y sont triés par date de publication et associés à un sujet unique, formant ce que l'on appelle des \textit{threads}\footnote{\RaggedOuter Suite de messages inféodés à un même sujet de discussion}), sa structure générale, quant à elle, est régulièrement bouleversée. Les catégories de discussions qui prédéfinissent l'ordre et l'agencement des threads, changent, disparaissent ou sont réintégrées au grès des nombreuses mutations du site. 

En 16 années d'existence, 81 catégories successives viennent, une à une, donner une nouvelle orientation au forum (Figure~\ref{fig:categories}). Des thématiques entières apparaissent (\textit{Grossesse, Maternité, Vie de Famille\ldots{}}) ou perdent en influence (\textit{Opportunité au Maroc, Forum étudiant, Solidarité \& associations\ldots{}}). Seules les catégories généralistes et légères : \textit{Général}, \textit{Halka}(ie: blagues) et \textit{Vacances} restent inchangées, alors que d'autres sont en perpétuelles mutations : \textit{Islam} devient \textit{Islam et religions}, puis \textit{Islam et pensées religieuses} et enfin \textit{Apprendre l'Islam}. L'orga\-nisation du forum se stabilise en 2010 et compte aujourd'hui 25 catégories différentes. Chaque jour, ce sont ainsi plusieurs dizaines de sujets de discussions et plusieurs de centaines de messages qui sont ouverts et échangés entre les membres du forum. 

\subsection{La manifestation du 20 février 2011}

\noindent Le \textbf{Printemps Arabe} est une suite de protestations et de soulèvements des populations du monde Arabe (Maghreb, Proche \& Moyen-Orient ), débutée en Décembre 2010. L'ampleur et la finalité des contestations varie d'un pays à l'autre, mais la contiguïté de leurs déclenchements contribue à véhiculer l'image d'un embrasement spontané de la région, traversée dans son intégralité par une vague révolutionnaire (Table~\ref{tab:printemps}).  

Le printemps Arabe débute le 17 Décembre 2010, en Tunisie, dans la ville de Sidi Bouzid. Suite à la confiscation répétée de son matériel par l'administration locale, le vendeur ambulant M. Bouazizi, s'immole devant le siège du gouvernorat. Il décèdera deux semaines plus tard des suites de ses blessures. La portée de son geste trouve immédiatement un écho parmi la population et devient le déclencheur d'une vague de protestations inédite dans tout le pays. Le peuple tunisien descendant dans la rue, scandant son mécontentement d'une situation économique devenue invivable. Au ras le bol généralisé, contre le chômage et l'austérité, s'ajoute la soif de renouvellement démocratique d'une jeunesse tunisienne qui cristallise sa colère contre la personne de Z. Ben Ali, dirigeant en place depuis 1987 \citep{salmon_29_2016}. L'usage déterminant d'Internet, des réseaux sociaux et des téléphones portables, comme moyens directs d'organisation collective, permet au mouvement de gagner rapidement en ampleur \citep{lotan_arab_2011, khondker_role_2011}.    

La fuite de Ben Ali, un mois plus tard le 14 Janvier 2011, rapportée sur le Web et amplifiée par des canaux de diffusion comme Al Jazeera entraine la contagion des révoltes aux pays voisins marquant, de fait, le premier temps fort du Printemps Arabe. Et si la démission de H. Moubarak, le 11 Février suivant, après plusieurs semaines d'occupation populaire de la place Tahrir au Caire, est vécue comme une nouvelle victoire démocratique, les assauts contre-révolutionnaires à venir donneront un coup d'arrêt aux protestations. Courant 2011 et 2012, les soulèvements sont réprimés (Égypte, Yémen) et, pour certains, tournent à la guerre civile (Libye, Syrie). \\

\begin{table*}
  \label{tab:printemps}
  \begin{tabular}{lcl}
    \toprule
    pays&déclenchement des contestations&finalités\\
    \midrule
Tunisie&17 décembre 2010&fuite du président et changement de régime\\
Algérie&28 décembre 2010&promesses de réformes\\
Yémen&29 décembre 2010&départ du président\\
Jordanie&14 janvier 2011&démission du gouvernement\\
Mauritanie&17 janvier 2011&manifestations\\
Oman&17 janvier 2011&réforme constitutionnelle\\
Arabie saoudite&21 janvier 2011&réformes sociales\\
Liban&24 janvier 2011&manifestations\\
Égypte&25 janvier 2011&départ du président et changement de régime\\
Syrie&26 janvier 2011&guerre civile\\
Palestine&28 janvier 2011&manifestations\\
Maroc&30 janvier 2011&réforme constitutionnelle\\
Soudan&30 janvier 2011&manifestations\\
Djibouti&1er février 2011&manifestations\\
Bahreïn&14 février 2011&manifestations\\
Irak&10 février 2011&manifestations\\
Libye&13 février 2011&mort du dirigeant et guerre civile\\
Somalie&13 février 2011&manifestations\\
Koweït&18 février 2011&manifestations\\
  \bottomrule
  \end{tabular}
  \bigskip
  \caption{Liste des pays touchés par le Printemps arabe (source: \url{https://fr.wikipedia.org/wiki/Printemps_arabe})}
\end{table*}

\noindent Tout au long de cette période, le Maroc cultive une forme d'\textit{exception marocaine} vis-à-vis du Printemps Arabe. Suite à une première manifestation en demi teinte (le 30 Janvier 2011), de jeunes militants marocains des droits de l'homme voient, dans les mobilisations tunisiennes et égyptiennes, l'occasion de redonner de l'élan à d'anciennes revendications démocratiques. L'analyse stratégique de ces événements, les amène à déduire que les victoires de leurs voisins sont, d'abord, le fait de la mise en avant d'une jeunesse dépolitisée, évoluant sans leader clairement identifié et agissant sur la base d'actions spontanées et innovantes (sit-in, réseaux sociaux, comités locaux\ldots{}) \citep{bennani-chraibi_dynamique_2012}. Partant de ce constat, un appel est alors lancé pour un grand rassemblement national le 20 février 2011, baptisé \textit{journée de la dignité}. Dans la foulée, le \textit{mouvement du 20 février} (M20F) voit le jour pour coordonner et incarner les différents aspects de la contestation à venir. Contrairement à ses voisins, la mobilisation marocaine n'est donc pas née d'un embrasement soudain, mais d'une construction méthodique, orchestrée par des acteurs hétérogènes.

En effet, plusieurs associations et organisations rejoignent rapidement le mouvement\footnote{\RaggedOuter \url{https://www.yabiladi.com/articles/details/4596/marche-fevrier-maroc} \url{-associations-defense.html}} qui déclenche déjà l'enthousiasme de militants historiques de la cause démocratique, comme le blogueur \textit{larbi.org}\footnote{\RaggedOuter \url{https://frama.link/cTMRPS5a}}. Une préavis unitaire est déposé le 17 février, agrégeant derrière le slogan \og\textit{Liberté, Dignité, Equité}\fg{} une multitude de revendications nationales ou régionales : pour une justice indépendante, pour la reconnaissance de l'amazigh\footnote{\RaggedOuter Langue berbère } comme langue officielle et pour la dissolution du gouvernement, en passant par la lutte contre la corruption, contre la mauvaise gestion administrative et communale et contre le chômage \citep{bennafla_maroc_2011}. Bien que l'objectif affiché ne soit pas le renversement de la monarchie, les signataires n'en réclament pas moins de grands changements démocratiques et une modification en profondeur de la constitution marocaine, pour \og\textit{un roi qui règne mais ne gouverne pas}\fg{}\footnote{\RaggedOuter \url{https://frama.link/V7R8y1SH}}.

Relayée localement par les comités du M20F, la mobilisation se prépare aussi, et avant tout, sur la toile : un site Web est mis en ligne et associés à des comptes Twitter et de groupes Facebook\footnote{\RaggedOuter \url{https://web.archive.org/web/20110220014401/http://mamfakinch.posterous.com/}, \url{https://twitter.com/mamfakinch}, \url{https://www.facebook.com/Movement20}} qui tiennent les internautes informés grâce aux hashtags \textit{\#Feb20 \& \#20Fev}. La diaspora s'empare elle aussi du sujet via les blogs et les canaux d'informations du M20F. Des manifestations de soutient sont organisées, notamment à Paris\footnote{\RaggedOuter \url{https://youtu.be/g7muGDOGoto}} et à Bruxelles. 

Mais une campagne de contre-communication est lancée en parallèle par le gouvernement. Les membres du M20F sont ciblés personnellement sur les réseaux, dénigrés et intimidés. Anti et pro 20 février s'affrontent par vidéos interposées sur Youtube \footnote{\RaggedOuter \url{https://www.youtube.com/user/mouvement20fevrier/feed} et \url{https://www.youtube.com/user/MoroccanYouth/videos}} et Dailymotion. À deux jours de l'échéance, le M20F publie une dernière vidéo, où de jeunes militants appellent, face caméra, à descendre dans la rue, incarnant à visage découvert l'élan d'une jeunesse marocaine qu'ils souhaitent voir défiler massivement\footnote{\RaggedOuter \url{https://youtu.be/6Y_J-2S_1m8}}.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/morocco}
  \vspace*{0.2cm}  
  \caption{Principaux foyers de contestation, lors des manifestations du 20 février 2011 au Maroc (source : \url{ https://globalvoices.org/2011/02/20/morocco-across} \url{-the-nation-demonstration/}) }
  \label{fig:morocco}
\end{marginfigure} 

Le 20 février 2011, entre 37,000 (selon le ministère Marocain de l'intérieur) et 100,000 personnes défilent dans 53 localités différentes (Figure~\ref{fig:morocco}). Si le succès de la journée est mitigé d'un point de vue quantitatif, le M20F marque symboliquement les esprits et veut pousser plus loin la mobilisation, prévoyant de redescendre dans la rue les \textit{20} de chaque mois à venir. Mais le gouvernement Marocain et le roi Mohammed VI prennent, à titre préventifs une série de mesures visant à apaiser les mécontentements \citep{desrues_mouvement_2012}. Le 9 Mars, Mohammed VI prononce un discours à la télévision et annonce une modification de la constitution, dont les détails\footnote{\RaggedOuter \url{https://frama.link/oB6K7-hJ}} sont donnés le 17 Juin : le premier ministre sera dorénavant désigné par des élections, mais le roi gardera le pouvoir de dissoudre le parlement qui, de son côté, gagne en indépendance. Par ailleurs, la langue berbère devient, comme l'arabe, langue officielle d'état. Ce faisant, le régime marocain arrive à gérer la menace contestataire et étouffe une possible amplification du mouvement en reprenant à son compte l'agenda politique des événements. 

La nouvelle constitution est approuvée par référendum le 1er Juillet 2011, malgré l'appel au boycott\footnote{\RaggedOuter \url{https://youtu.be/irbHL8Io--Q}} lancé par le M20F qui n'y voient que des changements de façade. Quelques manifestations émaillent le reste de l'année, mais le M20F penne à mobiliser et à retrouver sa légitimité. Lors des élections législatives de Novembre 2011, les conservateurs du Parti de la justice et du dévéloppement (PJD) arrivent en tête des suffrages, mettant ainsi un terme au volet marocain du Printemps Arabe.

\subsection{Topologie d'un site Web}

\noindent Comment évolue un site ? Comment s'étend-il sur le Web ? Comment naissent et disparaissent certaines de ses sections ? Peut-on voir un site croitre, à mesure que de nouvelles pages s'ajoutent à son arborescence~? 

Ces questions sortent du cadre stricte de notre étude sur le forum de \textit{yabildai.com}, mais nous souhaitons tout de même nous y attarder ici, afin d'ajouter une nouvelle brique à nos outils d'exploration. En effet, le Web est tout autant un flux continu d'informations qu'un espace en pleine expansion, dont nous voulons maintenant retracer la genèse (à l'échelle d'un site tout du moins). Aussi, plusieurs pistes de réflexion s'offrent à nous : Qu'est ce qu'un site Web, d'un point de vue topographique ? Comment le représenter ? Comment traduire ses dynamiques internes ? Comment rendre compte de l'évolution de ses diverses ramifications, partant d'un corpus d'archives Web ? Notre corpus suffit il, à lui seul, à couvrir toute la ramure d'un site ? 

Sur ce point, M. Toyoda et M. Kitsuregawa proposent de se baser sur les URL d'un site pour en reconstituer le graphe \citep{toyoda_extracting_2003,toyoda_system_2005}. Chaque élément d'une URL (compris entre deux \textit{/}) formant un nœud particulier du graphe, dont l'évolution est ici retranscrite par une série de captures successives. On appelle cette méthode, une série temporelle de graphes. C'est l'approche que nous avions utilisé pour notre prototype \textit{en oursin} (Figure~\ref{fig:prototypes}, a), présenté en Section~\ref{sec:3_constituer}. Mais, avec un peu de recul, il nous semble difficile de comparer visuellement de telles séries, surtout lorsque les sites (comme \textit{yabiladi.com}) se révèlent être très verbeux en URL à afficher. De plus, la période de capture et de représentation reste sujette à discussion et peut varier sensiblement d'un site à l'autre.

À l'opposé, la méthode employée par B. Fry, dans son application Anemone\footnote{\RaggedOuter \url{http://benfry.com/anemone/}} \citep[p.76-82]{fry_organic_2000}, permet de saisir de manière dynamique l'évolution d'un site, vu ici comme un être vivant en pleine croissance. Le système, conçu par Fry, part de la première page archi\-vée d'un site Web donné, à laquelle il ajoute toutes les $n$ secondes une nouvelle ramification, collant ainsi à l'arborescence du site telle qu'elle a été collectée (Figure~\ref{fig:anemone}) :

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/anemone}
  \caption{Fonctionnement du système de visualisation Anemone, pour un site fictif \textit{inter.net}}
  \label{fig:anemone}
\end{figure*}

\noindent Mais, si l'idée de croissance est bien restituée par Anemone, la spatialisation (en haut, en bas, à gauche\ldots{}), de chaque branche est, quant à elle, codée pour suivre un comportement aléatoire : la structure du site reste la même, mais l'agencement local des pages varie à chaque relance de l'application. Ce procédé écarte malheureusement toute possibilité d'étude répétée et systématique. De plus, le temps est ici pensé comme une mécanique de visualisation (le temps sert à mettre à jour l'Anemone) et non comme une véritable dimension d'analyse.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/minard}
  \caption{C.J. Minard, (1869), Carte figurative des pertes successives en hommes de l'Armée Française dans la campagne de Russie 1812-1813}
  \label{fig:minard}
\end{figure*}

\noindent Sur ce point, en matière de visualisation des dimensions spatio-tempo\-relles d'un processus historique, la célèbre \textit{Carte figurative des pertes successives en hommes de l'Armée Française dans la campagne de Russie 1812-1813} de C. J. Minard reste la meilleure source d'inspiration. Elle permet de suivre le trajet (tracé beige) de l'armée napoléonienne et ses pertes humaines (épaisseur du tracé), à travers la Russie (indications géographique), au cours de l'hiver 1812-1813 (temps en abscisse). Deux dimensions (temps et espaces) servent ici de cadre à l'étude de l'évolution d'une troisième (le nombre d'hommes). \\ 

\noindent Au regard de ces exemples, il nous semble judicieux de choisir de représenter un site comme un arbre d'URL, se déployant depuis sa racine (la première page mise en ligne) et grandissant à mesure que de nouvelles pages y sont publiées. En effet, un arbre croît suivant une direction donnée qui peut, dans notre cas, être associée à un axe temporel, placé en abscisse à la manière d'une timeline \ref{fig:topo}. 

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/topo}
  \caption{Proposition de visualisation de l'évolution de la structure d'un site fictif \textit{inter.net} dans le temps}
  \label{fig:topo}
\end{figure}

\noindent Chaque URL du site représente ici une branche de l'arbre et les pages Web font office de feuilles (Figure~\ref{fig:topo}, points rouges). L'abscisse d'une URL est déterminée suivant la date de création (dans le meilleur des cas) ou de téléchargement (dans le pire des cas) de la page qu'elle adresse. Pour positionner les embranchements mécaniques\footnote{\RaggedOuter les portions d'URL entre deux \textit{/} ne correspondant à aucune page réelle} de notre arbre, nous leur attribuons arbitrairement une date médiane (Figure~\ref{fig:topo}, $t(p_2) - t(p_1)$). L'ordonnée d'une URL est, quant à elle, fonction de son âge (du haut vers le bas, de la plus ancienne à la plus récente) et lui sert d'encrage autour de l'embranchement parent (Figure~\ref{fig:ordonnee}). L'épaisseur d'une branche de l'arbre d'URL est déterminée par son nombre d'enfants. La taille des marqueurs représentant les pages peut être ramenée à une mesure donnée, comme par exemple, un nombre de messages postés.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/ordonnee}
  \vspace*{0.2cm}  
  \caption{Positionnement de 3 pages (rouge) autour d'un embranchement parent (bleu)}
  \label{fig:ordonnee}
\end{marginfigure} 

Ceci étant défini, nous développons alors un système\footnote{\RaggedOuter Open-source et téléchargeable ici \url{https://github.com/lobbeque/archive-viz/tree/master/stayingAlive}}, permettant de récupérer, depuis notre moteur d'exploration et depuis le corpus d'Internet Archive, l'ensemble des URL archivées d'un site donné. En effet, afin de garantir une plus grande couverture de l'étendue d'un site nous choisissons de coupler plusieurs sources de données. Nous implémentons cette méthode et construisons une interface de visualisation Web. L'utilisateur peut y zoomer à volonté et sélectionner, s'il le souhaite, le détail d'une branche ou d'une feuille (Figure~\ref{fig:reve}).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/reve}
  \caption{Capture d'écran de l'évolution topologique de la section \textit{Interprétation des rêves, roqya, djinn} du forum de \textit{yabiladi.com}}
  \label{fig:reve}
\end{figure*}

\subsection{Revenir au 20 février}

\noindent La mobilisation de la jeunesse marocaine sur les réseaux sociaux a servi d'amorce aux manifestations du 20 février 2011. Le temps d'une journée, les plateformes Twitter et Facebook ont prolongé les rues de Casablanca, de Rabat et de Marrakech via les hashtags \textit{\#Feb20 \& \#20Fev} (Section~\ref{sec:5_blogs}). Porté par une communication inédite, l'élan de ce mouvement a atteint la communauté des marocains de l'étranger, qui s'est orga\-nisée pour apporter son soutien \citep{desrues_mouvement_2012}. Parallèlement à ces événements, le portail en ligne \textit{yabiladi.com} s'est imposé comme un point de rassemblement et de discussion privilégié par la diaspora Marocaine sur le Web. 

Partant de là, notre exploration se tourne maintenant vers la masse des archives de \textit{yabiladi.com}. Dans quelle mesure, la mobilisation du 20 février 2011, a-elle pu impacter le quotidien de ce site et de ses utilisateurs ? Y-a-il eu une forme d'organisation collective, en amont de la manifestation ? Une communauté, même éphémère, de soutiens ou de détracteurs a-elle pu y voir le jour ?

Aussi, commençons par définir notre espace d'exploration. Nous partons d'un site Web unique, \textit{yabiladi.com}, dont nous possédons des collectages hebdomadaires, allant de Mars 2010 à Septembre 2014. Les corpus d'Internet Archive peuvent, ici, servir de données d'appoint ou complémentaires. \textit{Yabiladi.com} est un site vaste, possédant plusieurs sections, dont un forum divisé lui même en une dizaine ou une vingtaine de catégories (Figure~\ref{fig:categories}). Chaque catégorie englobe plusieurs threads de messages, hébergés sur des pages Web dédiées. Si, d'un point de vue temporel, notre cible est connue, il s'agit de l'avant et de l'après 20 février 2011, le nombre de messages ou de threads s'y référant reste pour le moment inconnu. L'idée est donc : \textbf{1)} d'identifier les messages parlant de la mobilisation, \textbf{2)} de remonter aux utilisateurs qui les ont publiés, \textbf{3)} de voir si ces membre forment une communauté. \\   

\noindent Tout d'abord, nous construisons un arbre d'URL qui servira de support à nos visualisations. Nous partons des 2,683,928 pages archivées du corpus e-Diasporas et des 887,981 pages collectées par Internet Archive, pour proposer une représentation, la complète possible, de la structure du site et de son évolution. Les données venant de nos archives sont associées, si possible, à une date de création; les pages fournies par Internet Archive sont, elles, datées par rapport à leur collecte. En cas de doublon, nous privilégions la datation la plus précise (Table~\ref{tab:datation_2}).

Les archives DAFF de \textit{yabiladi.com} sont ensuite envoyées dans notre moteur d'exploration qui les fragmente et les indexe. Là, un filtre est appliqué, pour ne conserver que les pages appartenant à la seule section forum du site : celles contenant la mention \textit{/forum/} dans leurs URL. Passé cette étape, nous retenons un groupe de 109,534 pages Web, associées à une date de création unique et segmentées en 422,906 fragments Web.

Mais, il ne nous semble pas nécessaire, d'analyser toutes les catégories du forum. Les sections \textit{Général} et \textit{Actualités} étant plus susceptibles de renfermer des threads et des messages associés au 20 février. Or, comme nous savons que la section \textit{Actualités} a subi de nombreux changements au cours du temps \ref{fig:categories} : \textit{Actualités}, \textit{Actualités du Maroc}, \textit{Actualités Marocaines},  \textit{Actualités internationales} et \textit{Actualité du Maroc et du Monde}, nous choisissons de les agréger en une seule et même section renommée \textit{Actualités}. 

Par ailleurs, en se basant sur la structure des URL du forum, il est possible d'en filtrer les pages par catégorie. En effet, depuis la création du forum en 2002, les URL suivent toutes le même schéma~:

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/filtre}
\end{figure}  

\noindent Par exemple, la \textit{category\_id} de la section \textit{Général} est $1$, information qui peut être facilement extraite. Nous appliquons ainsi ce filtre et obtenons en sortie de notre moteur les résultats de la Table~\ref{tab:forum}.

\newpage

\begin{table}
  \label{tab:forum}
  \begin{tabular}{lrr}
    \toprule
    & Général & Actualités\\
    \midrule    
    Nombre de threads&17,025&20,553\\
    Nombre de messages&352,231&328,965\\
    Nombre de membres&19,745&10,819\\
	Premier message&Janv. 2002&Janv. 2002\\    	
	Max. messages par membre&5,019&6,041\\	
	Max. threads par membre&1,316&2,057\\
	Messages moyens par thread&21&16\\    
  \bottomrule
  \end{tabular}
  \bigskip
  \caption{Statistique des archives des sections \textit{Général} et \textit{Actualités} de \textit{yabiladi.com}}
\end{table} 

\noindent Pour construire cette table, nous demandons à notre moteur de nous retourner les fragments Web ayant la forme d'un message générique, publié sur le forum, soit : un nom d'utilisateur, une date d'édition et un ensemble d'éléments textuels postés au fil d'un thread. Dans la suite de cette section, et par abus de langage, fragments Web et messages publiés, seront confondus et utilisés de manière équivalente. Aussi, pour identifier les messages\footnote{\RaggedOuter Le forum est écrit en majorité en français} se référant aux événements du 20 février 2011, nous utilisons la recherche plein texte de notre moteur et partons de l'ensemble de mots clés suivants :

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/20fev}
  \caption{Mot clés associés à la manifestation du 20 février 2011}
  \label{fig:mot}
\end{figure}  

\noindent Nous agrégeons, ensuite, par thread les fragments retournés. Après une validation manuelle, nous n'en conservons que 12, selon qu'ils traitent directement du 20 février ou de ses conséquences\footnote{\RaggedOuter réception par la diaspora, suites à donner au mouvement, discréditation d'un des organisateurs\ldots{}}. Nous présentons, ci dessous, la liste des différents titres (ou sujets) de ces 12 threads~:

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/20fev-topic}
  \caption{Titre des 12 threads directement associés au 20 février}
  \label{fig:20fevTopic}
\end{figure}  

\noindent Nous appelons $V_0$ ce groupe initial de 12 threads, consistant en un ensemble de 196 messages, écrits par un panel de 94 auteurs uniques nommé $E_0$.

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/yabi-1}
  \caption{Évolution de la structure de \textit{yabiladi.com} et ensemble de threads $V_1$}
  \label{fig:yabi-1}
\end{figure*}

\noindent L'idée est maintenant d'élargir ce premier groupe aux messages écrits en amont et en aval de la manifestation. Pour ce faire, nous utilisons $E_0$ comme nouveau point de départ et filtre de sélection. Aussi, nous demandons à notre moteur de nous retourner tous les threads du forum dans lesquels au moins deux auteurs de $E_0$ ont publiés un message. En effet, c'est un collectif d'utilisateurs que nous cherchons ici à étudier. Il nous faut donc découvrir s'ils se connaissaient avant la manifestation et s'ils ont continué à collaborer par la suite, notamment en alimentant les même threads à plusieurs mains. Au final, nous obtenons un nouveau groupe de 343 threads appelé $V_1$. La Figure~\ref{fig:yabi-1} donne à voir la répartition de ces threads (points rouges) dans le temps, parmi les pages archivées du forum de \textit{yabiladi.com}.

\subsection{Des trajets de contributeurs}

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/trajet}
  \vspace*{0.2cm}  
  \caption{Trajet d'un utilisateur ayant posté des messages (bleu) sur deux threads (rouge)}
  \label{fig:trajet}
\end{marginfigure} 

\noindent Il faut ajouter à la Figure~\ref{fig:yabi-1} une nouvelle information : la trace du trajet d'un utilisateur, naviguant d'un thread à l'autre du forum. En effet, en utilisant le fragment Web (Section~\ref{sec:4_derrida}) comme unité principale d'exploration, nous souhaitons réintégrer de l'humain au cœur des archives Web, revenir aux gestes de celles et ceux qui alimentent quotidiennement les sites collectés. Aussi, en nous servant des noms d'auteurs associés aux messages que nous manipulons comme moyen d'identification, nous pouvons afficher de manière dynamique le trajet d'un membre donné (Figure~\ref{fig:trajet}). La Figure~\ref{fig:yabi-2} présente ainsi l'un de ces trajets individuels, agrégé ici au niveau des threads. 

Mais bien plus qu'un individu isolé, c'est une communauté que nous cherchons d'abord à caractériser. Or, le fragment Web nous permet justement de conjuguer le devenir historique de multiples lignes processuelles (Section~\ref{sec:4_derrida}), afin de raisonner autour de moments singuliers, à l'image du 20 février 2011. Nous définissons ainsi l'ensemble $E_1$ comme l'agrégation des trajets empruntés par le groupe d'utilisateurs $E_0$ et le graphe $G=(V_1,E_1)$ comme un réseau de threads liés entre eux par les trajets de contributeurs communs (Figure~\ref{fig:graphe_g}). 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/graphe_g}
  \vspace*{0.2cm}  
  \caption{Le graphe $G=(V_1,E_1)$ pour $V_1$ contenant quatre threads de messages}
  \label{fig:graphe_g}
\end{marginfigure} 


Nous affichons donc l'ensemble des trajets d'utilisateurs, extraits de nos archives et associés au 20 février. Mais afin de faciliter l'analyse de ces chemins, nous les représentons en utilisant la méthode \textit{edge bundling} \citep{holten_hierarchical_2006}, qui permet de modifier localement la courbure d'un lien dans un graphe, pour le rapprocher visuellement de ces voisins. 

La Figure~\ref{fig:yabi-3} donne à voir ce graphe $G$ et la manière dont il se construit au cours du temps. Pour clarifier, une dernière fois, la lecture de cette figure, nous dissimulons l'ossature de l'arbre d'URL de \textit{yabiladi.com} et n'affichons que les trajets $E_1$ (tracés noirs) parmi les threads $V_1$ (points rouges).

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/yabi-2}
  \caption{Exemple de trajet individuel (tracé bleu clair) parmi 66 threads du forum \textit{yabiladi.com}}
  \label{fig:yabi-2}
\end{figure*}

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/yabi-3}
  \caption{Trajets agrégés $E_1$ de l'ensemble des contributeurs des threads $V_1$ du forum \textit{yabiladi.com}}
  \label{fig:yabi-3}
\end{figure*}

\noindent Une première analyse de la Figure~\ref{fig:yabi-3}, révèle l'apparition de plusieurs \textit{points de fixations}. Ce sont des points précis du graphe $G$ où arcs et nœuds semblent converger tous au même endroit et même moment. Le plus visible de ces points, où le nombre de threads est le plus important et où les trajets sont les plus densément  concentrés, correspond aux voisinages directs du 20 février 2011 (Figure~\ref{fig:yabi-3}, flèche rouge). Plus précisément,  ce sont $25\%$ des 343 threads de $V_1$ qui sont crées entre Janvier et Février 2011.

Cette première observation fait sens, au regard, notamment de la construction de notre groupe de départ $V_0$, centré sur la mobilisation marocaine. Mais, nous voyons également que les manifestations du 20 février ont agrégé, autour d'elles, une communauté de membres du forum qui communiquaient déjà en entre eux, en amont des événements (un autre point de fixation est visible en 2009 par exemple, Figure~\ref{fig:yabi-3}).

Aussi, si nous divisons maintenant la Figure~\ref{fig:yabi-3} en deux parties, séparées par le 20 février et appelées respectivement parties \textit{pré-mouvement} et \textit{post-mouvement}, nous voyons que la partie pré-mouvement prend la forme d'un sous-graphe de $G$, clairsemé et étalé sur une période relativement importante, allant de début 2004 à février 2011.

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/user-first}
  \caption{Répartition des utilisateurs du groupe $E_0$ par date de premier message}
  \label{fig:user-first}
\end{figure}  

\noindent Sur l'ensemble du groupe initial d'utilisateur $E_0$, $62\%$ écrivent leur premier message sur le forum durant la période pré-mouvement (Figure~\ref{fig:user-first}). En particulier, $20\%$ d'entre eux, sont apparus sur \textit{yabiladi.com} en 2007-2008, suivant une vague de nouveaux arrivants\footnote{\RaggedOuter Ces auteurs ont notamment contribué au thread \og\textit{Accueil des nouveaux yabis ! Marhaba !}\fg{}}. Ces premiers membres se sont alors réunis et retrouvés pour débattre ensemble dans des threads dédiés au 20 février et ont, semble-il, continué à communiquer entre eux après ces événements. En effet, les $38\%$ restant, du groupe d'utilisateurs $E_0$, ont contribué d'abord et en premier aux threads directement liés au 20 février. Avant cette date, ils n'apparaissent pas dans les archives de \textit{yabiladi.com}. Nous les retrouvons, néanmoins dans la partie post-mouvement de notre graphe. 


Ces observations sont ici purement topographiques et basées sur des corrélations temporelles, nous ne rentrons pas encore dans le détail des conversations. Mais à ce niveau, nous pouvons déjà affirmer être face à un double comportement : \textbf{1)} d'anciens utilisateurs du forum convergent collectivement vers les threads mentionnant les manifestations \textbf{2)} de nouveaux membres débarquent directement sur \textit{yabiladi.com} pour contribuer aux débats post-mouvement. En revanche, tous disparaissent et s'évanouissent soudainement du site au début de l'année 2012.

\subsection{Vers un embrasement}

\noindent Afin de mieux saisir la dynamique de convergence des anciens et des nouveaux utilisateurs du forum autour des événements du 20 février 2011, nous souhaitons maintenant affiner notre analyse du graphe $G$. Avec la Figure~\ref{fig:yabi-3}, la spatialisation du graphe, c'est-à-dire la manière dont nous le représentons, est uniquement fonction de la date à la laquelle chaque thread de $V_1$ a été crée. Mais d'autres types de spatialisation existent, d'autres manière de reprocher ou d'éloigner visuellement les nœuds d'un graphe peuvent être employées. 

Nous reprenons donc notre graphe et l'envoyons dans le logiciel de visualisation gephi\footnote{\RaggedOuter \url{https://gephi.org/}} où nous choisissons de le spatialiser en utilisant, cette fois ci, la méthode \textit{force atlas} \citep{jacomy_forceatlas2_2014}. Appartenant à la famille des algorithmes dits \textbf{force-directed}\footnote{\RaggedOuter \url{https://en.wikipedia.org/wiki/Force-directed_graph_drawing}}, force atlas suit une approche purement topographique, où les nœuds  
d'un graphe sont supposés être chargés d'une force de répulsion et où les arrêtes sont elles chargées de les retenir (Figure~\ref{fig:force_atlas}). L'algorithme itère sur l'ensemble du graphe, déplaçant les nœuds et les rapports de force jusqu'à trouver un point d'équilibre global.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/force_atlas}
  \vspace*{0.2cm}  
  \caption{Principe de base de Force Atlas, les noeuds d'un graphe sont chargés d'une force de répulsion et les arcs d'une force d'attraction}
  \label{fig:force_atlas}
\end{marginfigure} 

La Figure~\ref{fig:gephi} présente le graphe $G$ nouvellement spatialisé. De la même manière qu'avec la Figure~\ref{fig:yabi-3}, nous voyons que $G$ suit à nouveau une distribution longitudinale, la graphe est étiré confirmant, de fait, sont aspect temporel. 

Les membres du forum contribuent d'abord et avant tout aux threads nouvellement crées. Ils ne reviennent que dans de très infimes cas participer à des discussions passées, construisant leur trajet d'auteur d'un instant $t_i$ vers un instant $t_{i+1}$, sans retour arrière. Le forum est ainsi vécu comme un flux continu de nouveaux threads, demandant des utilisateurs qu'ils entretiennent une présence régulière sur le site. Le temps moyen espaçant deux threads auxquels participe un auteur est ainsi de 53 jours, la valeur médiane étant de 8 jours. Ils sont, en cela, peu nombreux à marquer de longues pauses entre deux interventions, seuls $20\%$ des trajets durent plus d'un mois, l'intervalle maximum étant de 6 ans et 2 mois.   

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/gephi}
  \caption{Spatialisation du graphe $G$ par \textit{force atlas} et clustering des threads par classes de modularité}
  \label{fig:gephi}
\end{figure*} 

\noindent Dans un second temps, nous appliquons à notre graphe un algorithme de clustering par classes de modularité\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Modularité\_(réseaux)}} \citep{blondel_fast_2008}. Nous souhaitons grouper entre eux les threads du forum et ainsi analyser, sous une nouvelle perspective, les points de fixations précédemment révélés (Figure~\ref{fig:yabi-3}). 

La \textbf{modularité} d'un graphe est un score $\in [-1,1]$ qui cherche à traduire le rapport entre le nombre d'arêtes réel et le nombre d'arêtes espéré (placées de manière aléatoire) d'un groupe de nœuds. Plus ce score est élevé, plus le groupe tend à se rapprocher topographiquement de la structure d'une communauté (Figure~\ref{fig:modularite}).

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/modularite}
  \vspace*{0.2cm}  
  \caption{Exemple de clustering d'un graphe en 4 classes de modularité (couleurs)}
  \label{fig:modularite}
\end{marginfigure} 

\begin{table*}
  \label{tab:threads}
  \begin{tabular}{clcl}
    \toprule
    Cluster & Thread & Degré & Date de création\\
    \midrule    
	1&des espions a yabiladi?&8&25-05-2009\\
	1&Un nouveau forum ? Suggestions ?&9&04-05-2009\\
	1&adopter un chat&10&14-07-2009\\
	1&Assumez-vous vos écrits depuis votre inscription?&10&26-07-2009\\
	1&Accueil des nouveaux yabis ! Marhaba !&16&25-06-2007\\
    \midrule 	
	2&Les arabes et les apparences\ldots{}.&9&13-07-2010\\
	2&Franciser son prénom&10&20-06-2010\\
	2&correction orthographique\ldots{}&12&24-08-2010\\
	2&Double triple pseudo etc\ldots{}&14&08-02-2010\\
	2&Quels sont les 3 mots que vous associez à la France?&15&13-08-2010\\
    \midrule 	
	3&les homo sont musulmans comme les autres&10&15-10-2010\\
	3&Mais qu'est ce qui retiens certains en Occident????&10&26-09-2010\\
	3&Fautes d'orthographe: Catastrophique&10&19-10-2010\\
	3&porter une barbe au maroc\ldots{}terrorisme ?&12&15-09-2010\\
	3&Plus beau pays du monde??&12&03-09-2010\\
	\midrule 
	4&Bonne Année 2011 Meilleurs Voeux&12&28-11-2010\\
	4&Elections miss and mister yabi 2011.&14&04-11-2010\\
	4&Oh mon Dieu ! Qu'il est beau mon pays&15&16-11-2010\\
	4&L'accueil des MRE au Maroc&15&21-11-2010\\
	4&marocains et algériens&15&29-10-2010\\
    \midrule 	
	5&Arabe et Tamazight langues officielles !&12&28-01-2011\\
	5&Photos Des Manifestations&13&21-01-2011\\
	5&2 millions de manifestants a la place jame3 lfna&14&20-01-2011\\
	5&Le Couscous est il un plat raffiné ou populaire&14&16-01-2011\\
	5&Qui assistera le 20 février au Maroc\ldots{}.???&30&15-01-2011\\
    \midrule 
	6&Kadafi est juif&11&28-02-2011\\
	6&Images d'Algérie&12&04-03-2011\\
	6&Manifestation le 20 Mars au Maroc&12&15-02-2011\\
	6&Le "20 Fevrier" est il democratique&14&17-02-2011\\
	6&Si le Front national passe en 2012 ? ? ?&16&08-02-2011\\
    \midrule 	
	7&Oui ou Non pour la nouvelle constitution&10&20-05-2011\\
	7&J'aime notre Roi&10&29-06-2011\\
	7&Le roi du Maroc dans la boue !&10&24-05-2011\\
	7&Pourquoi un garçon a droit a plus d'héritages qu'une fille&11&27-08-2011\\
	7&Racisme biologique&12&07-04-2011\\
    \midrule 	
	8&Mariage à durée..déterminée !&10&07-09-2011\\
	8&Brandissons nos couleurs Rif\ldots{}&10&19-11-2011\\
	8&J'ai peur de la présence musulmane au Québec&10&21-11-2011\\
	8&Bonne année 2961 et meilleurs voeux à tous!&10&12-12-2011\\
	8&La Grande Classe Marocaine\ldots{}.&11&22-09-2011\\  
  \bottomrule
  \end{tabular}
  \bigskip
  \caption{Liste des 5 premiers threads (par degré) de chacun des 8 clusters du graphe $G$}
\end{table*} 

Ceci étant fait, le graphe $G$ se voit divisé en 8 clusters distincts (Figure~\ref{fig:gephi}, $\{\#1,...,\#8\}$), témoignant chacun d'un moment singulier de l'histoire de cette communauté. À nouveau, rappelons que cette segmentation ne prend pas en compte le contenu des threads, mais uniquement la structure du réseau. Le cluster \textit{\#1} couvre ainsi les premières années de $G$ (de Juillet 2004 à Septembre 2009) et le cluster \textit{\#5}, quant à lui, s'étend sur la période la plus courte, de Janvier à Septembre 2011. 

Afin de donner du sens à la lecture de ces clusters, nous procédons à une analyse manuelle du contenu de chacun des threads les composant. Avertissons simplement qu'il n'est pas aisé de résumer la diversité de ces conversations en une ou deux thématiques, cela n'a peut être même pas beaucoup de sens, aussi ce qui suit doit être pris avec précaution, de futures analyses viendront compléter cette première observation. La Table~\ref{tab:threads} présente pour chaque cluster, les sujets des 5 threads ayant agrégé le plus d'auteurs (en se basant sur le degré).

Le cluster \textit{\#1}, le plus long, est constitué de conversations sur les règles de fonctionnement internes au forum. Les groupes \textit{\#2} et \textit{\#3} agrègent des propos que l'on peut, faute de mieux, qualifier de quotidien pour ce forum. Le cluster \textit{\#4} marque le tournant des années 2010 à 2011, on note néanmoins une focalisation sur l'identité marocaine et des comparaisons entre le Maroc et ses voisins maghrébins. Mais soudainement, le cluster \textit{\#5} fait émerger une majorité de threads (19 sur 35) liés au Printemps Arabe et à la manifestation du 20 février. Puis, le cluster \textit{\#6} regroupe certains débats post-mouvement et diverses prises de position politiques. Le cluster \textit{\#7} traite de l'héritage politique du 20 février et du changement de constitution à venir. Enfin, avec le cluster \textit{\#8}, le forum retombe dans ses conversations quotidiennes.\\ 

\noindent Arrivée à cette étape, notre exploration des archives de \textit{yabiladi.com} nous suggère donc que le mouvement du 20 février 2011 n'a pas réellement été préparé de longue date sur le Web (ou tout du moins sur ce forum). Une étincelle a, soudainement et sans crier gare, embrasé une partie très minoritaire de \textit{yabiladi.com} : 94 utilisateurs actifs sur un total de 30,564. Cette vague a agrégé d'anciens membres établis du forum et de nouveaux venus en brisant leurs habitudes et la routine de leurs conversations quotidiennes. Mais, la mobilisation n'a pas duré dans le temps, ni donné lieu à une autre forme de protestation en ligne ou a une autre incarnation. La réforme de la constitution, menée par le roi du Maroc au printemps 2011, est venue clore ce moment révolutionnaire. Cette communauté d'utilisateurs est, en cela, une construction éphémère et aujourd'hui éteinte. 

En effet, la plupart de ses membres ont disparu du forum, au début de l'année 2012, quelques mois seulement après la première apparition de Twitter\footnote{\RaggedOuter \url{https://web.archive.org/web/20120627021244/www.yabiladi.com}} sur la page principale de \textit{yabiladi.com} (Figure~\ref{fig:timeline}). Mais, sur les 94 auteurs de l'ensemble $E_0$, nous pouvons avancer qu'au moins 26 d'entre eux ont crée et utilisent aujourd'hui un compte Twitter avec le même avatar\footnote{\RaggedOuter Comptage et validation manuelle réalisés en Avril 2018}.

\section{Mener des recherches historiques depuis les archives Web}
\label{sec:6_moment}

\noindent Au regard des derniers éléments tirés de nos explorations, peut-être est il maintenant temps d'interroger le bien fondé d'études basées sur les archives Web comme matière historique. Qu'il s'agisse des auteurs de la blogosphère marocaine ou des membres de \textit{yabiladi.com}, tous ont, peu de temps  après le début des opérations de collecte de l'e-Diaspora, choisi de quitter ces territoires du Web pour migrer vers les réseaux sociaux. En explorant d'abord et avant tout ces corpus d'archives Web, ne sommes nous pas passés à côté d'un des aspects majeurs de notre problématique ?

\subsection{Face aux limites de l'archivage du Web}

\noindent La mise en place de notre moteur d'exploration (Section~\ref{sec:4_moteur}) et la définition du fragment Web comme nouvelle unité d'analyse des archi\-ves Web (Section~\ref{sec:5_fragment}) ont été guidées par l'idée, selon laquelle, un site Web devait faire l'objet de recherches historiques dédiées \citep{brugger_web_2017}. 

Ce faisant, nous montrons qu'en étudiant les archives Web sur une échelle de temps large (Section~\ref{sec:6_blogs}) ou à travers un vaste espace d'explo\-ration (Section~\ref{sec:6_printemps}), il est possible de comprendre et d'analyser historiquement le devenir de collectifs en ligne aujourd'hui disparus. Nous avons trouvé les indices d'une mutation des auteurs et des lecteurs du Web (blogueurs, commentateurs, membres de forum\ldots{}) depuis les anciens blogs et les portails en ligne vers les nouvelles plateformes de réseaux sociaux (Facebook, Twitter\ldots{}). 

Mais, partant de nos seuls corpus archivés, nous ne pouvons mettre en lumière l'intégralité du processus de mutation. Seules quelques traces éparses de cette transition (Section~\ref{sec:6_blogs}), voire l'absence soudaine de ses dernières (Section~\ref{sec:6_printemps}), restent aujourd'hui décelables. À ce niveau, force est de constater que nous touchons ici l'une des limites des archives Web. Il nous faut, dès lors, considérer l'idée que nos corpus peuvent être intrinsèquement incomplets et partiales. 

Cette incomplétude va même bien au delà des cécités et autres artéfacts de crawl hérités de la structure même des archives Web (Section~\ref{sec:4_legacy}). Créées et pensées principalement au début des années 2000 \citep{masanes_web_2006}, les systèmes de préservation de la toile ont suivi avec succès les multiples évolutions du Web en tant que médium \citep{cho_evolution_1999,oita_archiving_2010,pop_archiving_2010}, mais pourtant, ils échouent encore à traduire le Web comme un écosystème \citep{brugger_website_2009}. 

Le Web vivant est un flot continu d'informations autant qu'un espace en perpétuel expansion. C'est un environnement de créations et de mutations où une multitude d'acteurs peuvent interagir organiquement. Les archives Web, elles, sont des collections figées de captures discrètes, stockées les unes à l'écart des autres. L'INA archive des données Twitter, la BNF collecte des blogs et Internet Archive préserve les premiers pas du Web mais sans jamais chercher à constituer des ponts entre chacun de ces corpus. Les archives des réseaux sociaux et les archives des sites Web classiques sont traitées comme deux entités séparées et irréconciliables. Quand bien même elles ont, toutes deux, été arrachées au même écosystème. 

Alors que nous cherchions à remonter la trace archivées des possibles conséquences du Printemps Arabe, les acteurs du Web (auteurs, lecteurs, visiteurs\ldots{}) s'étaient, depuis longtemps déjà, détournés des blogs et des forums \citep{khondker_role_2011,lotan_arab_2011}. La problématique des collectifs en ligne éteints est, ainsi, moins une question de disparition, qu'une question de transition. Malheureusement, nos archives Web ne témoignent que du premier saut de cette transition.  

\subsection{Une micro-histoire}

\noindent Dans son \textit{Manifeste pour une pensée numérique de l'écrit}\footnote{\RaggedOuter Manifeste vidéo \url{https://youtu.be/8kFntt1l09o}} (2016), F. Bon questionne les mutations récentes de l'écriture sur support numérique, au regard notamment, des moments charnières qui ont jalonné l'histoire de l'écriture dite classique, celle du livre papier, des rouleaux et des tablettes. Ces \og\textit{moments de transition où deux systèmes techniques se superposent}\fg{} et où le \og\textit{saut mental}\fg{} induit est \og\textit{mis à nu}\fg{}\footnote{\RaggedOuter Ibid, 5mn 30s} sont des axes de recherche privilégiés pour ressituer des textes et des œuvres numé\-riques dans l'histoire même de leur genèse. 

Aussi, l'histoire de l'écriture a-elle été ponctuée de moments clés, de moments de transition où tout l'écosystème de l'écrit (les modalités techniques, les supports techniques, les auteurs, les œuvres, les moyens de diffusion\ldots{}) pivote sur lui même et s'engage sur une nouvelle voie. L'historien L. Febvre note ainsi \citep{febvre_apparition_2013}, parmi d'autres moments : le passage de l'oral à l'écrit,  l'apparition des méta-données sur les rouleaux de parchemins, l'invention de la recopie mécanique et de l'imprimerie\ldots{}

Mais le Web et l'Internet en général possèdent-ils, eux aussi, de tels moments pivots ? Sur ce point, nous pouvons avancer que le Web s'inscrit déjà dans sa propre micro-histoire. À l'heure où ces lignes sont écrites, le Web fête ses 26 premières années d'existence (Section~\ref{sec:2_web}) et son enfance tout autant que son adolescence ne nous ont jamais semblé aussi éloignées. La difficulté à étudier aujourd'hui les premières heures du Web n'est plus à démontrer \citep{gebeil_quand_2016} et, malgré les mesures de préservation mises en place, beaucoup de ressources originales (logiciels, matériels, documentations\ldots{}) sont désormais perdues \citep{helmond_historical_2017}. Le simple fait de vouloir remettre sur pied un site Web passé, dans les conditions matérielles de sa première mise en ligne, s'apparente de nos jours à un jeu de piste insoluble ou a un exercice d'archéologie expérimentale\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Archéologie_expérimentale}} \citep{driscoll_searching_2017}. 

L'épopée de l'Arpanet \citep{russell_shadow_2014} et des réseaux antérieurs ou parallèles \citep{schafer_part_2015} à Internet font aujourd'hui figure de pré-histoire du Web. Dans leur enquête sur les pères fondateurs d'Internet, K. Hafner et M. Lyon mettent ainsi en lumière le devenir singulier de la liste de discussion \textit{MsgGroup} dans les années 80 :\\

\begin{fullwidth}
\og\textit{The dialogue itself in the MsgGroup had always been more important than the results. Creating the mechanisms of e-mail mattered, of course, but the MsgGroup also created something else entirely -- a community of equal, many of whom had never met each other yet who carried on as if they had know each other all their lives. It was the first place they had found something they'd been looking for since the Arpanet came into existence. The MsgGroup was perhaps the first virtual community.}\fg{} --- \citep[p.218]{hafner_where_1998}\\
\end{fullwidth} 

\noindent En outrepassant l'objet initial de cette liste\footnote{\RaggedOuter Le MsgGroup est une liste de diffusion créée en 1975, à laquelle souscrivait les spécialistes de l'e-mailing émergeant, dans le but de définir des bonnes pratiques, des normes, des standards\ldots{}}, pour en faire un espace vibrant de discussions et d'échanges, les membres du MsgGroup ont préfiguré les forums, les communautés de blogs et les réseaux sociaux à venir \citep{stevenson_slashdot_2016,paloque-berges_quest-ce_2018}. L'histoire du Web est ainsi jalonnée de ces moments où tout bascule, de ces moments pivots : comme la mise en place des systèmes xDSL et ADSL\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/ADSL}} qui participent de la démocratisation du Web à la fin des années 90, ou l'émergence des systèmes de partages et d'échanges \textit{consumer gifts} \citep{giesler_consumer_2006} qui tracent des ponts entre économie du Web et du réel au début des années 2000, en passant par le développement des smartphones et du Web mobile au tournant des années 2010\ldots{} 

\subsection{Les moments pivot du Web}

\noindent Si F. Bon ou J. Baschet utilisent tous les deux la notion de \textbf{moment} plutôt qu'\textit{instant} ou \textit{point} pour parler de moments de transitions entre systèmes ou de moments de rencontre de lignes processuelles, c'est que le moment est \og\textit{une forme diversifiée du temps vécu}\fg{}, une manière singulière de s'inscrire dans le temps et caractérisée par une \og\textit{densité spécifique}\fg{} \citep[p.186]{baschet_defaire_2018}. 

Chez ces chercheurs, la notion de moment est issue de la conception chinoise du temps qui, contrairement à la pensée occidentale, envisage le temps comme une suite de moments (\textit{shí}) successifs, s'inscrivant dans la durée (\textit{jia}), à la fois distincts et liés entre eux \citep{chen_cerner_2011} et non comme un continuum abstrait de points élémentaires \citep[livre XI, chap. XV, 20, p.~195]{saint_augustin_confessions_1993}. Dans la pensée chinoise, le temps est un agencement de moments et de durées. Le moment s'éprouve ainsi qualitativement, ce n'est pas une valeur abstraite (un instant, une date, une heure\ldots{}) mais le marqueur d'une temporalité concrète dont il faut faire l'expérience en la vivant (comme une saison ou une époque). L'intensité d'un moment (douce, tendue, brutale, ou diluée) varie tout autant que sa temporalité (brève, durable, étalée ou soudaine), permettant ainsi de différencier deux moments l'un de l'autre.

Mais pour nous, parler de moment, s'inscrit d'abord dans la continuité de notre discussion (Section~\ref{sec:4_temporalite}) sur les diverses temporalités du Web et de ses archives. Nous avancions alors, qu'il pouvait être possible de conjuguer ensemble plusieurs fragments Web et de suivre leurs lignes processuelles, afin d'étudier de saisir l'histoire du Web et ses cristallisations autour de moments singuliers. Une histoire du Web qui s'attarderait sur ces moments, est une histoire qui s'attache à comprendre qualitativement des processus historiques d'étendue et de durée variables. Sur ce point, les Sections \ref{sec:6_blogs} et \ref{sec:6_printemps} témoignent, à travers le prisme particulier des archives de l'e-Diaspora marocaine, du moment spécifique où certains acteurs de la toile ont choisi de quitter les territoires du Web 2.0 pour rejoindre le Web des plateformes de réseaux sociaux et satisfaire, par là même, leurs désirs et leurs besoins grandissant d'expression, d'organisation, de connexion et de partage de l'information en ligne. Nos archives Web (par leur contenu et par leur forme) sont ainsi chargée des derniers soubresauts d'un Web mourant \citep{stevenson_hypertext_2018} qui, lors de sa collecte, ne reflétait déjà plus la réalité de son temps \citep{helmond_platformization_2015}.

De fait, nous appelons \textbf{moment pivot du Web}, une époque de transition entre deux systèmes, un moment du Web où de nouveaux usages émergent et s'écartent des pratiques alors en vigueur sur la toile. C'est un moment d'instabilité où deux manières de vivre et d'expérimenter le Web se chevauchent. En cela, un moment pivot du Web nait de la rencontre de trois facteurs, soit : \textbf{(1)} la rencontre à un moment donné entre \textbf{(2)} une accélération technique et \textbf{(3)} des utilisateurs capables de s'en saisir et s'en emparer. La convergence de ces trois facteurs fait alors bifurquer le Web dans une direction inédite.

\begin{center}
	\textbf{***}
\end{center}

\noindent Ce chapitre nous aura permis de mettre en pratique et d'expérimenter une forme désagrégée d'exploration des archives Web, se basant, en premier lieu, sur le fragment Web comme unité d'analyse. La souplesse de cette méthode se conjugue assez naturellement avec l'Analyse Exploratoire de Données, courant singulier des statistiques, dont nous avons présenté les principales caractéristiques (Section~\ref{sec:6_eda}).

En partant d'une question simple, sur le devenir d'une blogosphère de sites migrants aujourd'hui éteints, nous avons cheminé à travers les archives Web, suivant une logique inductive, privilégiant l'observation et la recherche de l'étonnement (Section~\ref{sec:6_blogs}). De fait, il nous a été possible de suivre et de comprendre la manière avec laquelle ces blogs et les auteurs, qui les administraient, ont petit à petit migré vers d'autres territoires du Web : vers les réseaux sociaux (Twitter, Facebook\ldots{}). Dans ce nouvel espace d'expression, ces acteurs du Web se sont retrouvés pour reformer, puis renforcer leur communauté. 

Suite à la découverte, dans les archives des blogs, de deux hastags liés à la manifestation marocaine du 20 février 2011, nous nous sommes demandé si le portail en ligne \textit{yabiladi.com} avait pu être impacté par ce mouvement de contestation (Section~\ref{sec:6_printemps}). Site central de l'e-Diaspora marocaine, \textit{yabiladi.com} possède une section forum, fréquentée depuis toujours par des internautes marocains de l'étranger, susceptibles d'avoir été emportés par la vague révolutionnaire du Printemps Arabe. Dans les faits, une communauté éphémère d'utilisateurs du forum s'est construite en réponse à ces événements, agrégeant d'anciens et de nouveau membres du portail. De nombreux messages ont été publiés par ce collectif, mais sans pour autant réussir à s'inscrire dans la durée. Ses membres disparaissent rapidement des pages du forum, alors que le mouvement et les manifestations s'essoufflent, étouffés par le pouvoir marocain. 

Comme un bilan de ces deux explorations, nous voulons d'abord mettre en avant le rapport vertigineux entre l'infinité de points de départ possibles pour nos analyses et la dimension restreinte voire réduite des entités sur lesquelles nous conduisons, finalement, nos recherches. D'une part, nous partons d'un ensemble de 47 blogs archi\-vés pendant 4 années et terminons par questionner les messages d'adieu et les hashtags laissés par deux blogueurs uniquement. D'autre part, nous nous positions face à la collection des pages archivées de \textit{yabiladi.com}, qui se comptent en millions d'enregistrements, pour aboutir, en fin de compte, à l'étude d'un collectif de 94 membres. 

Pour nous, ce rapport est le résultat naturel de notre chaine d'analyse socio-technique, alliant approches qualitatives et quantitatives, déjà à l'œuvre lors de la création de l'Atlas e-Diasporas. C'est par l'articulation constante de ces diverses stratégies que nous sommes en mesure d'iden\-tifier, parmi nos vastes corpus archivés, des cas singuliers qui n'en demeurent pas moins aux croisement de multiples processus historiques, sociaux et techniques : le printemps Arabe, les formes d'organisation collective en ligne, le passage d'un âge du Web à un autre, etc. 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/topo-strate}
  \caption{vue de l'évolution de la structure des sites \textit{7didane.org} (haut), \textit{atmf.org} (bas)}
  \label{fig:topo-strate}
\end{figure*}

\noindent De fait, ces deux explorations découlent d'une suite non linéaire d'opé\-rations de natures (automatiques ou manuelles) et d'échelles (lar\-ges ou réduites) variables, comme le résume la Figure~\ref{fig:schema-full}. Aussi, nos corpus d'archives Web n'étant pas, en eux même, exhaustifs, il a été nécessaire de les enrichir de collectages réalisés par Internet Archive et de données extraites du Web vivant. Au cours de ces boucles d'exploration successives, le contenu et la structure des archives nous ont mené à conjuguer ensemble des techniques se référant autant à la science des réseaux, qu'à la recherche d'information, en passant par l'analyse sociologique d'une communauté et la définition d'un contexte historique.

\begin{figure*}[hbtp]%
  \includegraphics[width=\linewidth]{graphics/schema-full}
  \caption{Résumé des diverses opérations mises en place lors des explorations \protect\ref{sec:6_blogs} et \protect\ref{sec:6_printemps}, avec distinction entre approches automatique et manuelle}
  \label{fig:schema-full}
\end{figure*}

\noindent Mais, si l'ensemble s'apparente effectivement à une chaîne de traitements ad-hoc, cela ne nous empêche pas de concevoir chacune de ces briques, avec pour finalité, de les rendre adaptables à une grande variété de cas. Il en va ainsi des fragments Web, qui sont ici utilisés dans deux explorations distinctes, mais également de notre système de visualisation de la topologie d'un site Web. Cet outil de visualisation peut, partant d'un corpus d'archives Web, rendre possible l'étude des grands moments de l'histoire d'un site préservé, comme l'illustre, par exemple, la Figure~\ref{fig:topo-strate} pour les sites \textit{7didane.org} (haut), \textit{atmf.org} (bas, et Figure~\ref{fig:atmf-map}).

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/atmf-map}
  \vspace*{0.2cm}  
  \caption{\textit{atmf.org} (rouge) dans l'e-Diaspora marocaine}
  \label{fig:atmf-map}
\end{marginfigure} 

Enfin, ce chapitre aura été l'occasion d'apporter une contribution plus générale à l'étude du Web en tant qu'objet de recherches historiques. Nous proposons, ainsi, de construire une histoire du Web autour de l'analyse de certain de ses moments pivots. Soit l'histoire de ces périodes de transition entre différents systèmes et manières de penser le Web, où les gestes des différents acteurs de la toile étaient chargés d'une intensité particulière. Intensité qu'il est aujourd'hui possible d'identifier à travers l'exploration de nos corpus d'archives Web. Mais, tout au long de ce chapitre, nos collectages n'ont pu témoigner que de la première étape du moment qui nous intéressait, à savoir la migration des blogs vers les réseaux sociaux.

Malheureusement, les archives Web ne seront ni jamais complètes, ni jamais impartiales et ni jamais parfaitement fidèles au Web vivant. Aussi, dans la dernière partie de ce manuscrit, nous nous intéressons à d'autres formes d'archives Web, différentes de celles recueillis à l'INA ou chez Internet Archive et capturant de nouvelles traces numériques des migrations.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapitre 7 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Au Delà des Archives Web}
\label{chap:7}

\noindent Le Chapitre~\ref{chap:3}, nous avait permis d'aborder les différentes techniques de collecte et de stockage des archives Web, chaque stratégie de préservation étant liée à une manière particulière de concevoir les archives, autant sur la forme (fichiers, systèmes d'exploration\ldots{}) que sur le fond (nature de la ressource Web préservée).

Les réflexions des Chapitres \ref{chap:4}, \ref{chap:5} et \ref{chap:6} ont émané de l'analyse d'un corpus d'archives Web déjà existant : les collectages de l'Atlas e-Diasporas, appartenant à la famille du \textit{client-side-archiving}, celle des crawlers et des scrapers (Section~\ref{sec:3_constituer}). Mais bien d'autres formes d'archives existes pour préserver les traces numériques des migrations. 

Au cours de ce chapitre, nous présenterons deux autres corpus sur lesquels nous avons pu travailler au cours de cette thèse : \textbf{1)} les archives des logs de navigation de l'Internet Libre de la Bibliothèque Publique d'Information du Centre Pompidou (BPI), \textbf{2)} les archives du formulaire des familles d'accueil potentielles du programme d'héber\-gement de personnes exilées Comme à la Maison (CALM). Le premier peut être rattaché aux stratégies dites de \textit{transaction-archiving}, centrées sur les interactions entre un site et un ou plusieurs utilisateurs. Il s'agira pour nous de tenter de comprendre les particularités et les caractéristiques du Web de la BPI, destiné, d'abord et avant tout, à un public précaire de personnes seule, isolée, souvent migrantes. Le second appartient à la famille des méthodes dites de \textit{server-side-archiving}, cherchant à préserver les ressources du Web profond. L'idée, pour nous, sera de partir de l'étude d'une base de données (un formulaire de renseignement et ses évolutions) afin de saisir, à travers elle, la dynamique de l'accueil des personnes exilées chez des particuliers à la fin de l'été 2015. Nous chercherons, en particulier, à caractériser les familles accueillantes et leurs motivations, ainsi que l'environnement associatif et technique chargé de faciliter les mises en relation.  

Ces deux sujets seront traités de manière plus synthétique que l'ana\-lyse des archives e-Diasporas, telle que nous l'avons abordé précédemment. Ce sont des travaux toujours en cours\footnote{\RaggedOuter Ayant fait l'objet de communications préliminaires ou pour lesquelles des articles sont en cours de rédaction}, faisant appel à un grand nombre d'acteurs (institutions, chercheurs, étudiants\ldots{}) et contraints par une inertie plus importante que celle des travaux principaux de cette thèse. Mais, nous tenons néanmoins à en faire ici la présentation, car nous pensons qu'ils peuvent enrichir le regard que nous portons dans ce manuscrit aux archives Web et aux migrations.   

\section{Les archives de navigation Web de la BPI}
\label{sec:7_bpi}

\noindent Implantée à l'intérieur du Centre Pompidou, la Bibliothèque Publique d'Information (BPI) est la principale bibliothèque publique parisienne, accueillant plusieurs milliers de visiteurs uniques par jours\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Bibliothèque\_publique\_d'information}}. Inaugurée le 31 janvier 1977 en plein cœur de Paris, la BPI offre à ses visiteurs la possibilité de faire des recherches documentaires sur des collections papier et audio-visuelles, réparties parmi les 3 étages qui la compose. La bibliothèque est aussi un lieu de travail et d'occupation quotidienne, où se croisent étudiants, travailleurs, indépendants, personnes en situations précaires, migrants, sans domiciles fixes, etc\footnote{\RaggedOuter Cette section a fait l'objet d'une communication écrite : M. Amar, A. Camus, C. Evans \& Q. Lobbé, (2016), \textit{Études et recherches récentes sur les usages numériques à la Bpi}, Culture et Recherche n°134 2016}.  

\subsection{Les postes Internet Libre}

\noindent La BPI s'est toujours voulue pionnière de l'accès publique à l'informa\-tion. S'il est maintenant possible de venir y connecter son ordinateur en Wifi, la BPI met en place dès 1996 (soit 4 années seulement après la création du Web) des postes informatiques d'accès au World Wide Web. Ce service, aujourd'hui connu sous le nom d'\textbf{Internet Libre}\footnote{\RaggedOuter \url{http://www.bpi.fr/informations-pratiques/les-services/internet-et-le-wifi}}, met à disposition des visiteurs de la bibliothèque entre 200 et 250 postes\footnote{\RaggedOuter L'effectif des postes est régulièrement réajusté par les services de la BPI} ouverts sur le Web. L'inscription est anonyme (sans demande de pièce d'identité, ni formulaire à remplir) et donne accès à une session limitée à 40 minutes.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/ticket-bpi}
  \vspace*{0.2cm}  
  \caption{Ticket de réservation d'une session de 40 mn sur l'un des postes Internet Libre de la BPI}
  \label{fig:ticket-bpi}
\end{marginfigure} 

Une fois avoir fait la queue, un ticket nous est remis pour nous orienter vers la machine qui nous est attribuée (Figure~\ref{fig:ticket-bpi}). Là, il suffit de se connecter avec le code indiquer pour ouvrir notre session. Un compte à rebours nous indique en permanence le temps qui nous est encore alloué. Néanmoins, cette limitation à 40 minutes est progressivement abandonnée au cours du printemps 2017. Les postes sont aujourd'hui en accès libres et sans limite de temps, une personne peu donc passer toute la journée sur une machine, si elle le souhaite. 

Les postes sont répartis sur l'ensemble des trois étages de la bibliothèque, parmi les rayonnages des collections, à l'entrée ou le long des couloirs (Figure~\ref{fig:plan-bpi}). Mais, la consultations du Web à la BPI diffère d'une consultation \textit{à la maison} en cela qu'elle est publique, les écrans étant visibles aux yeux de tous les visiteurs. C'est pour cette raison que la connection Internet de la BPI est partiellement restreinte, les sites pornographiques, de pari en ligne, etc. sont ainsi filtrés.

Bien plus qu'une bibliothèque, la BPI est un environnement culturel ouvert à tous et devient, de fait, une maille importante du tissu social parisien. Fréquentée par un public en partie constitué de personnes en situation précaire (seules, fragiles, sans domicile fixe, migrants\ldots{}), bien souvent des hommes, les enquêtes de terrain dressent un portrait singulier du lien qu'entretient la BPI avec ses visiteurs \citep{paugam_pauvres_2013}. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/plan-bpi}
  \caption{Implantation des postes Internet Libre (rouge) sur les trois étages de la BPI}
  \label{fig:plan-bpi}
\end{figure*}

\noindent Pour beaucoup, la bibliothèque est un refuge où l'on peut s'assoir, passer la journée et y voir du monde. Certaines zones sont dédiées à l'accueil et à l'accompagnement de ces personnes, comme l'espace auto-formation ou les cours de langues et d'initiations à l'informatique. Mais la plupart du temps, ce sont les précaires eux même qui, par leur présence, redéfinissent le fonctionnement de la bibliothèque. Ce phénomène est notamment visible sur les postes Internet Libre. Malgré la présence d'un accès aux ressources électroniques (journaux en lignes, base de données\ldots{}) depuis ces machines, les observations font principalement remonter un usage \textit{loisir} et \textit{passe temps} du Web, centré sur la consultation de vidéos en ligne, de sites de réseaux sociaux ou de résultats sportifs\footnote{\RaggedOuter Voir l'intervention : \textit{Les publics, in situ et en ligne}, C. Evans et M. Amar  \url{https://www.dailymotion.com/video/x5mw8i7}}. Néanmoins, il reste courant de voir des personnes mener, depuis ces postes, de véritables recherches approfondies ou encore se lancer dans des démarches administratives complexes (CAF, pôle emploi\ldots{}) et qui pourrait, par exemple, faire l'objet d'un accompagnement dédié. 

Ainsi, le Web de la BPI peut, aujourd'hui, être vu comme un Web de première nécessité \citep{pasquier_classes_2018}. Tout l'enjeu de cette étude est donc de chercher à caractériser cet usage particulier de la toile à la bibliothèque. Le tout, partant d'une source de données archivée et centrée sur la relation site/usager : les logs de navigation Web. 

\subsection{Les logs de navigation}

\noindent Dans le contexte sécuritaire de l'après 11 septembre, nombre de gouvernements se dotent d'un arsenal législatif renforcé en matière de captation, de conservation et de fouille de données électroniques personnelles. 

En France, la loi du 15 novembre 2001 \textit{relative à la sécurité quotidienne}\footnote{\RaggedOuter \url{https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000000222052}} introduit le principe de rétention des données à des fins notamment d'enquêtes judiciaires et codifié dans le Code des postes et des communications électroniques (CPCE). L'article L.34-1 assimile, de fait, une bibliothèque comme la BPI à un opérateur de communication électroniques en cela qu'elle a pour objet d'\og\textit{offrir un accès à des services de communication au public en ligne [\ldots{}] par l'intermédiaire d'un accès au réseau, y compris à titre gratuit}\fg{}\footnote{\RaggedOuter \url{https://www.legifrance.gouv.fr/affichCodeArticle.do?cidTexte=LEGITEXT000006070987\&idArticle=LEGIARTI000006465770}}. 

Le CPCE prévoit, tout particulièrement, une obligation de conservation des données dites \og\textit{relatives au trafic}\fg{}. Soit un ensemble de données exclusivement techniques, mais contenant néanmoins des \og\textit{informations permettant d'identifier [un] utili\-sateur}\fg{}\footnote{\RaggedOuter Voir le décret d'application du 24 mars 2006 que la CNIL a, par ailleurs, qualifié d'imprécis \url{https://frama.link/jcb9WapK}} telles qu'une adresse IP. La durée de rétention de ces données est fixée à une année glissante. Le stockage est lui effectué par et chez l'opé\-rateur de communication qui doit être en mesure de fournir les données à la justice. Aussi, la BPI garde-elle en permanence une année de logs de navigation sur ses serveurs, auxquels nous avons eu accès dans le cadre d'un projet de recherche commun avec le service Études et Recherches de la BPI.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/log}
  \caption{Exemple de logs de navigation générés par le proxy Web de la BPI}
  \label{fig:log}
\end{figure*}

\noindent Un \textbf{log de navigation} est un enregistrement texte, généré par un proxy Web\footnote{\RaggedOuter Logiciel intermédiaire entre le réseau de la BPI et le Web, utilisé notamment pour filtrer certains sites}, dès qu'une page Web est chargée sur l'un des postes Internet Libre de la BPI. Or, toute page Web est composée d'un ensemble de ressources associées, chacune, à une URL donnée (comme les publicités, les images, les vidéos\ldots{}). Aussi, il est rare qu'une page s'affiche immédiatement, il lui faut souvent une poignée de secondes pour se charger dans son intégralité, élément par élément. Ainsi, chaque fois qu'un utilisateur visite une page Web à la BPI, cela se traduit, en base de données, par la création d'un ou plusieurs logs (Figure~\ref{fig:logs}) soit liés à un élément particulier, soit causés par un chargement laborieux. On parlera alors de logs de chargement.

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/logs}
  \vspace*{0.2cm}  
  \caption{Une page Web peut générer plusieurs logs de navigation}
  \label{fig:logs}
\end{marginfigure} 

Un log est une capture horodatée d'une action donnée (Figure~\ref{fig:log}). À la BPI, les logs de navigation font correspondre dates de visite et URL affichées. Dans le détail, nous pouvons y trouver les informations suivantes : une adresse IP virtuelle associée à chaque session de navigation, un identifiant physique de poste, un timestamp horodatant le chargement de l'URL, l'URL visitée, son code de retour HTTP et, enfin, une catégorie. Les IP virtuelles ne sont pas uniques. Elle sont issues d'un lot d'adresses disponibles et redistribuées à chaque ouverture d'une session de navigation. En revanche, à un identifiant physique de poste correspond une et une seule machine. Cet identifiant permet de situer le poste Internet dans les locaux de la bibliothèque. Par exemple, l'identifiant \textit{PUB-2-MUS-239} signifie : poste \textit{publique}, étage \textit{2}, espace \textit{musique}, numéro \textit{239}.  

Le proxy Web utilisé par la BPI est développé par la compagnie privée Olfeo. Il a pour particularité de fournir une catégorisation à la volée de chaque URL qu'il voit passer. Cette catégorisation se fait sur la base de masques de correspondances de noms de domaines, mis à jour et maintenus par Olféo\footnote{\RaggedOuter Voir le détail des catégories d'URL ici \url{https://frama.link/ffuy3r1h}}. De fait, nous n'avons pas la main sur ces catégories, mais elles peuvent néanmoins servir à enrichir nos analyses ou à servir de filtres. Par exemple, le site \textit{youtube.com} est catégorisé sous l'identifiant $1207$ correspondant à l'appellation \textit{Sites de Partage de Vidéo}.

Chaque log est donc une ligne de texte et plusieurs logs, mis les uns à la suite des autres, forment un fichier de logs. Ces fichiers sont générés quotidiennement, compressés, puis stockés sur les serveurs de la BPI. Pour résumer, les logs de navigations de la BPI, archivent la relation entre un utilisateur donné et la page Web (adressée par une URL) qu'il visite. \\

\noindent Il existe plusieurs type de logs de navigation, plus ou moins détaillés, plus ou moins proches des actions de l'utilisateur ou du site Web. En effe, il est possible de générer des logs beaucoup plus centrés sur le geste des internautes, souvent limité à un site donné, en collectant chaque clic ou chaque mouvement de la souris. Cette forme riche d'enregistrement est, par exemple, utilisées pour analyser les usages du site Web \textit{gallica.bnf.fr} par V. Beaudouin \citep{beaudouin_observer_2014}, qui détermine plusieurs profils type d'utilisateurs \textit{gallicanautes}. Mais, si les logs de la BPI ne bénéficient pas d'un tel niveau de finesse, ils nous offrent néanmoins un champ plus large de pistes de recherche. Ces logs sont balancés et équilibrés par leur simplicité, dans le rapport site/usager aucune des deux dimensions n'est favorisée. Ainsi, pour caractériser l'usage singulier du Web de la BPI, nous pouvont choisir de placer nos analyses, soit du côté des utilisateurs (profilage temporel, géographique\ldots{}) soit du côté des sites Web (études topologiques, sémantiques\ldots{}), soit en associant les deux points de vue.

\subsection{Construire une chaine de traitements}

\noindent Notre première tâche consiste à penser et mettre en place une chaîne d'extraction, d'analyse et de visualisation des logs de navigation\footnote{\RaggedOuter Travail réalisé en collaboration avec C. Berrachdi, étudiante à Télécom ParisTech}. En collaboration avec le service informatique de la bibliothèque, nous copions quotidiennement les logs de la veille vers l'espace de stockage sécurisé TeraLab\footnote{\RaggedOuter \url{https://www.teralab-datascience.fr/fr/}}, où un script automatique se charge d'ordonner les fichiers, de les décompresser, voire d'effacer les données antérieures à une année glissante. 

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/chaine_bpi}
  \caption{Chaine de traitement des logs de navigation de la BPI}
  \label{fig:chaine_bpi}
\end{figure*}

\noindent Une fois copiées, les logs sont ensuite envoyés dans notre chaîne de traitement, constituée de 3 briques logicielles distinctes\footnote{\RaggedOuter Logiciels open-sources, voir \url{https://www.elastic.co/fr/products/logstash}, \url{https://www.elastic.co/fr/products/logstash}, \url{https://www.elastic.co/fr/products/elasticsearch}, \url{https://www.elastic.co/fr/products/kibana}} : \textbf{1)} le logiciel logstash se charge d'extraire les logs de leur fichier d'origine, de les nettoyer et de les filtrer \textbf{2)} le moteur de recherche elasticsearch indexe et rend interrogeable les cogs \textbf{3)} l'interface Web kibana permet de réaliser des visualisations à la volée de nos données de navigation (Figure~\ref{fig:chaine_bpi}). Ici nous ne re-développons rien, nous agençons et configurons des solutions déjà existantes et performantes. 

Ouverte 6 jours sur 7 (de 12h00 à 22h00), la BPI génère entre 2 et 3 millions de logs de navigation par jours. Beaucoup de ces logs ne sont en réalité que du bruit. Or, nous souhaitons le plus possible nous rapprocher d'un ratio 1/1, soit un log généré par page visitée. Pour ce faire, nous filtrons d'abord les logs associés à des URL publicitaires en réutilisant à notre compte les listes des addblockeurs\footnote{\RaggedOuter Par exemple \url{https://filterlists.com/}}. Certaines catégories du proxy Olfeo peuvent également servir de filtre. Enfin, pour gérer les multiples URL de chargement, nous choisissons d'agréger ensemble, les logs générés par un même nom de domaine, et ce, dans un intervalle inférieur à 4 secondes\footnote{\RaggedOuter D'une étude à l'autre, le temps moyen de chargement d'une page Web est compris entre 3 et 6 secondes}. Ce faisant, en sortie du logiciel logstash (Figure~\ref{fig:chaine_bpi}, a), nous supprimons 9 logs sur 10 et envoyons au moteur de recherche une moyenne de 200,000 logs/jour. Il nous faut environ 3 heures pour traiter une journée de logs. 

Les données peuvent être interrogées via l'interface de visualisation kibana (Figure~\ref{fig:chaine_bpi}, c) pour faire, par exemple, du suivi quotidien (top 10 des sites les plus visités, occupation des postes par étage\ldots{}), ou encore, procéder à des analyses rapides\footnote{\RaggedOuter En cela, notre chaine de traitement vient remplacer un système existant, créé en 2004 par M. Renault, aujourd'hui obsolète}. Mais, dans la suite de cette étude, nous choisirons d'explorer les données de manière plus large et plus souple, en travaillant directement depuis le moteur de recherche elasticsearch (Figure~\ref{fig:chaine_bpi}, b). \\

\noindent D'un point de vue méthodologique, nous cherchons à ne pas couper le lien entre l'image du Web de la BPI, tel que nous le voyons à travers les logs, et la réalité du terrain. Au contraire, nous dressons des ponts entre le réel et le Web, afin de pouvoir questionner à tout moment telle ou telle représentation , tel ou tel résultat. Aussi, nous mettons régulièrement en place, ce que nous appelons des \textbf{sessions de navigation} documentées et horodatées. Ces sessions ont deux finalités : \textbf{1)} vérifier ma correspondance entre le ressenti d'une navigation Web derrière un écran et l'écart possible avec les logs archivés \textbf{2)} s'immerger parmi les utilisateurs de l'Internet Libre, se mettre dans une position d'observateur, pour déterminer de futures pistes de recherche.

\subsection{Des profils de navigation Web} 

\noindent Lorsqu'il s'agit de caractériser des utilisateurs partant de traces de navigation, les recherches s'orientent rapidement vers l'étude de profils et de parcours communs \citep{feng_web_2006}. Quels sont les grands motifs de navigation dominants ? Y-a-il des effets de périodicité temporel (à la semaine, en fin de journée\ldots{}) ou de territorialité (par étage ou par effet de voisinage\ldots{}) ? Cette piste est d'autant plus privilégiée qu'elle pourrait permettre de vérifier par les données, les observations du terrain, à savoir un Web de la BPI avant tout tourné vers le loisir et le passe-temps.

L'idée est ici de ramener les logs à la notion de trajet individuel d'une page à une autre et de voir, par des méthodes de clustering, s'il n'existe pas des trajectoires communes à tous les utilisateurs de la BPI\footnote{\RaggedOuter Travail réalisé en collaboration avec M. Pierru, étudiante à Télécom ParisTech}. Comme nous sommes dans une phase de découverte des données, notre première stratégie est de nous tourner vers des techniques non supervisées, sans apprentissage. La méthode dite \textbf{k-means}\footnote{\RaggedOuter K-moyennes en français \url{https://fr.wikipedia.org/wiki/K-moyennes}} permet par exemple de déterminer le centre d'une communauté d'individus donnés représentés par des vecteurs.

Pour initialiser l'algorithme k-means, il faut lui indiquer le nombre de centres recherchés, nombre qui peut être déterminé en utilisant la méthode dite du coude\footnote{\RaggedOuter \url{https://en.wikipedia.org/wiki/Elbow\_method\_(clustering)}}. Ces centres sont positionnés aléatoirement dans l'espace vectoriel (Figure~\ref{fig:k-means-algo}, b), puis l'algorithme procède par itération. La distance entre les centres et les individus est calculer pour permettre une première assignation (Figure~\ref{fig:k-means-algo}, c). Puis les centres se déplacent au milieu de ces communautés temporaires et la distance est à nouveau calculée. L'algorithme chemine ainsi jusqu'à que les centres ne se déplacent plus (Figure~\ref{fig:k-means-algo}, c), déterminant ainsi les communautés et leurs individus moyens (ie: centroïdes).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/k-means-algo}
  \caption{Exemple de fonctionnement de l'algorithme k-means avec 2 centres (bleu et rouge)}
  \label{fig:k-means-algo}
\end{figure*}

Avec nos logs, nous commençons par créer un identifiant de session unique pour grouper entre les pages visitées par un même individu : soit la concaténation de l'IP virtuelle, de l'identifiant de poste et de la date. Chaque session est ensuite représentée par un vecteur ayant autant de dimensions que de catégories Olfeo existantes. Les parcours sont déterminés par la catégorisation des URL. Nous choisissons, dans un premier temps, de ne pas prendre en compte la dimension temporelle à l'intérieur des sessions, c'est-à-dire le fait qu'une page est visitée après ou avant une autre. Il existe néanmoins des exemples de clustering de sessions de navigation par k-means temporel \citep{stevanovic_unsupervised_2011}. Aussi, pour chaque log de chaque session, nous incrémentons la coordonnée de la catégorie correspondante dans le vecteur. Nous testons cette méthode sur une semaine de données, du 20 au 26 mars 2017, semaine à priori neutre et sans événement particulier. 

Le nombre de centres varie d'un jour à l'autre, entre 2 et 4 centroïdes. La Figure~\ref{fig:k-means} présente les résultats sous la forme d'une matrice : les 11 catégories d'ULRs les plus représentées en ordonnée, les jours en abscisse. Pour chaque journée, nous ne conservons que les deux clusters les plus importants (les colonnes) pour lesquels nous indiquons la proportion de logs correspondants. 

Deux grands profils se dégagent, à savoir un profil fait exclusivement de consultations de sites de partage de vidéos (Youtube, Dailymotion\ldots{}) et un profil fait de consultations vidéos partagées en proportion avec les sites de réseaux sociaux (Facebook, Twitter\ldots{}). L'observation du terrain est donc confirmée par les données. Notons le cas particulier du mardi, où la bibliothèque est fermée et où les seules consultations Web sont celles des gardiens. Notons aussi, la sur-représentation des sites de traduction le lundi 20 mars 2017, qui après fouille dans les données, s'avère être liée à des recherche russophones. Là encore, cette information confirme l'observation dans la bibliothèque d'une grande communauté d'usagers d'Europe de l'est et russophiles. La catégorie \textit{services aux entreprises} s'avère, après recherches, être un ensemble d'URL et de sites de types \textit{analytics}, traceurs ou cookies. Cela ne nous renseigne pas beaucoup sur le profil des usagers, mais plutôt sur la nature du Web en général, à générer pléthore de statistiques et de sondes sur le dos des internautes.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/k-means}
  \caption{Clustering des sessions de navigation Web par la méthode des k-means pour la semaine du 20 au 26 mars 2017}
  \label{fig:k-means}
\end{figure*}

\noindent La semaine choisie étant située à l'époque où les sessions de navigation limitées à 40 minutes étaient encore en vigueur, nous relançons notre algorithme sur une semaine où l'Internet Libre est en accès entièrement ouvert, non contrôlé, soit la semaine du 22 au 28 mai 2017. Mais les résultats sont sensiblement les mêmes, à ceci près qu'ils sont moins précis puisqu'avec la fin des sessions, un visiteur n'est plus obligé de se déconnecter en quittant un poste informatique. À une session peut donc correspondre plusieurs personnes. Notre identifiant de session pourrait être ici amélioré en ajouter la détection d'un temps de non-activité entre deux usagers. Nous testons également des différenciations par moments de la semaine, journée ou par étage, mais là encore es deux même profils ressortent encore.

Cela peut s'expliquer par la simplicité de la méthode employée, une stratégie plus fine qui incorporerait le temps dans ses calcules, comme l'utilisation des chaînes de Markov\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Chaîne\_de\_Markov}} \citep{cadez_model-based_2003}, pourrait nous donner des résultats plus variés. Mais là encore, ce qu'il nous serait donné de voir, ne pourrait être que la norme et la moyenne, renvoyant à notre discution sur l'AED en Section~\ref{sec:6_eda}. Or l'étude de la longue traine et des profils minoritaires pourrait s'avérer plus intéressante. En effet, il y a un biais majeur dans cette analyse, à savoir que les sites Web ne sont pas \textit{verbeux} de la même manière. Des sites emplis de publicités (même si nous en supprimons beaucoup), de vidéos ou de traceurs vont mécaniquement générer infiniment plus d'URL, et donc plus de logs, qu'un site modéré comme le portail d'une administration ou des sites gouvernementaux. Aussi, si un profil semble faible ou écrasé par les mastodontes Youtube et Facebook, cela vient très certainement de notre méthode de comptage et de la nature de ces archives.

\subsection{Des dimensions particulières}

\noindent Pour caractériser le Web de la BPI, il peut être intéressant de regarder du côté du contenu des pages visitées, dont nous connaissons les URL. En effet, l'étude directe des usagers précaires de la bibliothèque, via leurs profils de navigation, ne semble nous mener que vers la confirmation de grandes observations. Or, de manière indirecte, ce qui est lu ou ce qui est vu sur les postes Internet Libre, sont autant d'indices à extraire des pages Web pour dresser une image globale de l'environnement complexe qu'est le Web de la BPI.

Sur ce point, les enquêtes terrains menées par le service Études et Recherche de la bibliothèque et l'expérience que nous commençons en acquérir, nous conduisent à revoir nos priorités d'exploration et à penser une analyse des logs \textbf{par dimensions} particulières. Comme la masse des logs générés par les sites verbeux écrasent les cas singuliers, nous nous proposons de construire des sous-ensembles de données, suivant une ligne thématique dictée par nos observations in situ. Par exemple, les URL des sites de traduction, contiennent, en elles même, les mots que l'usager a cherché à traduire :

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/traduction}
  \caption{Exemple d'url du site de traduction linguee, pour le mot mémoire, du français vers l'anglais}
  \label{fig:traduction}
\end{figure*} 

\noindent Ces informations, agrégée, à l'échelle d'une semaine, d'un mois ou d'une année peuvent nous renseigner indirectement, sur la nationalité de certains usagers ou sur leurs préoccupations de traduction : s'agit-il de termes courants ou de termes techniques ? Aussi, comme base de nos futures recherches par dimensions, nous assemblons plusieurs sous-ensembles de données, soit en déconstruisant les URL, soit scrapant les pages Web et ainsi d'obtenir : les termes traduits, les requêtes adressées aux moteurs de recherches (Google, Bing\ldots{}), les titres des articles des sites de news et d'actualité, les titres et les descriptions des vidéos visionnées\ldots{}

À ce niveau, nous n'en sommes qu'aux prémisses de nos recherches. Dans le cadre d'une collaboration avec N. Gaumont et les outils développés pour le projet Politoscope\footnote{\RaggedOuter \url{https://politoscope.org/}}, nous pouvons par exemple déterminer la couleur politique des sites de news français visités à la BPI : plutôt neutres mais néanmoins en accord avec la moyenne des articles postés sur le Twitter politique français \citep{gaumont_methods_2017}. 

Des expérimentations\footnote{\RaggedOuter Travail réalisé en collaboration avec A. Sciberras, A. Habis, T. Mokart, J. Grenier, M. Arrivat, A. Saheb, M.A. Chamli, P. Bernat, étudiants à Télécom ParisTech} plus ouvertes sont également menées, à la manière d'un G. Legrady qui propose de visualiser certaines dimensions singulières des données d'emprunts de la bibliothèque municipale de Seattle \citep{legrady_making_2005}.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/paff}
  \caption{Prototypes de systèmes de visualisations, basés sur des dimensions particulières des logs de la BPI}
  \label{fig:paff}
\end{figure*}

\noindent Ainsi, entre autres prototypes sur lesquels nous travaillons, nous pouvons citer un système de visualisation des catégories d'URL par ilots de postes (Figure~\ref{fig:paff}, b), une analyse des langues utilisées par les sites de news (où l'on voit la place importante de l'arabe à travers le site d'Aljazeera notamment, Figure~\ref{fig:paff}, a) , ou encore une expérimentation sur les pages sportives, révélant un intérêt non négligeable pour les compétitions de criquet comparé au football\footnote{\RaggedOuter Données extraites des mois de mai \& juin 2018, couvrant une coupe du monde de football et le final de la ligue de criquet indienne} (Figure~\ref{fig:paff}, c).

Ces travaux exploratoires, finiront certainement par révéler de nouvelles pistes de recherches, pour continuer à étudier le Web de la BPI, ces visiteurs et la manière dont ils naviguent sur la toile. Une analyse à venir des sites de la CAF ou de pôle emploi, pourront peut être déboucher sur la mise en place de services d'accompagnement dédiés. 

Mais plus nous laissons le temps passer et plus les données du Web se protègent de nos explorations. En effet, le taux de sites Web sécurisés augmente chaque jour et les URL en \textit{https}\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/HyperText\_Transfer\_Protocol\_Secure}} empêchent le proxy de la BPI d'enregistrer l'entièreté des adresses hypertextes : sur une journée moyenne de logs\footnote{\RaggedOuter Données de juillet 2018}, $88\%$ des sites Web sont identifiés comme protégés. Par exemple, toutes les URL du site \textit{youtube.com}, contenues dans les logs, sont tronquées après le nom de domaine. Nous ne pouvons donc plus avoir accès à l'adresse exacte d'une vidéo ou d'une page personnelle. Ainsi en va-t-il du Web et de ses archives, lorsque le premier évolue les secondes deviennent momentanément obsolètes, tant qu'elles n'intègrent pas elles même ces nouvelles mutations. 

\section{Les dynamiques de l'accueil des réfugiés (2015-2017)} 
\label{sec:7_calm}

\noindent Certaines zones de la toile se trouvent hors de ce qu'il est coutume d'appeler \textbf{le Web indexable} (\textit{the indexable Web}) \citep{lawrence_searching_1998}, soit la surface du Web rendue accessible par le travail des crawlers des moteurs de recherche généralistes (Google, Yahoo\ldots{}). La partie immergée du Web, dissimulée derrière les logins et les mots de passes, traduit une réalité technique de la toile : la grande majorité des formulaires, des services Web et des diverses bases de données, sur lesquels s'appuient les sites, ne sont pas adressables depuis la structure hypertexte du Web. Ainsi, le \textbf{Web profond} \citep{bergman_white_2001} représente, selon une étude publiée 2001, 500 fois la taille du Web de surface\footnote{\RaggedOuter \url{http://archive.wikiwix.com/cache/?url=http://www.press.umich.edu/jep/07-01/bergman.html}} et constitue, de fait, un défit pour les archivistes du Web cherchant, autant que faire ce peut, à le préserver \citep{masanes_archiving_2006}.

Dans cette section, nous partirons de l'archivage d'un de ces formulaires du Web profond pour tenter de comprendre, à travers l'analyse de ses évolutions successives (structure et contenu), un moment récent de l'histoire des migrations : la \textit{crise des réfugiés} de l'été 2015 et les formes multiples d'accueil qu'elle a engendrées ou réactivées\footnote{\RaggedOuter Cette section fait l'objet d'une publication en cours de rédaction : D. Diminescu, Q. Lobbé, \textit{Les mots de l'accueil} (titre provisoire)}.

\subsection{Été 2015 : organiser l'accueil}

\noindent À l'été 2015, les médias et les réseaux sociaux regorgent de reportages sur les réfugiés en détresse, aux portes de l’Europe. Qualifiée de \textit{crise migratoire} sans précédent, cette vague d'arrivées trouve son origine dans la persistance des conflits en Irak et en Syrie. Avec l'échec de la révolution citoyenne de 2011 qui se transforme, petit à petit, en une guerre civile meurtrière, ce sont près de 5 millions de Syriens qui sont forcés de franchir leurs frontières, pour fuir vers les territoires voisins~: 3 millions d'entre eux s'installent dans des camps en Turquie et le Liban accueille l'équivalent humain du tiers de sa population \citep{blanchard_crise_2016}.   

Par la suite, au début du printemps 2015, des milliers de personnes commencent à débarquer quotidiennement sur les îles de la mer Égée, au prix d'une traversée mortelle, partant des côtes turques et transformant ces eaux en un cimetière à ciel ouvert. Aussi, devant l'ampleur d'un phénomène qu'il est incapable de gérer seul, l'État grec décide rapidement de financer le transfert des réfugiés vers Athènes \citep{pillant_en_2016}. Point à partir duquel, beaucoup décident ensuite de suivre la \textit{route des Balkans}, espérant trouver un abris en Europe de l'ouest, notamment en Allemagne ou en Angleterre. L'espace de quelques mois, les frontières balkaniques deviennent ainsi \textit{facilement} franchissables, et ce, malgré une couverture médiatique grandissante, augmentant les chances de se faire arrêter en chemin. 

Mais, cet état de fait ne dure pas longtemps. La Hongrie s'enferme derrière des kilomètres de barbelés et les contrôles aux frontières sont rétablis au sein de même de l'espace Schengen. Ainsi, plusieurs gouvernements d'Europe centrale choisissent de condamner les points de passages, se servant politiquement de ce geste comme d'une démonstration de force autoritaire et protectionniste. Aussi, après l'échec des processus de relocalisation\footnote{\RaggedOuter Transfert, depuis l'Italie et la Grèce, de personnes éligibles aux droits d'asile, et ce, vers d'autres pays de l'Union Européenne \citep{tervonen_finlande:_2016}}, l'Union Européenne (UE) finit par verrouiller ses frontières extérieures, avec la mise en place de hotspots, dès le mois d'octobre 2015~: des lieux de privation de liberté alors présentés comme des \textit{centres d'identification et de réception} pour les réfugiés.   

Bien que le Haut-Commissariat des Nations unies pour les réfugiés (HCR) comptabilise, pour la seule année 2015, prêt de 65 millions de personnes victimes de migrations forcées dans le monde\footnote{\RaggedOuter Demandeurs d'asile, réfugiés enregistrés, personnes apatrides ou déplacées dans leur propre pays}, l'arrivée, à la même période, de ces réfugiés en Europe reste pourtant difficile à estimer. Sur ce point nous pouvons, tout de même, nous tourner vers les statistiques de l'agence Eurostats\footnote{\RaggedOuter Voir \url{https://frama.link/rb9m8yRD}} portant sur le nombre de demandes d'asile, déposées dans l'UE cette année là. Soit 1,255,640 primo-demandeurs sur l'ensemble des 28 États membres (en augmentation de $123\%$ par rapport à 2014). L'Allemagne en prenant à elle seule $35,2\%$, devant la Hongrie ($13,9\%$) et la Suède ($12,4\%$).

Loin derrière, mais sans pour autant rester totalement à l'écart, la France enregistre en 2015 plus de 70,000 nouvelles demandes d'asile sur sont territoire, le taux de reconnaissance du statut de réfugié\footnote{\RaggedOuter Chiffres de l'Office français de protection des réfugiés et apatrides (Ofpra) \url{https://www.ofpra.gouv.fr/fr/l-ofpra/actualites/premiers-chiffres-de-l-asile-en}} atteignant $31,5\%$. Or, derrière chacune de ces demandes, se trouve une personne à accueillir et à prendre en charge. Ainsi, parallèlement aux services de l'État, se développe un tissu associatif qui s'oriente vers l'organisation et la mise en place de l'accueil des réfugiés en France. 

En particulier, l'association Singa\footnote{\RaggedOuter \url{https://www.singafrance.com/}} propose, à travers son programme \textit{Comme à la maison} (CALM), de mettre en relation des familles françaises souhaitant accueillir chez elles, à la maison donc, une personne ayant déposé une demande d'asile. L'accueil proposé par Singa ne cherche pas à répondre à situation d'urgence, mais à s'inscrire dans le temps long pour faciliter l'intégration des personnes, l'hébergement allant de 3 à 6 mois. La médiation entre les particuliers \textit{accueillants} et les réfugiés \textit{accueillis}, se fait d'abord en remplissant un formulaire en ligne\footnote{\RaggedOuter \url{http://calm.singa.fr/inscription/accueillant/}}, c'est ensuite au personnel de Singa que revient la tâche de créer les pairs accueillants/accueillis.

\subsection{Les archives du formulaire des accueillants}

\noindent Dans le cadre d'un projet de recherche, monté en partenariat avec l'équipe en charge de CALM, nous avons eu accès, entre 2015 et 2017, aux enregistrements des formulaires d'inscriptions et à leurs évolutions successives\footnote{\RaggedOuter Données anonymisées par les membres de l'association}. 

L'inscription se déroule comme suit : lorsque l'on se connecte sur la plateforme CALM, il convient d'abord d'indiquer si l'on est un futur accueillant ou un futur accueilli, le système nous dirige ensuite vers un formulaire dédié (Figure~\ref{fig:calm-capture}). L'inscription est individuelle autant pour les accueillis que pour les accueillants, même si pour ces derniers, on sous entend plus généralement la notion de foyer (Une famille, un  couple, voire une personne seule\ldots{}). Ces formulaires s'appuient sur la technologie gratuite Google Form\footnote{\RaggedOuter Web service permettant de créer et de partager à la volée des formulaires en ligne \url{https://docs.google.com/forms/u/0/}} et se présentent comme une suite de questions appelant des réponses ouvertes (d'expression libre) ou fermées (à choix multiples ou listés).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/calm-capture}
  \caption{Premières questions du formulaire accueillants}
  \label{fig:calm-capture}
\end{figure*}

\noindent Dans les faits, le formulaire des accueillis n'a jamais été réellement mis en place, si ce n'est durant quelques jours, au début de l'automne 2015. Durant ce court laps de temps, le service est assaillit et croule rapidement sous plusieurs centaines d'inscriptions. Aussi, faute de pouvoir gérer la demande, le formulaire est quasi immédiatement fermé, l'équipe de CALM proposant plutôt aux futurs accueillis de se déplacer dans les locaux de l'association pour les rencontrer directement. En revanche, le formulaire des accueillants reste lui accessible et fait l'objet de mis à jour régulière par l'association. Nous dénombrons, ainsi, 4 versions successives : \textbf{1)} avant juin 2015 \textbf{2)} de juin 2015 à novembre 2016 \textbf{3)} de novembre 2016 à juin 2017 \textbf{1)} après juin 2017.       

Partant de là, notre première tâche\footnote{\RaggedOuter Travail réalisé en collaboration avec E. Barnoud, S. Dahan, M. Garnier, T. Glasser, N. Leclerc, K. Nguyen, C. Ruppli, M. Verstraete, étudiants à Télécom ParisTech}, lorsque nous entrons en possession de ces archives, consiste à les nettoyer, à les structurer et à les uniformiser. En effet, il est courant que, d'une version à l'autre, la formulation d'une question puisse évoluer. Certaines apparaissent, d'autres disparaissent. Par exemple, la question de l'âge d'un accueillant est ramenée, progressivement, à sa date de naissance. Or, si l'information finale reste la même, la donnée à traiter, soit par un humain, soit par un script automatique, est différente. Il nous faut donc : ou bien transformer les âges en date, ou bien  faire l'opération inverse afin de mener, comme nous l'envisageons maintenant, une analyse longitudinale de l'ensemble de ces inscriptions. Pour ce faire, nous développons une première chaîne semi-automatique d'unification des données (Figure~\ref{fig:desambi}).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/calm-0}
  \caption{Évolution de la structure du questionnaire des accueillants}
  \label{fig:calm-0}
\end{figure*}

\newpage

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/desambi}
  \vspace*{0.2cm}  
  \caption{Unification des différentes versions d'une même base de données}
  \label{fig:desambi}
\end{marginfigure} 

\noindent Mais avant de plonger dans l'exploration de l'archive maintenant nettoyée, commençons par observer l'évolution de sa structure au cours du temps, telle que nous l'expose la Figure~\ref{fig:calm-0}. Contrairement à l'historique des sections d'un forum (Figure~\ref{fig:categories}) qui peut être révélateur de grandes ruptures ou de grands changements, la structure du formulaire CALM s'inscrit plutôt dans une forme de continuité. Il n'y a pas d'apparition de nouvelles questions à proprement parler, mais, une tendance générale à la fragmentation et la spécialisation de questions ouvertes (\textit{Parlez nous de vous}, \textit{Type d'espace}\ldots{}) en une suite de champs plus restreints (\textit{Quelles langues parlez vous ?}, \textit{Combien de chambres pouvez vous mettre à disposition ?}\ldots{}). 

À travers l'évolution du formulaire, ce sont les descripteurs avec lesquels sont qualifiés les accueillants, en base de données, qui se transforment et se rationalisent : d'un point de vue d'informaticien, il est ainsi plus simple de gérer à grande échelle un paramètre clairement définit et quantifiable (l'âge, un nombre de chambre, une liste de langues\ldots{}), qu'un champ d'expression libre, d'où il faudra extraire une information potentiellement mal formulée, voire inexploitable. La Figure~\ref{fig:calm-0} traduit, de fait, une évolution d'ingénierie, pensée pour améliorer la gestion et l'exploitation des données d'inscription. Aussi, cette discrétisation d'un individu en un ensemble de descripteurs normés sous-tend ce que A. Rouvroy et T. Berne nomment \textbf{gouvernementalité algorithmique}, soit :\\

\begin{fullwidth}
\og\textit{un certain type de rationalité (a)normative ou (a)politique reposant sur la récolte, l’agrégation et l’analyse automatisée de données en quantité massive de manière à modéliser, anticiper et affecter par avance les comportements possibles}\fg{} --- \citep[p.11]{rouvroy_gouvernementalite_2013}\\
\end{fullwidth}

\noindent La gouvernementalité algorithmique est une stratégie de rationalisation et de transcription du réel sous forme de données numériques exploitables par les systèmes informatiques. L'incertitude générée par les comportements humains est effacée (ici les champs d'expression libre) au profit d'une information spontanée et objective, qu'il n'est plus nécessaire de discuter. Aussi pourquoi l'association Singa a-elle souhaité rationaliser à ce point les modalités de gestion de ses données d'inscriptions ? Pourquoi modéliser le profil des familles d'accueillants~?\\

\noindent Nait d'un hackathon\footnote{\RaggedOuter Événement de courte durée réunissant développeurs, experts industriels et associatifs pour participer au développement d'un projet collaboratif \citep{lobbe_concevoir_2018}}, en février 2015, le programme CALM est, dans un premier temps, géré par des personnes qui ne se considèrent pas comme des développeurs informatiques (Figure~\ref{fig:calm-0}, versions 1 \& 2). Par le choix d'une infrastructure technologique simple et accessible (Google form et feuilles de calcul Excel), servant de base à une mise en relation manuelle des couples accueillants/accueillis\footnote{\RaggedOuter Les membres de l'association fouillent à la main les inscriptions dans leur base de données pour détecter de bons candidats à l'accueil}, l'association favorise d'abord un travail humain, qualitatif et fondé sur l'expérience acquise par son équipe. Chaque médiation est l'objet d'une discussion singulière entre familles et réfugiés.

Cependant, quelques mois plus tard (Figure~\ref{fig:calm-0}, versions 3 \& 4), devant faire face à une augmentation des inscriptions au programme, Singa décide de recruter un dévelop\-peur pour CALM. Au cours d'entre\-tiens organisés avec ce dernier, nous apprenons qu'il travaille alors sur la conception d'un système de \og\textit{matching automatisé}\fg{} des accueillants et des accueillis, pour épauler, voire remplacer, à terme, le travail fastidieux des membres de l'association. En favorisant des questions précises et non bruitées dans les formulaires, il pense dégager \og\textit{une trentaine de paramètres}\fg{} décrivant finement le profil des accueillants. La base de données sera, de fait, adaptée à un futur traitement algorithmique. Son système de suggestion automatisé proposera alors \og\textit{un sous-ensemble qualifié de familles d'accueil\-lants} qui, une fois validé par l'accueillis, seront à même de discuter ensemble \og\textit{dans un salon en ligne privé, hébergé sur la plateforme}\fg{}. Ce faisant, le développeur pousse au maximum la logique d'automatisation de la mise en relation, avec une médiation devenue purement algorithmique, supposée neutre ou juste, car rendue invisible et sans intermédiaire humain. L'incertitude disparait. 

Mais, la collaboration entre le développeur et l'association n'aboutit pas : la mise en production du module de matching est annulée, incapables de faire converger leurs visions respectives de l'outil. En effet, Singa comprend rapidement que la mise en relation humaine des réfugiés et des familles doit rester au cœur de leur savoir faire. Elle ne doit pas être déléguée à une machine, car cette expertise est vecteur de confiance et de liens entre les deux parties. 

En cela, Singa et CALM font office d'exception dans le paysage des innovations sociales et solidaires, émergeant à mesure que la crise des réfugiés s'aggrave. Ils sont ainsi nombreux\footnote{\RaggedOuter Dans un rapport encore non publié, L. Macias, recense l'apparition de 82 applications mobiles d'aide aux réfugiés sur cette période}, dans la veine de l'initiative Techfugees\footnote{\RaggedOuter \url{https://techfugees.com/}} à se lancer, par altruisme ou par simple opportunisme, dans la création de toutes sortes d'applications et de services automatisés à destination des personnes réfugiées : diffusion d'informations, appels d'urgence, aide à la navigation, traduction\ldots{} Pour D. Diminescu, l'année 2015 doit être considérée, comme un véritable moment \textbf{technophorique}, où l'on voit exploser l'intérêt pour ce type d'innovations.

Mais, nous tenons à souligner que cette forme de solutionisme technologique \citep{morozov_save_2013} ouvre une brèche potentiellement dange\-reuse, qui nous obligent à interroger les modalités de gestion, de traitement et de protection des données numériques personnelles des populations réfugiées. En effet, ces multiples applications ont accès à des informations extrêmement sensibles (des noms, des adresses, des localisation GPS\ldots{}), qu'elles stockent et accumulent sans qu'aucun consensus technique ou éthique n'ait encore été établie et partagée à grande échelle. Aussi, comment mettre en garde et sensibiliser les personnes réfugiées, vis-à-vis d'une utilisation malveillante ou maladroite de leurs données personnelles par un tiers ? Comment concevoir et penser des protocoles de recherches, basés sur ces données et qui seraient à la fois sécurisés et sécurisants ? Ces questions restent ici ouvertes, mais nous espérons à l'avenir pouvoir mener plus avant nos réflexions.

\subsection{Les mots de l'accueil}

\noindent Nettoyé et unifié, le contenu de l'archive peut maintenant faire l'objet d'une exploration longitudinale. De juin 2015 à juin 2017, Singa met en place l'accueil de prêt de 300 personnes réfugiées et enregistre, dans le même temps, 11,892 inscriptions d'accueillants sur sa plateforme. Mais, la distribution temporelle de ces inscriptions est loin d'être uniforme, le mois de septembre 2015 comptabilisant à lui seul prêt de 10,000 propositions d'accueil. La Figure~\ref{fig:calm-distri} donne le détail des inscriptions par jour, du 1er au 15 Septembre 2015.

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/clam-distri}
  \caption{Inscriptions par jour au programme CALM (Septembre 2015) et pourcentage de d'utilisation des mots \textit{internet} et \textit{radio} dans le champ \textit{Motivations ?}}
  \label{fig:calm-distri}
\end{figure}

\noindent En Aout 2015, peu de personnes s'intéressent au programme CALM, le souvent cantonnés à un milieu militant et sensible à la cause des réfugiés. Mais pourtant, les inscriptions d'accueillants explosent littéralement le 3 septembre 2015, passant de quelques dizaines à plusieurs milliers en l'espace d'une semaine. La diffusion mondiale, par la presse et la télévision, de la photographie du corps du jeune A. Kurdi\footnote{\RaggedOuter \url{https://fr.wikipedia.org/wiki/Alan_Kurdi}}, retrouvé noyés sur les côtes turques, suscite une grande émotion et génère une vague d'inscriptions sans précédent sur CALM. Aussi, de la base de données, nous tirons plusieurs informations démographiques basiques que nous confrontons avec des entretiens d'accueillants et enrichissons par la lecture des champs d'expression libre \textit{Motivations ?} et \textit{Parlez nous de vous}. 

\begin{marginfigure}%
  \includegraphics[width=\linewidth]{graphics/calm-prof}
  \vspace*{0.2cm}  
  \caption{Répartition des accueillants par classes professionnelles}
  \label{fig:calm-prof}
\end{marginfigure} 

Les nouveaux accueillants vivent, ainsi, dans les grands foyers urbains français, proposant de simples pièces dans de petits appartements, voire uniquement un canapé. Ceux qui résident à la campagne mettent parfois à disposition des maisons entières ou des dépendances demeurées vacantes, pouvant accueillir bien plus d'un réfugié à la fois. Jeunes trentenaires ou parents se retrouvant seuls après le départ de leurs enfant (Figure~\ref{fig:calm-age}), les accueillants sont, pour $50\%$ d'entre eux (Figure~\ref{fig:calm-prof}), des cadres, des retraités ou des personnes exerçants une profession intellectuelle supérieure (des enseignants, des journalistes, des artistes …).

Si, pour certaines familles, l'accueil de réfugiés s'inscrit dans le prolongement d'un engagement philosophique ou politique, voire fait écho à une histoire familiale passée (pour les descendants d'immigrés), il nous semble pourtant, à la lecture du champ \textit{Motivations ?}, qu'une majorité d'entre elles pense répondre, d'abord et avant tout, à une situation d'urgence. Les reportages sur la situation en mer Égée, diffusés quotidiennement, poussent un public non militant à se tourner vers Singa, à s'engager auprès de l'association. 

\begin{figure}
  \includegraphics[width=\linewidth]{graphics/calm-age}
  \caption{Distribution de l'âge des accueillants}
  \label{fig:calm-age}
\end{figure} 

\noindent Afin de vérifier cette impression, nous développons plusieurs scripts de tokenization et de stemming (Section~\ref{sec:4_moteur}), que nous appliquons à l'ensemble des déclarations de motivations des accueillants. Ces déclarations pouvant se cantonner à une ou deux lignes de texte seulement, mais également s'étirer sur plusieurs paragraphes argumentés. Nous construisons ainsi un \textbf{vocabulaire} représentatif des mots les plus fréquemment utilisés par les familles. Pour chacun de ces mots, nous traçons une courbe de fréquence trimestrielle, normalisée par le nombre de nouveaux inscrits sur la même période. Nous pouvons ainsi suivre, l'évolution, au cours du temps, de la fréquence d'utilisation de l'ensemble de ces termes (Figure~\ref{fig:calm-2}).

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/calm-2}
  \caption{Évolution de la fréquence d'utilisation de certains termes du champ \textit{Motivations ?}}
  \label{fig:calm-2}
\end{figure*}

\noindent Visuellement, ces mots peuvent être classés suivant quatre grandes tendances : \textbf{1)} les mots fréquemment utilisés à la fin de l'été 2015 et dont la proportion décroit par la suite (Figure~\ref{fig:calm-2}, a), \textbf{2)} les mots utilisés de manière stable de juin 2015 à juin 2017 (Figure~\ref{fig:calm-2}, b), \textbf{3)} les mots prenant de l'importance à mesure que la couverture médiatique diminue (Figure~\ref{fig:calm-2}, c), \textbf{4)} les mots utilisés de manière non caractéristique. De fait, un vocabulaire propre à chaque tendance peut être dégagé :

Si la volonté de rester \textit{solidaire} vis-à-vis du \textit{drame} et de la détresse des personnes \textit{réfugiées} en leur proposant un \textit{hébergement} reste stable dans le temps, c'est en réponse au choc médiatique ( \textit{télévision, radio, reportages}\ldots{} ) que nombre d'accueillants viennent dans un premier temps s'inscrire au programme Calm, comme un réflexe face à l'\textit{urgence} de la situation.

En revanche, plus nous nous éloignons chronologiquement de l'épi\-centre de la crise et plus l'accueil se conçoit comme une expérience réfléchie et mûrie de longue date : les accueillants disent vouloir \textit{intégrer} les accueillis et \textit{partager} avec eux, les \textit{recevoir} dans le \textit{confort} et dans le \textit{respect}, \textit{s'entraider} et \textit{s'enrichir}. Le vocabulaire devient alors plus posé, rassurant ( \textit{chaleur, heureuse, belle, cœur}\ldots{} ) et se déploie comme autant de façon d'exprimer le soin que l'on souhaite apporter aux personnes réfugiées. Ainsi, la \textit{chambre} que l'on partage en 2017, prend le relais du coin de \textit{canapé} que l'on proposait en 2015.
   
Parmi l'ensemble des médias qui ont influencé les familles d'accueil\-lants, France Inter\footnote{\RaggedOuter \url{https://www.franceinter.fr/}} semble avoir joué un rôle très particulier. En effet, les 3 et 15 Septembre 2015, Singa bénéficie\footnote{\RaggedOuter Voir \url{https://www.franceinter.fr/emissions/grand-angle/grand-angle-03-septembre-2015} \url{https://www.franceinter.fr/emissions/l-esprit-d-initiative/l-esprit-d-initiative-15-septembre-2015} \url{https://www.franceinter.fr/emissions/un-jour-en-france/un-jour-en-france-15-septembre-2015 }} de plusieurs passages sur les ondes de la radio nationale : un reportage, une interview et un débat. Dans le champ \textit{Motivations ?}, les accueillants désignent alors France Inter comme vecteur de découverte principal de l'association. L'expression \og\textit{J'en ai entendu parler à France Inter}\fg{}\footnote{\RaggedOuter Une expérience de clustering par k-means nous permet de détecter un cluster de personnes utilisant le vocabulaire : \textit{entendu, parler, france, inter, radio, association, médias\ldots{}}} devient le dénominateur commun de plus de 500 inscrits via le formulaire en ligne. 

Aussi, en comparant la fréquence d'utilisation des mots \textit{internet} et \textit{radio} avec les dates des reportages de France Inter (voir la Figure~\ref{fig:calm-distri}, courbes du bas et tirets rouges), il est possible de voir une corrélation nette entre ces événements et le choix, momentané, du second médium au détriment du premier. L'écoute de France Inter devient alors, à nos yeux, un marqueur sociologique au moins aussi important que l'âge ou la profession des accueillants. Mais, aidé par une mise en scène sonore très immersive (captation dans les locaux de Singa en pleine agitation et rencontre avec une accueillante), le vocabulaire utilisé lors de ces passages radio a-il pu influencer les futurs accueillants ? Peut on retrouver la trace de ces mots dans les archives du formulaire ? 

Pour ce faire, nous construisons enfin une interface d'exploration interactive\footnote{\RaggedOuter \url{https://github.com/lobbeque/calm-miner/tree/master/viz}}. Basée sur la découverte mot à mot de liens entre le texte de chaque intervention à France Inter (Figure~\ref{fig:calm-match}, partie gauche) et les déclarations de motivations des accueillants issues de la base de données (Figure~\ref{fig:calm-match}, partie droite), cette interface nous permet d'identifier l'esquisse d'un vocabulaire commun.

\begin{figure*}
  \includegraphics[width=\linewidth]{graphics/calm-match}
  \caption{Utilisation d'un même vocabulaire (bleu) entre les reportages de France Inter (gauche) et les déclarations de motivation des accueillants (droite)}
  \label{fig:calm-match}
\end{figure*}

\noindent À ce niveau et passé cette première phase exploratoire, de futurs travaux devront permettre de quantifier, si possible, l'influence lexicale de la radio sur ces déclarations d'intentions. 

Aussi et afin de compléter notre étude, il pourrait être intéressant d'élargir le panorama de recherche à d'autres types d'innovations sociales et solidaires. Chaque nouvelle structure apportant une manière différente de concevoir l'accueil et de penser la gestion des données accueillants/accueillis. Par exemple, les membres du \textit{Jesuit Refugee Service}\footnote{\RaggedOuter \url{http://www.jrsfrance.org/}} (JRS) utilisent un système de prise de contact et d'inscription des familles d'accueillants par email. De même, en Belgique, les membres de la plateforme citoyenne \textit{Bxlrefugeess}\footnote{\RaggedOuter \url{http://www.bxlrefugees.be/}} s'organisent de manière autonome et décentralisée via des sondages Facebook\footnote{\RaggedOuter \url{https://www.facebook.com/plateformerefugiesbxl?fref=ts}}. Ils se rencontrent ensuite chaque soir à Bruxelles, au cœur du parc Maximilien, pour mettre en place un hébergement d'urgence et quotidien des réfugiés.

\begin{center}
	\textbf{***}
\end{center}

\noindent Après avoir consacré la quasi totalité de notre manuscrit à l'analyse d'archives Web \textit{classiques}\footnote{\RaggedOuter Les collectages de sites Web par des crawlers étant, en volume, le type d'archive Web le plus représenté et le plus utilisé}, ce dernier chapitre aura été l'occasion d'élar\-gir nos horizons de recherche. Il existe, ainsi, une multitude de traces numériques à explorer pour interroger les diverses formes de représentations en ligne des populations migrantes.  

Ce faisant, les archives de navigation Web de la BPI se sont, d'abord, présentées à nous comme le moyen d'aborder, plus directement, les usages du Web de personnes en situation souvent précaire (Section~\ref{sec:7_bpi}). Migrants, sans domicile fixe ou séniors isolés se retrouvent à la bibliothèque du Centre Pompidou et s'installent jour après jour devant les postes Internet Libre. Ils viennent y chercher du repos, consulter des vidéos, voir simplement du monde ou effectuer des recherches documentaires approfondies. 

Mais, si au final, nous avons chercher à reconstruire une chaine d'exploitation des logs assez similaire à ce que nous avions bâti pour les collectages de l'Atlas e-Diasporas (Section~\ref{sec:4_moteur}), le travail réalisé avec la BPI nous aura surtout permis de réaffirmer l'idée suivante : les liens entre enquêtes de terrain et explorations à grande échelle de données archivées doivent être maintenus ou encouragés. 

Le Web de la BPI s'intègre dans l'écosystème global de la bibliothèque : le lieu, le personnel, les visiteurs, ce que l'on y voit, ce que l'on y entend, ce que les autres consultent\ldots{} Aussi, nous ne pouvons nous satisfaire de la seule perspective que nous donnent à voir les logs de navigation Web. Les observations in situ préfigurent toute hypothèse de travail et nous permettent de cheminer vers la compréhension des usages du Web de la BPI, dans un dialogue constant entre explorations semi-automatiques et validations par le terrain. Mais, ces traces se dégradent déjà et perdent de leur richesse, le Web se protégeant mécaniquement de nos méthodes de capture, dissimulé derrière des URL en https. L'archive Web, quelque soit sa nature et son contenu, n'est pas une matière immortelle ou immuable. Ses défauts et ses points de fragilité présents ou à venir doivent être pris en compte tout au long de nos analyses.

De son côté, l'étude des archives du formulaire d'inscrip\-tion au programme CALM nous a permis d'évoquer, sous certains aspects, la \textit{crise des réfugiés} de l'été 2015 (Section~\ref{sec:7_calm}). En réponse à une couverture médiatique inédite, une vague soudaine de citoyens et d'anonymes se sont proposés d'accueillir les victimes de ce drame. Par l'étude automatisée de leurs déclarations de motivations et des mots qu'ils employaient pour se décrire, nous avons pu entrapercevoir les dynamiques de cet forme d'accueil, de personnes réfugiées chez des particuliers, entre 2015 et 2017. Ou comprendre comment un geste d'urgence s'est transformé progressivement en une démarche réfléchie. 

Mais, le contenu d'une archive n'est pas la seule et unique source d'information à interroger. La forme de cette dernière et la compréhension du contexte historique dans lequel elle a été définie, puis potentiellement modifiée, sont autant d'éléments susceptibles d'enrichir nos explorations. Le programme CALM a, ainsi, été confronté à la tentation de l'automatisation et du tout algorithme là où, justement, le savoir-faire manuel des équipes de l'association incarnait sa singularité, dans un moment de pure technophorie. Aussi, et de manière plus générale, les modalités de gestion, d'analyse et de traitement des données liées aux migrations doivent faire l'objet de recherches dédiées et approfondies, ne serait-ce que pour garantir la sécurité des personnes concernées. \\

\noindent Enfin, au cours de cette thèse, d'autres corpus d'archives auront été constitués au grès des rencontres et de l'évolution de nos recherches. Conversations Whatsapp, groupes Facebook de réfugiés syriens ou encore vidéos Youtube de traversées de la mer Égée, sont autant de fragments extraits de la masse quotidienne de données générées par les migrations. Diverses et éparses, la valeur historique et sociologique de ces traces grandit à mesure que le temps passe et le devenir de certaines d'entre elles nous frappe encore aujourd'hui. Ainsi, lorsqu'à l'été 2016, nous accompagnions les équipes d'OpenstreetMap\footnote{\RaggedOuter Carte du monde en ligne, open source et collaborative \url{https://www.openstreetmap.org}} sur une campagne de cartographie\footnote{\RaggedOuter Ce travail a fait l'objet d'une publication : Q. Lobbé, (2016), \textit{Cartographier les jungles}, Plein Droit n°110, 2016} des camps de Calais et de Grande-Synthe, il nous aurait été impossible d'imaginer que, seulement quel\-ques mois plus tard, ces cartes en ligne deviendraient archives des \textit{jungles} telles qu'elles avaient été (Figure~\ref{fig:openstreet}). 

\begin{figure*}%
  \includegraphics[width=\linewidth]{graphics/openstreet}
  \caption{Évolution de la création de la carte de la Jungle de Calais en Juillet 2016 (a) et carte finale (b)}
  \label{fig:openstreet}
\end{figure*}     


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Conclusion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{\Large Conclusion}
\chaptermark{CONCLUSION}

\noindent Cette thèse a été menée avec la volonté assumée de revenir au sens social et historique premier des archives Web manipulées. Quitte à laisser en cours de route des pistes à peine défrichées, nous nous étions donné pour objectif de proposer l'illustration concrète d'une analyse du Web passé (Chapitre \ref{chap:6}) afin d'entrevoir les possibilités offertes par le fragment Web (Chapitre \ref{chap:5}). Ce faisant, nous souhaitons maintenant revenir  sur quelques éléments restés à la marge.\\ 

\noindent Il serait intéressant, en premier lieu, de poursuivre la discussion engagée sur les artéfacts de crawl (Section \ref{sec:4_temporalite} et \ref{sec:desagreger}). Nous pourrions profiter de la nature de nos corpus pour proposer un modèle plus ambitieux de gestion de la cohérence entre pages et fragments archivés. Passant d'un crawl unique à l'intégration de plusieurs campagnes de collecte, il s'agirait alors de penser la cohérence non plus du point de vue du crawler, mais en considérant cette fois le regard singulier d'un observateur.

Cette réflexion déboucherait sur la mise en place d'une palette d'outils destinés à juger de la qualité générale ou relative des corpus étudiés. Des indicateurs dynamiques de cohérence (structurelle, temporelle, thématique\ldots{}) permettraient au chercheur de s'orienter tout au long de son exploration. Il pourrait aussi s'agir de généraliser l'usage des échelles de datation (Table \ref{tab:datation_2}) en calculant, à la volée, l'écart entre les diverses dates d'une page Web consultée et la période ciblée par une requête donnée.

La méthode d'extraction des fragments Web (Section \ref{sec:5_scraping}) gagnerait, pour sa part, à être comparée à d'autres approches. Même si nous soutenons l'idée qu'une page archivée doit être segmentée relativement à chaque question de recherche, cela ne doit pas nous empêcher de faire l'inventaire des défauts et des qualités de notre stratégie. D'autres chercheurs pourraient alors s'en saisir et proposer des implémentations concurrentes ou complémentaires.  

Malgré nos efforts, la capacité du fragment Web à capturer les dispositifs d'écriture et de partage d'un contenu sur le Web (Section \ref{sec:5_fragment}, point n°5) n'a pas été exploitée. Cette dimension aurait pourtant pu enrichir notre analyse de la migration des blogs marocains vers les plateformes de réseaux sociaux (Section \ref{sec:6_blogs}), et ce, en questionnant les gains cognitifs et sémiologiques d'une telle mutation. C'est peut-être là que se niche la clé de compréhension du passage d'un territoire du Web à un autre.   

Enfin, fidèles à notre approche exploratoire (Section \ref{sec:6_eda}), il nous semble évident que l'étude des conversations postées sur \textit{yabiladi.com} pourrait être poussée plus avant. Par exemple, nous n'avons pas observé dans le détail les prises de position des pro et des anti mouvement du 20 février. Une analyse fine du vocabulaire employé pourrait nous aider à entrevoir les conflits internes au forum. De nouvelles catégories apparaitraient alors, nous offrant une lecture approfondie de ces événements.\\

\noindent À la manière d'un inventaire, le Chapitre \ref{chap:7} nous invitait à porter notre réflexion au-delà des archives Web et des formes classiques de collecte. Constitués à différentes époques et sur la base de technologies ou de standards parfois datés, les corpus archivés se laissent aujourd'hui découvrir dans toute leur diversité. Ainsi, chaque plongée dans la mémoire du Web passé nous pousse, tout autant, à repenser notre rapport au Web tel qu'il a été qu'à questionner, au présent, les mutations du Web vivant.

Assez paradoxalement et malgré la multiplication des moyens de connexion, force est de constater que le Web d'aujourd'hui s'appauvrit. En effet, la toile subit les assauts de stratégies industrielles visant à lui imposer une forme de gouvernance marchande. Les GAFA\footnote{\RaggedOuter Acronyme de Google, Apple, Facebook et Amazon désignant de manière plus générale l'ensemble des géants du Web.} se nourrissent de la singularité de nos passages sur le Web en réduisant les traces que nous y laissons à un ensemble fini de particularités calculables. Penser le Web, d'abord et avant tout, pour y faire prospérer des algorithmes de recommandation ou de profilage finira inéluctablement par impacter le devenir de l'archivage. L'altérité que l'on pouvait éprouver face à la multitude des ressources et des personnes évoluant sur le Web, disparait au profit d'une normalisation basée sur l'historique de nos propres navigations. De fait, avec la personnalisation généralisée de nos manières d'être sur la toile (Section~\ref{sec:2_web}), c'est toute l'architecture commune du Web qui tend à s'effacer.

Et si l'avenir du Web vivant appelle une reprise en main collective de son développement, pour nous, explorateurs d'archives, l'enjeu est de veiller à ce que les corpus du Web passé restent des communs de l'humanité. Nous avons la chance d'être contemporains de la matière sur laquelle nous menons nos recherches. Aussi, prenons garde à ce que les archives ne deviennent pas des denrées à monétiser et favorisons plutôt un modèle où elles contribueraient à produire des savoirs. \\

\noindent Ce faisant, l'une des dimensions les plus importantes du fragment Web est peut-être de vouloir recentrer l'exploration sur le chercheur et sur ses choix, en préférant au consommateur passif la figure du praticien actif. 

Le Web passé s'éprouve dans la durée et dans une forme de rapport qualitatif à ce qu'il renferme. Les savoir-faire que nous développons incorporent alors l'expérience de situations vécues au contact direct des archives. De fait, nous recommandons des méthodes d'analyses mixtes, alliant traitements automatisés à grande échelle et validations ad hoc et manuelles. Ces stratégies doivent pouvoir s'adapter à la singularité des corpus et à la variété des époques représentées. Pour rendre compte, au présent, du Web tel qu'il a été, il faut ainsi parfois savoir se rendre anachronique à son propre temps.

Mais il ne s'agit pas, pour autant, de faire l'économie d'outils déjà existants. La Wayback Machine, au même titre que les systèmes développés par l'INA, reste indispensable à toute analyse. Aussi, lors d'une exploration, rien ne doit être jeté ou laissé de côté. Ne sachant pas l'étendu de ce qui a été collecté et de ce qui n'a pas été préservé, tout élément, même anodin, pourrait être le point de départ des recherches de demain\footnote{\RaggedOuter Voir l'articulation entre les explorations des Sections \ref{sec:6_blogs} et \ref{sec:6_printemps}}. En creux, l'exploration des archives Web nous invite à la traque de ce qui, justement, est absent des corpus, repérer les légers décalages entre les collectages et identifier les fantômes qui hantent les pages.

Mosaïque dispersée, il est illusoire de vouloir préserver la mémoire du Web au sein d'un seul est unique corpus. Aussi, pourquoi ne pas chercher à fédérer les sources éparses de collecte pour y établir des ponts ou des jointures ? C'est en conjuguant les vastes ressources d'Internet Archive avec le plus petit des fichiers HTML égaré que nous pourrons tenter de reconstituer une image fidèle du Web passé. 

Cependant, la nature et la valeur que l'on accorde à nos traces évoluent avec le temps. Ce qui, autrefois, a été déposé sur le Web est peut-être, aujourd'hui, devenu trop sensible. Certaines données doivent ainsi être anonymisées, protégées ou aggrégées suivant les cas. Mais gardons-nous bien de détruire ou d'endommager les archives. Travaillons toujours sur des copies et laissons des zones inexplorées pour les générations à venir, car la plus grande tâche n'a pas encore commencé.

En effet, il nous faut maintenant poursuivre les recherches entamées sur l'Atlas e-Diaspora en les généralisant à l'ensemble des corpus migrants. Cela sera une manière de valider nos outils en mobilisant, à nouveau, l'ensemble des contributeurs de l'Atlas. Confrontés aux évolutions des sites qu'ils avaient cartographiés, ces chercheurs seront alors à même d'analyser les dynamiques révélées.\\

\noindent Arrivés au terme de cette thèse, nous espérons, finalement, avoir su créer des possibles et ouvrir quelques brèches dans les archives du Web passé. Encore balbutiantes, nos explorations finirons peut être par s'effacer au profit d'une discipline nouvelle, plus mature et qu'il nous faudra entièrement construire. Viendra alors le temps d'établir, enfin, les bases d'une véritable archéologie du Web.   


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Biblio %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\backmatter


\bibliography{biblio}
\bibliographystyle{apalike-fr}

%\printindex

\end{document}

